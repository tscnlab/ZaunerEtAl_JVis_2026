[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Analysis of human visual experience data",
    "section": "",
    "text": "Exposure to the optical environment — often referred to as visual experience — profoundly influences human physiology and behavior across multiple time scales. Two notable examples, from distinct research domains, can be understood through a common retinally-referenced framework.\nThe first example relates to the non-visual effects of light on human circadian and neuroendocrine physiology. The light–dark cycle entrains the circadian clock, and light exposure at night suppresses melatonin production (Brown et al. 2022; Blume, Garbazza, and Spitschan 2019). The second example concerns the influence of visual experience on ocular development, particularly myopia. Time spent outdoors — which features distinct optical environments — has been consistently associated with protective effects on ocular growth and health outcomes (Dahlmann-Noor et al. 2025).\nIn controlled laboratory settings, light exposure can be held constant or manipulated parametrically. However, such exposures rarely replicate real-world conditions, which are inherently complex and dynamic. As people move in and between spaces (indoors and outdoors) and move their body, head, and eyes, exposure to the optical environment varies significantly (Webler et al. 2019) and is modulated by behavior (Biller, Balakrishnan, and Spitschan 2024). Wearable devices for measuring light exposure have thus emerged as vital tools to capture the richness of ecological visual experience. These tools generate high-dimensional datasets that demand rigorous and flexible analysis strategies.\nStarting in the 1980s (Okudaira, Kripke, and Webster 1983), technology to measure optical exposure has matured, with miniaturized illuminance sensors now (in 2025) very common in consumer wearables. In research, several devices are available that differ in functionality, ranging from small pins measuring ambient illuminance (Mohamed et al. 2021) to head-mounted multi-modal devices capturing nearly all relevant aspects of visual experience (Gibaldi et al. 2024). Increased capabilities in wearables bring complex, dense datasets. These go hand-in-hand with a proliferation of metrics, as highlighted by recent review papers in both circadian and myopia research.\nAt present, the analysis processes to derive metrics are often implemented on a per-laboratory or even per-researcher basis. This fragmentation is a potential source of errors and inconsistencies between studies, consumes considerable researcher time (Hartmeyer, Webler, and Andersen 2022), and these bespoke processes and formats hinder harmonization or meta-analysis across multiple studies. Too often, more time is spent preparing data than gaining insights through rigorous statistical analysis. These preparation tasks are best handled, or at least facilitated, by standardized, transparent, community-based analysis pipelines (Zauner, Udovicic, and Spitschan 2024).\nIn circadian research, the R package LightLogR was developed to address this need (Zauner, Hartmeyer, and Spitschan 2025). LightLogR is an open-source, MIT-licensed, community-driven package specifically designed for data from wearable light loggers and optical radiation dosimeters. It contains functions to calculate over sixty different metrics used in the field (Hartmeyer and Andersen 2023). In a recent update, the package was expanded to handle modalities beyond illuminance, such as viewing distance and light spectra—capabilities highly relevant for myopia research (Hönekopp and Weigelt 2023).\nIn this article, we demonstrate that LightLogR’s analysis pipelines and metric functions apply broadly across the field of visual experience research, not just to circadian rhythms and chronobiology. Our approach is modular and extensible, allowing researchers to adapt it to a variety of devices and research questions. Emphasis is placed on clarity, transparency, and reproducibility, aligning with best practices in scientific computing and open science. We use example data from two devices to showcase the LightLogR workflow with metrics relevant to myopia research, covering working distance, (day)light exposure, and spectral analysis. Readers are encouraged to recreate the analysis using the provided code. All necessary data and code are openly available in the GitHub repository."
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Analysis of human visual experience data",
    "section": "",
    "text": "Exposure to the optical environment — often referred to as visual experience — profoundly influences human physiology and behavior across multiple time scales. Two notable examples, from distinct research domains, can be understood through a common retinally-referenced framework.\nThe first example relates to the non-visual effects of light on human circadian and neuroendocrine physiology. The light–dark cycle entrains the circadian clock, and light exposure at night suppresses melatonin production (Brown et al. 2022; Blume, Garbazza, and Spitschan 2019). The second example concerns the influence of visual experience on ocular development, particularly myopia. Time spent outdoors — which features distinct optical environments — has been consistently associated with protective effects on ocular growth and health outcomes (Dahlmann-Noor et al. 2025).\nIn controlled laboratory settings, light exposure can be held constant or manipulated parametrically. However, such exposures rarely replicate real-world conditions, which are inherently complex and dynamic. As people move in and between spaces (indoors and outdoors) and move their body, head, and eyes, exposure to the optical environment varies significantly (Webler et al. 2019) and is modulated by behavior (Biller, Balakrishnan, and Spitschan 2024). Wearable devices for measuring light exposure have thus emerged as vital tools to capture the richness of ecological visual experience. These tools generate high-dimensional datasets that demand rigorous and flexible analysis strategies.\nStarting in the 1980s (Okudaira, Kripke, and Webster 1983), technology to measure optical exposure has matured, with miniaturized illuminance sensors now (in 2025) very common in consumer wearables. In research, several devices are available that differ in functionality, ranging from small pins measuring ambient illuminance (Mohamed et al. 2021) to head-mounted multi-modal devices capturing nearly all relevant aspects of visual experience (Gibaldi et al. 2024). Increased capabilities in wearables bring complex, dense datasets. These go hand-in-hand with a proliferation of metrics, as highlighted by recent review papers in both circadian and myopia research.\nAt present, the analysis processes to derive metrics are often implemented on a per-laboratory or even per-researcher basis. This fragmentation is a potential source of errors and inconsistencies between studies, consumes considerable researcher time (Hartmeyer, Webler, and Andersen 2022), and these bespoke processes and formats hinder harmonization or meta-analysis across multiple studies. Too often, more time is spent preparing data than gaining insights through rigorous statistical analysis. These preparation tasks are best handled, or at least facilitated, by standardized, transparent, community-based analysis pipelines (Zauner, Udovicic, and Spitschan 2024).\nIn circadian research, the R package LightLogR was developed to address this need (Zauner, Hartmeyer, and Spitschan 2025). LightLogR is an open-source, MIT-licensed, community-driven package specifically designed for data from wearable light loggers and optical radiation dosimeters. It contains functions to calculate over sixty different metrics used in the field (Hartmeyer and Andersen 2023). In a recent update, the package was expanded to handle modalities beyond illuminance, such as viewing distance and light spectra—capabilities highly relevant for myopia research (Hönekopp and Weigelt 2023).\nIn this article, we demonstrate that LightLogR’s analysis pipelines and metric functions apply broadly across the field of visual experience research, not just to circadian rhythms and chronobiology. Our approach is modular and extensible, allowing researchers to adapt it to a variety of devices and research questions. Emphasis is placed on clarity, transparency, and reproducibility, aligning with best practices in scientific computing and open science. We use example data from two devices to showcase the LightLogR workflow with metrics relevant to myopia research, covering working distance, (day)light exposure, and spectral analysis. Readers are encouraged to recreate the analysis using the provided code. All necessary data and code are openly available in the GitHub repository."
  },
  {
    "objectID": "index.html#methods-and-materials",
    "href": "index.html#methods-and-materials",
    "title": "Analysis of human visual experience data",
    "section": "\n2 Methods and materials",
    "text": "2 Methods and materials\n\n2.1 Software\nThis tutorial was built with Quarto, an open-source scientific and technical publishing system that integrates text, code, and code output into a single document. The source code to reproduce all results is included and accessible via the Quarto document’s code tool menu. All analyses were conducted in R (version 4.4.3, “Trophy Case”) using LightLogR (version 0.9.2 “Sunrise”). We also used the tidyverse suite (version 2.0.0) for data manipulation (which LightLogR follows in its design), and the gt package (version 1.0.0) for generating summary tables. A comprehensive overview of the R computing environment is provided in the session info (see Session info section).\n\n2.2 Metric selection and definitions\nIn March 2025, two workshops with myopia researchers — initiated by the Research Data Alliance (RDA) Working Group on Optical Radiation Exposure and Visual Experience Data — focused on current needs and future opportunities in data analysis, including the development and standardization of metrics. Based on expert input from these workshops, the authors of this tutorial compiled a list of visual experience metrics, shown in Table 1. These include many currently used metrics and definitions (Wen et al. 2020, 2019; Bhandari and Ostrin 2020; Williams et al. 2019), as well as new metrics enabled by spectrally-resolved measurements.\n\n\nTable 1: Overview of metrics. In all cases, the averages for weekday, weekend, and the mean daily value are calculated through [mean_daily](https://tscnlab.github.io/LightLogR/reference/mean_daily.html).\n\n\n\nNo.\nName\nImplementation1\n\n\n\n\n\nDistance\n\n\n\n1\nTotal wear time daily\ndurations()\n\n\n2\n\nDuration ofNear work,\nIntermediate Work,\nNear + Intermediate Work, or\nper each Distance range\n(10cm steps)\n\n\nfilter for distance range +\ndurations() (for single ranges)\nor\ngrouping by distance range +\ndurations() (for all ranges)\n\n\n\n3\nFrequency ofContinuous near work\n\n\nextract_clusters() +\nsummarize_numeric()\n\n\n\n4\nFrequency,\nduration,\nand distances ofNear Work episodes\n\n\nextract_clusters() +\nextract_metric() +\nsummarize_numeric()\n\n\n\n5\nFrequency and duration of Visual breaks\n\n\nextract_clusters() +\nfilter\n\n\n\n\nLight\n\n\n\n6\nLight exposure (in lux)\nsummarize_numeric()\n\n\n7\nDuration per Outdoor range\n\n\ngrouping by Outdoor range +\ndurations()\n\n\n\n8\nThe number of times light level changes from indoor (&lt;1000 lx) to outdoor (&gt;1000 lx)\n\nextract_states() +\nsummarize_numeric()\n\n\n\n9\nLongest period above 1000 lx\nperiod_above_threshold()\n\n\n\nSpectrum\n\n\n\n10\nRatio of short vs. long wavelength light\n\nspectral_integration() +\nsummarize_numeric()\n\n\n\n11\nShort-wavelength light at certain times of day\n\nspectral_integration() +\nfilter_Time() (for defined times) orcut_Datetime() (for regular time intervals) oradd_photoperiod() (for solar times) +\ngrouping by time state +\nsummarize_numeric()\n\n\n\n\n\n\n\nTable 2 provides definitions for the terms used in Table 1. Note that specific definitions may vary depending on the research question or device capabilities.\n\n\nTable 2: Definitions of mean daily and conditions for distance and illuminance calculation\n\n\n\n\n\n\n\nMetric\nDescription / pseudo formula\n\n\n\nTotal wear time\n\\(\\sum(t)*dt, \\textrm{ where } t\\textrm{: valid observations }\\)\n\n\nMean daily\n\\(\\frac{5*\\bar{\\textrm{weekday}} + 2*\\bar{weekend}}{7}\\)\n\n\nNear work\n\\(\\textrm{working distance}, [10,60)cm\\)\n\n\nIntermediate Work\n\\(\\textrm{working distance}, [60,100)cm\\)\n\n\nTotal work\n\\(\\textrm{working distance}, [10,120)cm\\)\n\n\nDistance range\n\\(\\textrm{working distance}, {[10,20)cm \\textrm{,  Extremely near} \\\\ [20,30)cm \\textrm{,  Very near} \\\\ [30,40)cm \\textrm{,  Fairly near} \\\\ [40,50)cm \\textrm{,  Near} \\\\ [50,60)cm \\textrm{,  Moderately near} \\\\ [60,70)cm \\textrm{,  Near intermediate} \\\\ [70,80)cm \\textrm{,  Intermediate} \\\\ [80,90)cm \\textrm{,  Moderately intermediate} \\\\ [90,100)cm \\textrm{,  Far intermediate}}\\)\n\n\nContinuous near work\n\n\\(\\textrm{working distance}, [20,60)cm,\\)\n\\(T_\\textrm{duration} ≥ 30 minutes, \\textrm{ }T_{interruptions} ≤ 1 minute\\)\n\n\n\nNear work episodes\n\n\\(\\textrm{working distance}, [20,60)cm,\\)\n\\(T_\\textrm{interruptions} ≤ 20 seconds\\)\n\n\n\nRatio of daily near work\n\\(\\frac{T_\\textrm{near work}}{T_\\textrm{total wear}}\\)\n\n\nVisual break\n\\(\\textrm{working distance} ≥ 100cm, \\\\ T_\\textrm{duration} ≥ 20 seconds, \\textrm{ }T_\\textrm{previous episode} ≤ 20 minutes\\)\n\n\nOutdoor range\n\\(\\textrm{illuminance}, {[1000,2000)lx \\textrm{,  Outdoor bright} \\\\ [2000,3000)lx \\textrm{,  Outdoor very bright} \\\\ [3000, \\infty) lx \\textrm{,  Outdoor extremely bright}}\\)\n\n\nLight exposure2\n\n\\(\\bar{illuminance}\\)\n\n\nSpectral bands\n\\(\\textrm{spectral irradiance}, {[380,500]nm \\textrm{,  short wavelength light} \\\\ [600, 780]nm \\textrm{,  long wavelength light}}\\)\n\n\nRatio of short vs. long wavelength light\n\\(\\frac{E_{e\\textrm{,short wavelength}}}{E_{e\\textrm{,long wavelength}}}\\)\n\n\n\n\n\n\n\n2.3 Devices\nData from two wearable devices are used in this analysis:\n\nClouclip: A wearable device that measures viewing distance and ambient light [Glasson Technology Co., Ltd, Hangzhou, China; Wen et al. (2021); Wen et al. (2020)]. The Clouclip provides a simple data output with only Distance (working distance, in centimeters) and Illuminance (ambient light, in lux). Data in our example were recorded at 5-second intervals. Approximately one week of data (~120,960 observations) is about 1.6 MB in size.\nVisual Environment Evaluation Tool (VEET): A head-mounted multi-modal device that logs multiple data streams [Meta Platforms, Inc., Menlo Park, CA, USA; Sah, Narra, and Ostrin (2025); Sullivan et al. (2024)]. The VEET dataset used here contains simultaneous measurements of distance (via a time-of-flight sensor), ambient light (illuminance), activity (accelerometer & gyroscope), and spectral irradiance (multi-channel light sensor). Data were recorded at 2-second intervals, yielding a very dense dataset (~270 MB per week).\n\n2.4 Data processing summary\nThe Results section uses imported and pre-processed data from the two devices to calculate metrics. Supplement 1 contains the annotated code and description for the steps involved. The following summarizes the steps involved:\nData import: We imported raw data from the Clouclip and VEET devices using LightLogR’s built-in import functions, which automatically handle device-specific formats and idiosyncrasies. The Clouclip export file (provided as a tab-delimited text file) contains timestamped records of distance (cm) and illuminance (lux). LightLogR’s import$Clouclip function reads this file, after specifying the device’s recording timezone, and converts device-specific sentinel codes into proper missing values. For instance, the Clouclip uses special numeric codes to indicate when it is in “sleep mode” or when a reading is out of the sensor’s range, rather than recording a normal value. LightLogR identifies -1 (for both distance and lux) as indicating the device’s sleep mode and 204 (for distance) as indicating the object was beyond the measurable range, replacing these with NA and logging their status in separate columns. The import routine also provides an initial summary of the dataset, including start and end times and any irregular sampling intervals or gaps.\nFor the VEET device, data were provided as CSV logs (zipped on Github, due to size). We focused on the ambient light sensor modality first. Using import$VEET(..., modality = \"ALS\"), we extracted the illuminance (Lux) data stream and its timestamps. The raw VEET data similarly can contain irregular intervals or missing periods (e.g., if the device stopped recording or was reset); the import summary flags these issues.\nIrregular intervals and gaps: Both datasets showed irregular timing and missing data, i.e., gaps. Irregular data means that some observations did not align to the nominal sampling interval (e.g., slight timing drift or pauses in recording). For the Clouclip 5-second data, we detected irregular timestamps spanning all but the first and last day of the recording. Handling such irregularities is important because many downstream analyses assume a regular time series. We evaluated strategies to address this, including:\n\nRemoving an initial portion of data if irregularities occur mainly during device start-up.\nRounding all timestamps to the nearest regular interval (5 s in this case).\nAggregating to a coarser time interval (with some loss of temporal resolution).\n\nBased on the import summary and visual inspection of the time gaps, we chose to round the observation times to the nearest 5-second mark, as this addressed the minor offsets without significant data loss. After rounding timestamps, we added an explicit date column for convenient grouping by day.\nWe then generated a summary of missing data for each day. Implicit gaps (intervals where the device should have recorded data but did not) were converted into explicit missing entries using LightLogR’s gap-handling functions. We also removed days that had very little data (in our Clouclip example, days with &lt;1 hour of recordings were dropped) to focus on days with substantial wear time.\nAfter these preprocessing steps, the Clouclip dataset had no irregular timestamps remaining and contained explicit markers for all periods of missing data (e.g., times when the device was off or not worn). The distance and illuminance values were now ready for metric calculations.\nThe VEET illuminance data underwent a similar cleaning procedure. To make the VEET’s 2-second illuminance data more comparable to the Clouclip’s and to reduce computational load, we aggregated the illuminance time series to 5-second intervals. We then inserted explicit missing entries for any gaps and removed days with more than one hour of missing illuminance data. After cleaning, six days of VEET illuminance data with good coverage remained for analysis (see Supplementary Material for details).\nFinally, for spectral analysis, we imported the VEET’s spectral sensor modality, and, for the distance analysis, the time-of-flight modality. This required additional processing: the raw spectral data consists of counts from 10 wavelength-specific channels (approximately 415 nm through 940 nm, plus two broadband clear channels and a dark channel) along with a sensor gain setting. We aggregated the spectral data to 5-minute intervals to focus on broader trends and reduce data volume. Each channel’s counts were normalized by the appropriate gain at each moment, and the two clear channels were averaged. Using a calibration matrix provided by the manufacturer (specific to the spectral sensor model), we reconstructed full spectral power distributions for each 5-minute interval. The end result is a list-column in the dataset where each entry is the estimated spectral irradiance across wavelengths for that time interval. (Detailed spectral preprocessing steps, including the calibration and normalization, are provided in the Supplement.) After spectral reconstruction, the dataset was ready for calculating example spectrum-based metrics.\nSimilarly, the time-of-flight modality contains 256 values per observation, encoding an 8x8 grid of distance and confidence measurements for up to two objects (8x8 grid, times two objects, times distance + confidence column for each object and grid point -&gt; 256 values). These data were pivoted into a long format, where each row contains the distance and confidence data for both objects for a given position in the grid and a given datetime. After pivoting and converting grid positions into a deviation angle from central view, the dataswert was ready to be used for distance analysis.\nThis tutorial will start by importing a Clouclip dataset and providing an overview of the data. The Clouclip export is considerably simpler compared to the VEET export, only containing Distance and Illuminance measurements. The VEET dataset will be imported later for the spectrum related metrics.\n\n# load libraries\nlibrary(LightLogR)\nlibrary(tidyverse)\nlibrary(gt)\n\n\nload(\"data/cleaned/data.RData\")\ncoordinates &lt;- c(29.75, -95.36) #coordinates for Houston, Texas\n#coordinates are important to calculate and visualize photoperiods later"
  },
  {
    "objectID": "index.html#results",
    "href": "index.html#results",
    "title": "Analysis of human visual experience data",
    "section": "\n3 Results",
    "text": "3 Results\n\n3.1 Distance\nWe first examine metrics related to viewing distance, using the processed Clouclip dataset. Many distance-based metrics are computed for each day and then averaged over weekdays, weekends, or across all days. To facilitate this, we define a helper function that will take daily metric values and calculate the mean values for weekdays, weekends, and the overall daily average:\n\nto_mean_daily &lt;- function(data, prefix = \"average_\") {\n  data |&gt; \n    ungroup(Date) |&gt;        # ungroup by days\n    mean_daily(prefix = prefix) |&gt;   # calculate the averages per grouping\n    rename_with(.fn = \\(x) str_replace_all(x,\"_\",\" \")) |&gt;  # remove underscores in names\n    gt()               # format as a gt table for display\n}\n\n\n3.1.1 Total wear time daily\nTotal wear time daily refers to the amount of time the device was actively collecting distance data each day (i.e. the time the device was worn and operational). We compute this by summing all intervals where a valid distance measurement is present, ignoring periods where data are missing or the device was off. The results are shown in Table 3.\n\ndataCC |&gt; \n  durations(Dis) |&gt;                # calculate total duration of data per day\n  to_mean_daily(\"Total wear \")\n\n\nTable 3: Total wear time per day (average across days)\n\n\n\n\n\n\nDate\nTotal wear duration\n\n\n\nClouclip\n\n\nMean daily\n31448s (~8.74 hours)\n\n\nWeekday\n34460s (~9.57 hours)\n\n\nWeekend\n23918s (~6.64 hours)\n\n\n\n\n\n\n\n\n\n\n3.1.2 Duration within distance ranges\nMany myopia-relevant metrics concern the time spent at certain viewing distances (e.g., “near work” vs. intermediate or far distances). We calculate the duration of time spent in specific distance ranges. Table 4 shows the average daily duration of near work, defined here as time viewing at 10–60 cm (a commonly used definition for near-work distance). Table 5 provides a more detailed breakdown across multiple distance bands.\n\n\nDuration of near work\nDuration within distance ranges\n\n\n\n\ndataCC |&gt; \n  filter(Dis &gt;= 10, Dis &lt; 60) |&gt;   # consider only distances in [10, 60) cm\n  durations(Dis) |&gt;                # total duration in that range per day\n  to_mean_daily(\"Near work \")\n\n\nTable 4: Daily duration of near work (10–60 cm viewing distance)\n\n\n\n\n\n\nDate\nNear work duration\n\n\n\nClouclip\n\n\nMean daily\n22586s (~6.27 hours)\n\n\nWeekday\n26343s (~7.32 hours)\n\n\nWeekend\n13192s (~3.66 hours)\n\n\n\n\n\n\n\n\n\n\n\nFirst, we define a set of distance breakpoints and descriptive labels for each range:\n\n# defining distance ranges (in cm)\ndist_breaks &lt;- c(10, 20, 30, 40, 50, 60, 70, 80, 90, 100, Inf)\ndist_labels &lt;- c(\n    \"Extremely near\",          # [10, 20)\n    \"Very near\",               # [20, 30)\n    \"Fairly near\",             # [30, 40)\n    \"Near\",                    # [40, 50)\n    \"Moderately near\",         # [50, 60)\n    \"Near intermediate\",       # [60, 70)\n    \"Intermediate\",            # [70, 80)\n    \"Moderately intermediate\", # [80, 90)\n    \"Far intermediate\",        # [90, 100)\n    \"Far\"                      # [100, Inf)\n  )\n\nNow we cut the distance data into these ranges and compute the daily duration spent in each range:\n\ndataCC |&gt; \n  mutate(Dis_range = cut(Dis, breaks = dist_breaks, labels = dist_labels)) |&gt;  # categorize distances\n  drop_na(Dis_range) |&gt;           # remove intervals with no data\n  group_by(Dis_range, .add = TRUE) |&gt;  # group by distance range (and by day)\n  durations(Dis) |&gt;               # duration per range per day\n  pivot_wider(names_from = Dis_range, values_from = duration) |&gt;  # wide format (ranges as columns)\n  # to_mean_daily(\"\") |&gt; \n  ungroup() |&gt; \n  mean_daily(prefix = \"\") |&gt; \n  pivot_longer(-Date) |&gt; \n  pivot_wider(names_from = Date) |&gt; \n  mutate(name = factor(name, levels = rev(dist_labels))\n  ) |&gt; \n  arrange(name) |&gt; \n  gt() |&gt; \n  fmt_duration(input_units = \"seconds\", output_units = \"minutes\")  # convert seconds to minutes\n\n\nTable 5: Daily duration in each viewing distance range\n\n\n\n\n\n\nname\nMean daily\nWeekday\nWeekend\n\n\n\nFar\n16m\n20m\n5m\n\n\nFar intermediate\n11m\n14m\n2m\n\n\nModerately intermediate\n5m\n6m\n3m\n\n\nIntermediate\n4m\n6m\n1m\n\n\nNear intermediate\n7m\n7m\n8m\n\n\nModerately near\n13m\n16m\n5m\n\n\nNear\n27m\n36m\n5m\n\n\nFairly near\n46m\n60m\n12m\n\n\nVery near\n102m\n128m\n38m\n\n\nExtremely near\n169m\n180m\n141m\n\n\n\n\n\n\n\n\n\nTo visualize this, Figure 1 illustrates the relative proportion of time spent in each distance range:\n\n\n\n\n\n\n\nFigure 1: Percentage of total time spent in each viewing distance range\n\n\n\n\n\n\n\n\n3.1.3 Frequency of continuous near work\nContinuous near-work is typically defined as sustained viewing within a near distance for some minimum duration, allowing only brief interruptions. We use LightLogR’s cluster function to identify episodes of continuous near work. Here we define a near-work episode as viewing distance between 20 cm and 60 cm that lasts at least 30 minutes, with interruptions of up to 1 minute allowed (meaning short breaks ≤1 min do not end the episode). Using extract_clusters() with those parameters, we count how many such episodes occur per day.\nTable 6 summarizes the average frequency of continuous near-work episodes per day, and Figure 2 provides an example visualization of these episodes on the distance time series.\n\ndataCC |&gt; \n  extract_clusters(\n    Dis &gt;= 20 & Dis &lt; 60,            # condition: near-work distance\n    cluster.duration = \"30 mins\",    # minimum duration of a continuous episode\n    interruption.duration = \"1 min\", # maximum gap allowed within an episode\n    drop.empty.groups = FALSE        # keep days with zero episodes in output\n  ) |&gt; \n  summarize_numeric(remove = c(\"start\", \"end\", \"epoch\", \"duration\"),\n                    add.total.duration = FALSE) |&gt;    # count number of episodes per day\n  mean_daily(prefix = \"Frequency of \") |&gt;             # compute daily mean frequency\n  gt() |&gt; fmt_number() \n\n\nTable 6: Frequency of continuous near-work episodes per day\n\n\n\n\n\n\nDate\nFrequency of episodes\n\n\n\nClouclip\n\n\nMean daily\n0.86\n\n\nWeekday\n1.20\n\n\nWeekend\n0.00\n\n\n\n\n\n\n\n\n\n\ndataCC |&gt; \n  add_clusters(\n    Dis &gt;= 20 & Dis &lt; 60,\n    cluster.duration = \"30 mins\",\n    interruption.duration = \"1 min\"\n  ) |&gt; \n  gg_day(y.axis = Dis, y.axis.label = \"Distance (cm)\", geom = \"line\",\n         y.scale = \"identity\", y.axis.breaks = seq(0,100, by = 20)) |&gt; \n  gg_state(state, fill = \"red\") + #add state bands\n  geom_hline(yintercept = c(20, 60), col = \"red\", linetype = \"dashed\") +\n  coord_cartesian(ylim = c(0,100))\nggsave(\"manuscript/figures/Figure2.png\",\n                width = 9,\n                height = 9)\n\n\n\n\n\n\nFigure 2: Example of continuous near-work episodes. Red shaded areas indicate periods of continuous near work (20–60 cm for ≥30 min, allowing ≤1 min interruptions). Black trace is viewing distance over time; red dashed lines mark the 20 cm and 60 cm boundaries.\n\n\n\n\n\n3.1.4 Near-work episodes\nBeyond frequency, we can characterize near-work episodes by their duration and typical viewing distance. This section extracts all near-work episodes (using a shorter minimum duration to capture more routine near-work bouts) and summarizes three aspects: (1) frequency (count of episodes per day), (2) average duration of episodes, and (3) average distance during those episodes. These results are combined in Table 7.\n\ndataCC |&gt; \n  extract_clusters(\n    Dis &gt;= 20 & Dis &lt; 60,\n    cluster.duration = \"5 secs\",    # minimal duration to count as an episode (very short to capture all)\n    interruption.duration = \"20 secs\",\n    drop.empty.groups = FALSE\n  ) |&gt; \n  extract_metric(dataCC, distance = mean(Dis, na.rm = TRUE)) |&gt;  # calculate mean distance during each episode\n  summarize_numeric(remove = c(\"start\", \"end\", \"epoch\"), prefix = \"\",\n                    add.total.duration = FALSE) |&gt;  \n  mean_daily(prefix = \"\") |&gt;    # daily averages for each metric\n  gt() |&gt; fmt_number(c(distance, episodes), decimals = 0) |&gt; #table\n  cols_units(distance = \"cm\")\n\n\nTable 7: Near-work episodes: frequency, mean duration, and mean viewing distance\n\n\n\n\n\n\nDate\nduration\ndistance, cm\nepisodes\n\n\n\nClouclip\n\n\nMean daily\n233s (~3.88 minutes)\n32\n57\n\n\nWeekday\n284s (~4.73 minutes)\n32\n64\n\n\nWeekend\n104s (~1.73 minutes)\n32\n40\n\n\n\n\n\n\n\n\n\n\nIn the above, extract_metric(..., distance = mean(Dis, ...)) computes the mean viewing distance during each episode, and the subsequent summarize_numeric and mean_daily steps derive daily averages of episode count, duration, and distance.\n\n\n3.1.5 Visual breaks\nVisual breaks are a little different, compared to the previous metrics. The difference is that, in this case, the minimum break and the previous episode is important. This leads to a two step process, where we first extract instances of Distance above 100 cm for at least 20 seconds, before we filter for a previous duration of at maximum 20 minutes. Table 8 provides the daily frequency of visual breaks.\n\ndataCC |&gt; \n  extract_clusters(Dis &gt;= 100, #define the condition, greater 100 cm away\n                   cluster.duration = \"20 secs\", #define the minimum duration\n                   return.only.clusters = FALSE, #return non-clusters as well\n                   drop.empty.groups = FALSE #keep all days, even without clusters\n                   ) |&gt; \n  # return only clusters with previous episode lengths of maximum 20 minutes:\n  filter((start - lag(end) &lt;= duration(\"20 mins\")), is.cluster) |&gt; \n  summarize_numeric(remove = c(\"start\", \"end\", \"epoch\", \"is.cluster\", \"duration\"), \n                    prefix = \"\",\n                    add.total.duration = FALSE) |&gt;  #count the number of episodes\n  mean_daily(prefix = \"Daily \") |&gt; #daily means\n  gt() |&gt; fmt_number(decimals = 1) #table\n\n\nTable 8: Frequency of visual breaks\n\n\n\n\n\n\nDate\nDaily episodes\n\n\n\nClouclip\n\n\nMean daily\n5.9\n\n\nWeekday\n6.2\n\n\nWeekend\n5.0\n\n\n\n\n\n\n\n\n\n\ndataCC |&gt; \n    extract_clusters(Dis &gt;= 100, #define the condition, greater 100 cm away\n                   cluster.duration = \"20 secs\", #define the minimum duration\n                   return.only.clusters = FALSE, #return non-clusters as well\n                   drop.empty.groups = FALSE #keep all days, even without clusters\n                   ) |&gt; \n  # return only clusters with previous episode lengths of maximum 20 minutes:\n  filter((start - lag(end) &lt;= duration(\"20 mins\")), is.cluster) %&gt;%\n  add_states(dataCC, ., ) |&gt; \n  gg_day(y.axis = Dis, y.axis.label = \"Distance (cm)\", geom = \"line\") |&gt; \n  gg_photoperiod(coordinates) +\n  geom_point(data = \\(x) filter(x, is.cluster), col = \"red\")\nggsave(\"manuscript/figures/Figure3.png\",\n                width = 9,\n                height = 9)\n\n\n\n\n\n\nFigure 3: Plot of visual breaks (red dots). Black traces show distance measurement data. Grey shaded areas show nighttime between civil dusk and civil dawn\n\n\n\n\n\n3.1.6 Distance with spatial distribution\nThe Clouclip device outputs a singular measure for distance, while the visual environment in natural conditions contains many distances, depending on the solid angle and direction of the measurement. A device like the VEET increases the spatial resolution of these measurements, allowing for more in-depth analyses of the size and position of an object within the field of view. In the case of the VEET, data are collected from an 8x8 measurement grid, spanning 52° vertically and 41° horizontally. Here are exemplary observations from six different days at the same time.\n\nslicer &lt;- function(x){seq(min((x-1)*64+1), max(x*64), by = 1)} #allows to choose an observation\n\n#set visualization parameters\nextras &lt;- list(\n  geom_tile(),\n  scale_fill_viridis_c(direction = -1, limits = c(0, 200),\n                       oob = scales::oob_squish_any),\n  scale_color_manual(values = c(\"black\", \"white\")),\n  theme_minimal(),\n  guides(colour = \"none\"),\n  geom_text(aes(label = (dist1/10) |&gt; round(0), colour = dist1&gt;1000), size = 2.5),\n  coord_fixed(),\n  labs(x = \"X position (°)\", y = \"Y position (°)\", \n       fill = \"Distance (cm)\", alpha = \"Confidence (0-255)\"))\n\ndataVEET3 |&gt; \n  slice(slicer(9530)) |&gt;  #choose a particular observation\n  mutate(dist1 = ifelse(dist1 == 0, Inf, dist1)) |&gt; #replace 0 distances with infinity\n  filter(conf1 &gt;= 0.1 | dist1 == Inf) |&gt; #remove data that has less than 10% confidence\n  ggplot(aes(x=x.pos, y=y.pos, fill = dist1/10))+ extras + #plot the data\n  facet_wrap(~Datetime) #show one plot per day\nggsave(\"manuscript/figures/Figure4.png\",\n                width = 8,\n                height = 6)\n\n\n\n\n\n\nFigure 4: Example observations of the measurement grid at 1:14 p.m. for each measurement day. Text values show distance in cm. Empty grid points show values with low confidence. Zero-distance values were replaced with infinite distance and plotted despite low confidence.\n\n\n\n\nTo use these distance data in the framework shown above for the Clouclip device, a sensible method to condense the data has to be applied. This method has to be chosen based on theoretical assumptions about what a relevant distance within the field of view is. Possible methods include:\n\naverage across all (high confidence) distance values within the grid\nclosest (high confidence) distance within the grid\n(high confidence) values at or around a given grid position, e.g., ±10 degrees around the central view (0°)\n\nMany more options are available based on the richer dataset, e.g., condensation rules based on the number of points in the grid with a given condition, or the variation within the grid.\nWe will demonstrate these three exemplary methods for a single day (2024-06-10), all leading to a data structure akin to the Clouclip, i.e., to be used for further calculation of visual experience metrics.\n\ndataVEET3_part &lt;- #filter one day\ndataVEET3 |&gt;\n  filter_Date(start = \"2024-06-10\", length = \"1 day\")\n\ndataVEET3_condensed &lt;- \ndataVEET3_part |&gt; \n  group_by(Datetime, .add = TRUE) |&gt; #group additionally by every observation\n  filter(conf1 &gt;= 0.1) |&gt; #remove data with low confidence\n  summarize(\n    distance_mean = mean(dist1), #average across all distance values,\n    distance_min = min(dist1), #closest across all distance values,\n    distance_central = mean(dist1[between(x.pos, -10,10) & between(y.pos, -10,10)]), #central distance\n    n = n(), #number of (valid) grid points\n    .groups = \"drop_last\"\n  )\n\ndataVEET3_condensed |&gt; \n  aggregate_Datetime(\"15 mins\", numeric.handler = \\(x) mean(x, na.rm = TRUE)) |&gt; #create 15 minute data\n  remove_partial_data(by.date = TRUE) |&gt; #remove midnight data points\n  pivot_longer(contains(\"distance\"), #put all methods into a long file for plotting\n               names_to = c(\".value\", \"method\"),\n    names_pattern = \"(distance)_(mean|min|max|central)\"\n    ) |&gt;\n  gg_day(y.axis = distance/10, \n         geom = \"line\", \n         aes_col = method,\n         group = method,\n         linewidth = 1, \n         alpha = 0.75, \n         y.scale = \"identity\",\n         y.axis.breaks = seq(0,150, by = 20), \n         y.axis.label = \"Distance (cm)\"\n         )\nggsave(\"manuscript/figures/Figure5.png\",\n                width = 7,\n                height = 4)\n\n\n\n\n\n\nFigure 5: Comparison of condensation methods for spatial grid of distance measurements. The lines represent an average across all data points (yellow), the minimum distance (grey), or the central 10° (blue). Data points with confidence less than 10% were removed prior to calculation.\n\n\n\n\nAs can be seen in Figure 5, while the overall pattern is similar regardless of the used method, there are notable differences between the methods, which will consequently affect downstream analyses. Most importantly, the process of condensation has to be well documented and reproducible, as shown above. Any of these data could now be used to calculate the frequency of continuous near work, visual breaks, or near-work episodes as described above.\n\n3.2 Light\nThe Clouclip illuminance data in our example are extremely low (the device was mostly used in dim conditions), which would make certain light exposure summaries trivial or not meaningful. To better illustrate light exposure metrics, we turn to the exemplary VEET device’s illuminance data, which capture a broader range of lighting conditions. We import the VEET ambient light data (already preprocessed to have regular 5-second intervals as described above) and briefly examine its distribution.\nIlluminance distribution: The illuminance values from the Clouclip were almost always near zero, while the VEET data include outdoor exposures up to several thousand lux. The contrast is evident from comparing histograms of the two datasets’ lux values (Clouclip vs. VEET). The VEET illuminance histogram (see Figure 7) shows a heavily skewed distribution with a spike at zero (indicating many intervals of complete darkness or the sensor being covered) and a long tail extending to very high lux values. Such zero-inflated and skewed data are common in wearable light measurements (Zauner, Guidolin, and Spitschan).\n\n\n\n\n\n\n\n\nFigure 6: Histogram of illuminance values from the Clouclip dataset (5-second data). The values are very low and are typical of indoor conditions.\n\n\n\n\n\n\n\n\n\n\n\nFigure 7: Histogram of illuminance values from the VEET dataset (aggregated to 5 s). Note the logarithmic x-axis: the distribution is highly skewed with many low values (including zeros) and a long tail of high lux readings.\n\n\n\nAfter confirming that the VEET data cover a broad dynamic range of lighting, we proceed with calculating light exposure metrics. (The VEET data had been cleaned for gaps and irregularities as described earlier; see Supplement 1 for the gap summary table.)\n\n3.2.1 Average light exposure\nA basic metric is the average illuminance over the day. Table 9 shows the mean illuminance (in lux) for weekdays, weekends, and the overall daily mean, calculated directly from the raw lux values.\n\ndataVEET |&gt; \n  select(Id, Date, Datetime, Lux) |&gt; \n  summarize_numeric(prefix = \"mean \", remove = c(\"Datetime\")) |&gt; \n  to_mean_daily() |&gt;             # compute mean for weekday, weekend, all days\n  fmt_number(decimals = 1) |&gt; \n  cols_hide(`average episodes`) |&gt;  # hide an irrelevant column (episodes count)\n  cols_label(`average mean Lux` = \"Mean photopic illuminance (lx)\")\n\n\nTable 9: Mean light exposure (illuminance) per day\n\n\n\n\n\n\nDate\nMean photopic illuminance (lx)\n\n\n\nVEET\n\n\nMean daily\n304.1\n\n\nWeekday\n357.8\n\n\nWeekend\n169.8\n\n\n\n\n\n\n\n\n\nHowever, because illuminance data tend to be extremely skewed and contain many zero values (periods of darkness), the arithmetic mean can be misleading. A common approach is to apply a logarithmic transform to illuminance before averaging, which down-weights extreme values and accounts for the multiplicative nature of light intensity effects. LightLogR provides helper functions log_zero_inflated() and its inverse exp_zero_inflated() to handle log-transformation when zeros are present (by adding a small offset before log, and back-transforming after averaging). Using this approach, we recompute the daily mean illuminance. The results in Table 10 show that the log-transformed mean (back-transformed to lux) is much lower, reflecting the fact that for much of the time illuminance was near zero. This transformed mean is often more representative of typical exposure for skewed data.\n\ndataVEET |&gt; \n  select(Id, Date, Datetime, Lux) |&gt; \n  mutate(Lux = Lux |&gt; log_zero_inflated()) |&gt;        # log-transform with zero handling\n  summarize_numeric(prefix = \"mean \", remove = c(\"Datetime\")) |&gt; \n  mean_daily(prefix = \"\") |&gt;                         # get daily mean of log-lux\n  mutate(`mean Lux` = `mean Lux` |&gt; exp_zero_inflated()) |&gt;  # back-transform to lux\n  gt() |&gt; fmt_number(decimals = 1) |&gt; cols_hide(episodes) |&gt; \n  cols_label(`mean Lux` = \"Mean photopic illuminance (lx)\")\n\n\nTable 10: Mean light exposure per day (after logarithmic transformation to account for zero inflation and skewness)\n\n\n\n\n\n\nDate\nMean photopic illuminance (lx)\n\n\n\nVEET\n\n\nMean daily\n6.3\n\n\nWeekday\n7.9\n\n\nWeekend\n3.5\n\n\n\n\n\n\n\n\n\n\n3.2.2 Duration in high-light (outdoor) conditions\nAnother important metric is the amount of time spent under bright light, often used as a proxy for outdoor exposure. We define thresholds corresponding to outdoor light levels (e.g. 1000 lx and above). Here, we categorize each 5-second interval of illuminance into bands: Outdoor bright (≥1000 lx), Outdoor very bright (≥2000 lx), and Outdoor extremely bright (≥3000 lx). We then sum the duration in each category per day. We first create a categorical variable for illuminance range:\n\n# Define outdoor illuminance thresholds (in lux)\nout_breaks &lt;- c(1e3, 2e3, 3e3, Inf)\nout_labels &lt;- c(\n    \"Outdoor bright\",          # [1000, 2000) lx\n    \"Outdoor very bright\",     # [2000, 3000) lx\n    \"Outdoor extremely bright\" # [3000, ∞) lx\n  )\n\ndataVEET &lt;- dataVEET |&gt; \n  mutate(Lux_range = cut(Lux, breaks = out_breaks, labels = out_labels))\n\nNow we compute the mean daily duration spent in each of these outdoor light ranges (Table 11):\n\ndataVEET |&gt; \n  drop_na(Lux_range) |&gt; \n  group_by(Lux_range, .add = TRUE) |&gt; \n  durations(Lux) |&gt;                            # total duration per range per day\n  pivot_wider(names_from = Lux_range, values_from = duration) |&gt; \n  to_mean_daily(\"\") |&gt; \n  fmt_duration(input_units = \"seconds\", output_units = \"minutes\")\n\n\nTable 11: Average daily duration in outdoor-equivalent light conditions\n\n\n\n\n\n\nDate\nOutdoor bright\nOutdoor very bright\nOutdoor extremely bright\n\n\n\nVEET\n\n\nMean daily\n24m\n32m\n55m\n\n\nWeekday\n29m\n41m\n65m\n\n\nWeekend\n10m\n10m\n30m\n\n\n\n\n\n\n\n\n\nIt is also informative to visualize when these high-light conditions occurred. Figure 8 shows a timeline plot with periods of outdoor-level illuminance highlighted in color. In this example, violet denotes ≥1000 lx, green ≥2000 lx, and yellow ≥3000 lx. Grey shading indicates nighttime (from civil dusk to dawn) for context.\n\ndataVEET |&gt; \n  gg_day(y.axis = Lux, y.axis.label = \"Photopic illuminance (lx)\", geom = \"line\", jco_color = FALSE) |&gt; \n  gg_state(Lux_range, aes_fill = Lux_range, alpha = 0.75) |&gt; \n  gg_photoperiod(coordinates) +\n  scale_fill_viridis_d() +\n  labs(fill = \"Illuminance range\") +\n  theme(legend.position = \"bottom\")\nggsave(\"manuscript/figures/Figure8.png\",\n                width = 9,\n                height = 9)\n\n\n\n\n\n\nFigure 8: Outdoor light exposure over time. Colored bands indicate periods when illuminance exceeded outdoor thresholds: violet for ≥1000 lx, green for ≥2000 lx, and yellow for ≥3000 lx. Grey shaded regions denote night (from civil dusk to dawn).\n\n\n\n\n\n3.2.3 Frequency of transitions from indoor to outdoor light\nWe next consider how often the subject moved from an indoor light environment to an outdoor-equivalent environment. We operationally define an “outdoor transition” as a change from &lt;1000 lx to ≥1000 lx. Using the cleaned VEET data, we extract all instances where illuminance crosses that threshold from below to above.\nTable 12 shows the average number of such transitions per day. Note that if data are recorded at a fine temporal resolution (5 s here), very brief excursions above 1000 lx could count as transitions and inflate this number. Indeed, the initial count is fairly high, reflecting fleeting spikes above 1000 lx that might not represent meaningful outdoor exposures.\n\ndataVEET |&gt; \n  extract_states(Outdoor, Lux &gt;= 1000, group.by.state = FALSE) |&gt;  # label each interval as Outdoor (Lux≥1000) or not\n  filter(!lead(Outdoor) & Outdoor) |&gt;   # find instances where the previous interval was \"indoor\" and current is \"outdoor\"\n  summarize_numeric(prefix = \"mean \",\n    remove = c(\"Datetime\", \"Outdoor\", \"start\", \"end\", \"duration\"),\n    add.total.duration = FALSE) |&gt; \n  mean_daily(prefix = \"\") |&gt; \n  gt() |&gt; fmt_number(episodes, decimals = 0) |&gt; \n  fmt_duration(`mean epoch`, input_units = \"seconds\", output_units = \"seconds\")\n\n\nTable 12: Average daily count of transitions from indoor (&lt;1000 lx) to outdoor (≥1000 lx) lighting when looking at 5-second epochs\n\n\n\n\n\n\nDate\nmean epoch\nepisodes\n\n\n\nVEET\n\n\nMean daily\n5s\n64\n\n\nWeekday\n5s\n72\n\n\nWeekend\n5s\n46\n\n\n\n\n\n\n\n\n\nTo obtain a more meaningful measure, we can require that the outdoor state persists for some minimum duration to count as a true transition (filtering out momentary fluctuations around the 1000 lx mark). For example, we can require that once ≥1000 lx is reached, it continues for at least 5 minutes (allowing short interruptions up to 20 s). Table 13 applies this criterion, resulting in a lower, more plausible transition count.\n\ndataVEET |&gt; \n  extract_clusters(Lux &gt;= 1000,\n                   cluster.duration = \"5 min\", \n                   interruption.duration = \"20 secs\",\n                   return.only.clusters = FALSE,\n                   drop.empty.groups = FALSE) |&gt; \n  filter(!lead(is.cluster) & is.cluster) |&gt; \n  summarize_numeric(prefix = \"mean \",\n    remove = c(\"Datetime\", \"start\", \"end\", \"duration\"),\n    add.total.duration = FALSE) |&gt; \n  mean_daily(prefix = \"\") |&gt; \n  gt() |&gt; fmt_number(episodes, decimals = 0)\n\n\nTable 13: Daily indoor-to-outdoor transition count (requiring ≥5 min duration of ≥1000 lx to count)\n\n\n\n\n\n\nDate\nmean epoch\nepisodes\n\n\n\nVEET\n\n\nMean daily\n5s\n5\n\n\nWeekday\n5s\n6\n\n\nWeekend\n5s\n4\n\n\n\n\n\n\n\n\n\n\n3.2.4 Longest sustained bright-light period\nThe final light exposure metric we illustrate is the longest continuous period above a certain illuminance threshold (often termed Longest Period Above Threshold, e.g. PAT1000 for 1000 lx). This gives a sense of the longest outdoor exposure in a day. Along with it, one might report the total duration above that threshold in the day (TAT1000). While we could derive these from the earlier analyses, LightLogR provides dedicated metric functions for such calculations, which can compute multiple related metrics at once.\nUsing the function period_above_threshold() for PAT and duration_above_threshold() for TAT, we calculate both metrics for the 1000 lx threshold. Table 14 shows the mean of these metrics across days (i.e., average longest bright period and average total bright time per day).\n\ndataVEET |&gt; \n  summarize(\n    period_above_threshold(Lux, Datetime, threshold = 1000, na.rm = TRUE, as.df = TRUE),\n    duration_above_threshold(Lux, Datetime, threshold = 1000, na.rm = TRUE, as.df = TRUE),\n    .groups = \"keep\"\n  ) |&gt; \n  to_mean_daily(\"\")\n\n\nTable 14: Longest period and total duration above 1000 lx (PAT1000 and TAT1000)\n\n\n\n\n\n\nDate\nperiod above 1000\nduration above 1000\n\n\n\nVEET\n\n\nMean daily\n1987s (~33.12 minutes)\n6709s (~1.86 hours)\n\n\nWeekday\n2501s (~41.68 minutes)\n8164s (~2.27 hours)\n\n\nWeekend\n702s (~11.7 minutes)\n3070s (~51.17 minutes)\n\n\n\n\n\n\n\n\n\n\n3.3 Spectrum\nThe VEET device’s spectral sensor provides rich data beyond simple lux values, but it requires reconstruction of the actual light spectrum from raw sensor counts. We processed the spectral sensor data in order to compute two example spectrum-based metrics. Detailed data import, normalization, and spectral reconstruction steps are given in Supplement 1; here we present the resulting metrics. Briefly, the VEET’s spectral sensor recorded counts in ten wavelength bands (roughly 415 nm to 910 nm), plus a Dark and a Clear channel3. After normalizing by sensor gain and applying the calibration matrix, we obtained an estimated spectral irradiance distribution for each 5-minute interval in the recording. With these reconstructed spectra, we can derive novel metrics that consider spectral content of the light.\n\n\n\n\n\n\nNote\n\n\n\nSpectrum-based metrics in wearable data are relatively new and less established compared to distance or broadband light metrics. The following examples illustrate potential uses of spectral data in a theoretical sense, which can be adapted as needed for specific research questions.\n\n\n\n3.3.1 Ratio of short- vs. long-wavelength light\nOur first spectral metric is the ratio of short-wavelength light to long-wavelength light, which is relevant, for example, in assessing the blue-light content of exposure. We define “short” wavelengths as 400–500 nm and “long” as 600–700 nm. Using the list-column of spectra in our dataset, we integrate each spectrum over these ranges (using spectral_integration()), and then compute the ratio short/long for each time interval. We then summarize these ratios per day.\n\ndataVEET &lt;- dataVEET2 |&gt; \n  select(Id, Date, Datetime, Spectrum) |&gt;    # focus on ID, date, time, and spectrum\n  mutate(\n    short = Spectrum |&gt; map_dbl(spectral_integration, wavelength.range = c(400, 500)),\n    long  = Spectrum |&gt; map_dbl(spectral_integration, wavelength.range = c(600, 700)),\n    `sl ratio` = ifelse(is.nan(short / long), NA, short / long)   # compute short-to-long ratio\n  )\n\nTable 15 shows the average short/long wavelength ratio, averaged over each day (and then as weekday/weekend means if applicable). In this dataset, the values give an indication of the spectral balance of the light the individual was exposed to (higher values mean relatively more short-wavelength content).\n\ndataVEET |&gt; \n  summarize_numeric(prefix = \"\", remove = c(\"Datetime\", \"Spectrum\")) |&gt; \n  # mean_daily(prefix = \"\") |&gt;\n  gt() |&gt; \n  fmt_number(decimals = 1, scale_by = 1000) |&gt;\n  fmt_number(`sl ratio`, decimals = 3) |&gt;\n  cols_hide(episodes)\n\n\nTable 15: Average (mW/m²) and ratio of short-wavelength (400–500 nm) to long-wavelength (600–700 nm) light\n\n\n\n\n\n\nDate\nshort\nlong\nsl ratio\n\n\n\nVEET\n\n\n2025-06-18\n44.1\n42.2\n0.524\n\n\n2025-06-20\n69.2\n49.1\n0.336\n\n\n\n\n\n\n\n\n\n\n3.3.2 Short-wavelength light at specific times of day\nThe second spectral example examines short-wavelength light exposure as a function of time of day. Certain studies might be interested in, for instance, blue-light exposure during midday versus morning or night. We demonstrate three approaches: (a) filtering the data to a specific local time window, and (b) aggregating by hour of day to see a daily profile of short-wavelength exposure. Additionally, we (c) look at differences between day and night periods.\n\n\nLocal morning exposure\nHourly profile across the day\nDay vs. night (photoperiod)\n\n\n\nTable 16 isolates the time window between 7:00 and 11:00 each day and computes the average short-wavelength irradiance in that interval. This represents a straightforward query: “How much blue light does the subject get in the morning on average?”\n\ndataVEET |&gt; \n  filter_Time(start = \"7:00:00\", end = \"11:00:00\") |&gt;    # filter data to local 7am–11am\n  select(-c(Spectrum, long, `sl ratio`, Time, Datetime)) |&gt;\n  summarize_numeric(prefix = \"\") |&gt; \n  # mean_daily(prefix = \"\") |&gt; \n  gt() |&gt; fmt_number(short, scale_by = 1000) |&gt; \n  cols_label(short = \"Short-wavelength irradiance (mW/m²)\") |&gt; \n  cols_hide(episodes)\n\n\nTable 16: Average short-wavelength light (400–500 nm) exposure between 7:00 and 11:00 each day\n\n\n\n\n\n\nDate\nShort-wavelength irradiance (mW/m²)\n\n\n\nVEET\n\n\n2025-06-18\n5.44\n\n\n2025-06-20\n0.95\n\n\n\n\n\n\n\n\n\n\n\nTo visualize short-wavelength exposure over the course of a day, we aggregate the data into hourly bins. We cut the timeline into 1-hour segments (using local time), compute the mean short-wavelength irradiance in each hour for each day. Figure 9 shows the resulting diurnal profile, with short-wavelength exposure expressed as a fraction of the daily maximum for easier comparison.\n\n# Prepare hourly binned data\ndataVEETtime &lt;- dataVEET |&gt;\n  cut_Datetime(unit = \"1 hour\", type = \"floor\", group_by = TRUE) |&gt;  # bin timestamps by hour\n  select(-c(Spectrum, long, `sl ratio`, Datetime)) |&gt;\n  summarize_numeric(prefix = \"\") |&gt; \n  add_Time_col(Datetime.rounded)  |&gt;   # add a Time column (hour of day)\n  mutate(rel_short = short / max(short))\n\n#creating the plot\ndataVEETtime |&gt; \n  ggplot(aes(x=Time, y = rel_short)) +\n  geom_col(aes(fill = factor(Date)), position = \"dodge\") +\n  ggsci::scale_fill_jco() +\n  theme_minimal() +\n  labs(y = \"Normalized short-wavelength irradiance\", \n       x = \"Local time (HH:MM)\",\n       fill = \"Date\") + \n  scale_y_continuous(labels = scales::label_percent()) +\n  scale_x_time(labels = scales::label_time(format = \"%H:%M\"))\nggsave(\"manuscript/figures/Figure9.png\",\n                width = 5,\n                height = 4)\n\n\n\n\n\n\nFigure 9: Diurnal profile of short-wavelength light exposure. Each bar represents the average short-wavelength irradiance at that hour of the day (0–23 h), normalized to the daily maximum.\n\n\n\n\n\n\nFinally, we compare short-wavelength exposure during daytime vs. nighttime. Using civil dawn and dusk information (based on geographic coordinates, here set for Houston, TX, USA), we label each measurement as day or night and then compute the total short-wavelength exposure in each period. Table 17 summarizes the daily short-wavelength dose received during the day vs. during the night.\n\ndataVEET |&gt;\n  select(-c(Spectrum, long, `sl ratio`)) |&gt;\n  add_photoperiod(coordinates) |&gt; \n  group_by(photoperiod.state, .add = TRUE) |&gt; \n  summarize_numeric(prefix = \"\", \n                    remove = c(\"dawn\", \"dusk\", \"photoperiod\", \"Datetime\")) |&gt; \n  group_by(Id, photoperiod.state) |&gt; \n  # mean_daily(prefix = \"\") |&gt; \n  select(-episodes) |&gt; \n  pivot_wider(names_from =photoperiod.state, values_from = short) |&gt; \n  gt() |&gt; fmt_number(scale_by = 1000, decimals = 1)\n\n\nTable 17: Short wavelength light exposure (mW/m²) during the day and at night\n\n\n\n\n\n\nDate\nday\nnight\n\n\n\nVEET\n\n\n2025-06-18\n73.9\n2.6\n\n\n2025-06-20\n112.0\n1.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn the above, add_photoperiod(coordinates) is used as a convenient way to add columns to the data frame, indicating for each timestamp whether it was day or night, given the latitude/longitude."
  },
  {
    "objectID": "index.html#discussion-and-conclusion",
    "href": "index.html#discussion-and-conclusion",
    "title": "Analysis of human visual experience data",
    "section": "\n4 Discussion and conclusion",
    "text": "4 Discussion and conclusion\nThis tutorial demonstrates a standardized, step-by-step pipeline to calculate a variety of visual experience metrics. We illustrated how a combination of LightLogR functions and tidyverse workflows can yield clear and reproducible analyses for wearable device data. While the full pipeline is detailed, each metric is computed through a dedicated sequence of well-documented steps. By leveraging LightLogR’s framework alongside common data analysis approaches, the process remains transparent and relatively easy to follow. The overall goal is to make analysis transparent (with open-source functions), accessible (through thorough documentation, tutorials, and human-readable function naming, all under an MIT license), robust (the package includes ~900 unit tests and continuous integration with bug tracking on GitHub), and community-driven (open feature requests and contributions via GitHub).\nEven with standardized pipelines, researchers must still make and document many decisions during data cleaning, time-series handling, and metric calculations — especially for complex metrics that involve grouping data in multiple ways (for example, grouping by distance range as well as by duration for cluster metrics). We have highlighted these decision points in the tutorial (such as how to handle irregular intervals, choosing thresholds for “near” distances or “outdoor” light, and deciding on minimum durations for sustained events). Explicitly considering and reporting these choices is important for reproducibility and for comparing results across studies.\nThe broad set of features in LightLogR — ranging from data import and cleaning tools (for handling time gaps and irregularities) to visualization functions and metric calculators — make it a powerful toolkit for visual experience research. Our examples spanned circadian-light metrics and myopia-related metrics, demonstrating the versatility of a unified analysis approach. By using community-supported tools and workflows, researchers in vision science, chronobiology, myopia, and related fields can reduce time spent on low-level data wrangling and focus more on interpreting results and advancing scientific understanding."
  },
  {
    "objectID": "index.html#sessioninfo",
    "href": "index.html#sessioninfo",
    "title": "Analysis of human visual experience data",
    "section": "\n5 Session info",
    "text": "5 Session info\n\nsessionInfo()\n\nR version 4.5.1 (2025-06-13)\nPlatform: x86_64-pc-linux-gnu\nRunning under: Ubuntu 24.04.2 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 \nLAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.26.so;  LAPACK version 3.12.0\n\nlocale:\n [1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8       \n [4] LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8   \n [7] LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C          \n[10] LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C   \n\ntime zone: UTC\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nother attached packages:\n [1] gt_1.0.0        lubridate_1.9.4 forcats_1.0.0   stringr_1.5.1  \n [5] dplyr_1.1.4     purrr_1.0.4     readr_2.1.5     tidyr_1.3.1    \n [9] tibble_3.3.0    ggplot2_3.5.2   tidyverse_2.0.0 LightLogR_0.9.2\n\nloaded via a namespace (and not attached):\n [1] sass_0.4.10        generics_0.1.4     renv_1.1.4         class_7.3-23      \n [5] xml2_1.3.8         KernSmooth_2.23-26 stringi_1.8.7      hms_1.1.3         \n [9] digest_0.6.37      magrittr_2.0.3     evaluate_1.0.4     grid_4.5.1        \n[13] timechange_0.3.0   RColorBrewer_1.1-3 fastmap_1.2.0      jsonlite_2.0.0    \n[17] e1071_1.7-16       DBI_1.2.3          viridisLite_0.4.2  scales_1.4.0      \n[21] textshaping_1.0.1  cli_3.6.5          rlang_1.1.6        units_0.8-7       \n[25] cowplot_1.1.3      withr_3.0.2        yaml_2.3.10        tools_4.5.1       \n[29] tzdb_0.5.0         vctrs_0.6.5        R6_2.6.1           proxy_0.4-27      \n[33] classInt_0.4-11    lifecycle_1.0.4    htmlwidgets_1.6.4  ragg_1.4.0        \n[37] pkgconfig_2.0.3    pillar_1.10.2      gtable_0.3.6       Rcpp_1.0.14       \n[41] glue_1.8.0         sf_1.0-21          systemfonts_1.2.3  xfun_0.52         \n[45] tidyselect_1.2.1   knitr_1.50         farver_2.1.2       htmltools_0.5.8.1 \n[49] rmarkdown_2.29     ggsci_3.2.0        labeling_0.4.3     suntools_1.0.1    \n[53] compiler_4.5.1"
  },
  {
    "objectID": "index.html#statements",
    "href": "index.html#statements",
    "title": "Analysis of human visual experience data",
    "section": "\n6 Statements",
    "text": "6 Statements\n\n6.1 Data availability statement\nAll data and code in this tutorial and Supplement 1 are available from the GitHub repository: https://github.com/tscnlab/ZaunerEtAl_JVis_2025/, archived on Zenodo: https://doi.org/10.5281/zenodo.16566014 under a MIT license (data under CC-BY license).\n\n6.2 Funding statement\nJZ’s position is funded by the MeLiDos project. The project has received funding from the European Partnership on Metrology (22NRM05 MeLiDos), co-financed from the European Union’s Horizon Europe Research and Innovation Programme and by the Participating States. Views and opinions expressed are however those of the author(s) only and do not necessarily reflect those of the European Union or EURAMET. Neither the European Union nor the granting authority can be held responsible for them. JZ, LAO, and MS received research funding from Reality Labs Research. The funders had no role in study design, data collection and analysis, decision to publish or preparation of the manuscript.\n\n6.3 Conflict of interest statement\nJZ declares the following potential conflict of interest in the past five years (2021-2025). Funding: Received research funding from Reality Labs Research.\nAN declares the following potential conflicts of interest in the past five years (2021-2025). none\nLAO declares the following potential conflict of interest in the past five years (2021-2025). Consultancy: Zeiss, Alcon, EssilorLuxottica; Research support: Topcon, Meta, LLC; Patents: US 11375890 B2\nMS declares the following potential conflicts of interest in the past five years (2021–2025). Academic roles: Member of the Board of Directors, Society of Light, Rhythms, and Circadian Health (SLRCH); Chair of Joint Technical Committee 20 (JTC20) of the International Commission on Illumination (CIE); Member of the Daylight Academy; Chair of Research Data Alliance Working Group Optical Radiation and Visual Experience Data. Remunerated roles: Speaker of the Steering Committee of the Daylight Academy; Ad-hoc reviewer for the Health and Digital Executive Agency of the European Commission; Ad-hoc reviewer for the Swedish Research Council; Associate Editor for LEUKOS, journal of the Illuminating Engineering Society; Examiner, University of Manchester; Examiner, Flinders University; Examiner, University of Southern Norway. Funding: Received research funding and support from the Max Planck Society, Max Planck Foundation, Max Planck Innovation, Technical University of Munich, Wellcome Trust, National Research Foundation Singapore, European Partnership on Metrology, VELUX Foundation, Bayerisch-Tschechische Hochschulagentur (BTHA), BayFrance (Bayerisch-Französisches Hochschulzentrum), BayFOR (Bayerische Forschungsallianz), and Reality Labs Research. Honoraria for talks: Received honoraria from the ISGlobal, Research Foundation of the City University of New York and the Stadt Ebersberg, Museum Wald und Umwelt. Travel reimbursements: Daimler und Benz Stiftung. Patents: Named on European Patent Application EP23159999.4A (“System and method for corneal-plane physiologically-relevant light logging with an application to personalized light interventions related to health and well-being”). With the exception of the funding source supporting this work, M.S. declares no influence of the disclosed roles or relationships on the work presented herein.\n\n6.4 Statement of generative AI and AI-assisted technologies in the writing process\nThe authors used ChatGPT during the preparation of this work. After using this tool, the authors reviewed and edited the content as needed and take full responsibility for the content of the publication.\nUse of AI in contributor roles 4: Conceptualization: no Data curation: no Formal analysis: bug fixing Methodology: no Software: bug fixing Validation: no Visualization: tweaking of options Writing – original draft: abstract refinement Writing – review & editing: improve readability and language"
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Analysis of human visual experience data",
    "section": "Footnotes",
    "text": "Footnotes\n\nFunctions from LightLogR are presented as links to the function documentation. General analysis functions (from package dplyr) are presented as normal text.↩︎\nThis deviates from the common definition of luminous exposure, which is the sum of illuminance measurements scaled to hourly observation intervals↩︎\nNote that older firmware versions contained two Clear channels and the highest spectral channel was indicated as 940 nm. Data collected with this early firmware version are not suitable for spectral reconstruction in the context of research projects.↩︎\nBased on the CRediT taxonomy. Funding acquisition, investigation, project administration, resources, and supervision were deemed irrelevant in this context and thus removed.↩︎"
  },
  {
    "objectID": "supplement.html",
    "href": "supplement.html",
    "title": "Supplement 1",
    "section": "",
    "text": "This supplementary document provides a detailed, step-by-step tutorial on importing and preprocessing raw data from two wearable devices: Clouclip and VEET. We describe the structure of the raw datasets recorded by each device and explain how to parse these data, specify time zones, handle special sentinel values, clean missing observations, regularize timestamps to fixed intervals, and aggregate data as needed. All original R code from the main tutorial is preserved here for transparency, with additional guidance intended for a broad research audience. We demonstrate how to detect gaps and irregular sampling, convert implicit missing periods into explicit missing values, and address device-specific quirks such as the Clouclip’s use of sentinel codes for “sleep mode” and “out of range” readings. Special procedures for processing the VEET’s rich spectral data (e.g. normalizing sensor counts and reconstructing full spectra from multiple sensor channels) are also outlined. Finally, we show how to save the cleaned datasets from both devices into a single R data file for downstream analysis. This comprehensive walkthrough is designed to ensure reproducibility and to assist researchers in understanding and adapting the data pipeline for their own visual experience datasets."
  },
  {
    "objectID": "supplement.html#abstract",
    "href": "supplement.html#abstract",
    "title": "Supplement 1",
    "section": "",
    "text": "This supplementary document provides a detailed, step-by-step tutorial on importing and preprocessing raw data from two wearable devices: Clouclip and VEET. We describe the structure of the raw datasets recorded by each device and explain how to parse these data, specify time zones, handle special sentinel values, clean missing observations, regularize timestamps to fixed intervals, and aggregate data as needed. All original R code from the main tutorial is preserved here for transparency, with additional guidance intended for a broad research audience. We demonstrate how to detect gaps and irregular sampling, convert implicit missing periods into explicit missing values, and address device-specific quirks such as the Clouclip’s use of sentinel codes for “sleep mode” and “out of range” readings. Special procedures for processing the VEET’s rich spectral data (e.g. normalizing sensor counts and reconstructing full spectra from multiple sensor channels) are also outlined. Finally, we show how to save the cleaned datasets from both devices into a single R data file for downstream analysis. This comprehensive walkthrough is designed to ensure reproducibility and to assist researchers in understanding and adapting the data pipeline for their own visual experience datasets."
  },
  {
    "objectID": "supplement.html#introduction",
    "href": "supplement.html#introduction",
    "title": "Supplement 1",
    "section": "1 Introduction",
    "text": "1 Introduction\nWearable sensors like the Clouclip and the Visual Environment Evaluation Tool (VEET) produce high-dimensional time-series data on viewing distance and light exposure. Proper handling of these raw data is essential before any analysis of visual experience metrics. In the main tutorial, we introduced an analysis pipeline using the open-source R package LightLogR (Zauner, Hartmeyer, and Spitschan 2025) to calculate various distance and light exposure metrics. Here, we present a full account of the data import and preparation steps as a supplement to the methods, with an emphasis on clarity for researchers who may be less familiar with data processing in R.\nWe use example datasets from a Clouclip device (Wen et al. 2021, 2020) and from a VEET device (Sah, Narra, and Ostrin 2025) (both provided in the accompanying repository). The Clouclip is a glasses-mounted sensor that records working distance (distance from eyes to object, in cm) and ambient illuminance (in lux) at 5-second intervals. The VEET is a head-mounted multi-modal sensor that logs ambient light and spectral information (along with other data like motion and distance via a depth sensor) - in this exemplary case at 2-second intervals. A single week of continuous data illustrates the contrast in complexity: approximately 1.6 MB for the Clouclip’s simple two-column output versus up to 270 MB for the VEET’s multi-channel output (due to its higher sampling rate and richer sensor modalities).\nIn the following sections, we detail how these raw data are structured and how to import and preprocess them using LightLogR. We cover device-specific considerations such as file format quirks and sensor range limitations, as well as general best practices like handling missing timestamps and normalizing sensor readings. All code blocks can be executed in R (with the required packages loaded) to reproduce the cleaning steps. The end result will be clean, regularized datasets (dataCC for Clouclip, dataVEET for VEET light data, and dataVEET2 for VEET spectral data) ready for calculating visual experience metrics. We conclude by saving these cleaned datasets into a single file for convenient reuse."
  },
  {
    "objectID": "supplement.html#clouclip-data-raw-structure-and-import",
    "href": "supplement.html#clouclip-data-raw-structure-and-import",
    "title": "Supplement 1",
    "section": "2 Clouclip Data: Raw Structure and Import",
    "text": "2 Clouclip Data: Raw Structure and Import\nThe Clouclip device exports its data as a text file (not a true Excel file despite sometimes using an .xls extension), which is actually tab-separated values. Each record corresponds to one timestamped observation (nominally every 5 seconds) and includes two measured variables: distance and illuminance. In the sample dataset (Sample_Clouclip.csv provided), the columns are:\n\nDate – the date and time of the observation (in the device’s local time, here one week in 2021).\nDis – the viewing distance in centimeters.\nLux – the ambient illuminance in lux.\n\nFor example, a raw data line might look like:\n2021-07-01 08:00:00 45  320\nindicating that at 2021-07-01 08:00:00 local time, the device recorded a working distance of 45 cm and illuminance of 320 lx. The Clouclip uses special sentinel values1 in these measurement columns to denote certain device states. Specifically, a distance (Dis) value of 204 is a code meaning the object is out of the sensor’s range, and a value of -1 in either Dis or Lux indicates the device was in sleep mode (not actively recording). During normal operation, distance measurements are limited by the device’s range, and illuminance readings are positive lux values. Any sentinel codes in the raw file need to be handled appropriately, as described below.\nWe will use LightLogR’s built-in import function for Clouclip, which automatically reads the file, parses the timestamps, and converts sentinel codes into a separate status annotation. To begin, we load the necessary libraries and import the raw Clouclip dataset:\n\n# Load required packages\nlibrary(tidyverse)\nlibrary(LightLogR)\nlibrary(gt)\nlibrary(downlit) #not used, but important for code-linking feature\n\n\n# Define file path and time zone\npath &lt;- \"data/Sample_Clouclip.csv\"\ntz   &lt;- \"US/Central\"   # Time zone in which device was recording (e.g., US Central Time)\n# Import Clouclip data\ndataCC &lt;- import$Clouclip(path, tz = tz, manual.id = \"Clouclip\")\n\n\nSuccessfully read in 58'081 observations across 1 Ids from 1 Clouclip-file(s).\nTimezone set is US/Central.\nThe system timezone is Europe/Berlin. Please correct if necessary!\n\nFirst Observation: 2021-02-06 17:12:47\nLast Observation: 2021-02-14 17:12:36\nTimespan: 8 days\n\nObservation intervals: \n  Id       interval.time            n pct     \n1 Clouclip 5s                   54572 93.9601%\n2 Clouclip 17s                     12 0.0207% \n3 Clouclip 18s                     14 0.0241% \n4 Clouclip 120s (~2 minutes)     3479 5.9900% \n5 Clouclip 128s (~2.13 minutes)     1 0.0017% \n6 Clouclip 132s (~2.2 minutes)      1 0.0017% \n7 Clouclip 133s (~2.22 minutes)     1 0.0017% \n\n\n\n\n\n\n\n\nFigure 1: Overview plot of imported Clouclip data\n\n\n\n\n\nIn this code, import$Clouclip() reads the tab-delimited file and returns a tibble2 (saved in the variable dataCC) containing the data. We specify tz = \"US/Central\" because the device’s clock was set to U.S. Central time; this ensures that the Datetimevalues are properly interpreted with the correct time zone. The argument manual.id = \"Clouclip\" simply tags the dataset with an identifier (useful if combining data from multiple devices).\nDuring import, LightLogR automatically handles the Clouclip’s sentinel codes. The Date column from the raw file is parsed into a POSIX date-time (Datetime) with the specified time zone. The Lux and Dis columns are read as numeric, but any occurrences of -1 or 204 are treated specially: these are replaced with NA (missing values) in the numeric columns, and corresponding status columns Lux_status and Dis_status are created to indicate the reason for those NA values. For example, if a Dis value of 204 was encountered, that row’s Dis will be set to NA and Dis_status will contain \"out_of_range\"; if Lux or Dis was -1, the status is \"sleep_mode\". We will set all other readings to  \"operational\" (meaning the device was functioning normally at that time) for visualisation purposes.\nAfter import, it is good practice to get an overview of the data. The import function by default prints a brief summary (and generates an overview plot of the timeline) showing the number of observations, the time span, and any irregularities or large gaps. In our case, the Clouclip summary indicates the data spans one week and reveals that there are irregular intervals in the timestamps. This means some observations do not occur exactly every 5 seconds as expected. We can programmatically check for irregular timing:\n\n# Check if data are on a perfectly regular 5-second schedule\ndataCC |&gt; has_irregulars()\n\n[1] TRUE\n\n\nIf the result is TRUE, it confirms that the time sequence has deviations from the 5-second interval. Indeed, our example dataset has many small timing irregularities and gaps (periods with no data). Understanding the pattern of these missing or irregular readings is important. We can visualize them using a gap plot:\n\n# Plot gaps and irregular timestamps for Clouclip data\ny.label &lt;- \"Distance (cm)\"\ndataCC |&gt; gg_gaps(Dis, \n                  include.implicit.gaps = FALSE,  # only show recorded gaps, not every missing point\n                  show.irregulars = TRUE,         # highlight irregular timing\n                  y.axis.label = y.label,\n                  group.by.days = TRUE, col.irregular = alpha(\"red\", 0.03)\n                  ) + labs(title = NULL)\n\n\n\n\n\n\n\nFigure 2: Visualization of gaps and irregular data. Black traces show available data. Red shaded areas show times of missing data. Red dots show instances where observations occur off the regular interval from start to finish, i.e., irregular data.\n\n\n\n\n\nIn Figure 2, time periods where data are missing appear as red-shaded areas, and any off-schedule observation times are marked with red dots. The Clouclip example shows extensive gaps (red blocks) on certain days and irregular timing on all days except the first and last. These irregular timestamps likely arise from the device’s logging process (e.g. slight clock drift or buffering when the device was turned on/off). Such issues must be addressed before further analysis.\nWhen faced with irregular or gapped data, LightLogR recommends a few strategies:\n\nRemove leading/trailing segments that cause irregularity. For example, if only the first day is regular and subsequent days drift, one might exclude the problematic portion using date filters (see filter_Date() / filter_Datetime() in LightLogR).\nRound timestamps to the nearest regular interval. This can snap slightly off-schedule times back to the 5-second grid (using cut_Datetime() with a 5-second interval), provided the deviations are small and this rounding won’t create duplicate timestamps.\nAggregate to a coarser time interval. For instance, grouping data into 1-minute bins with aggregate_Datetime() can mask irregularities at finer scales, at the cost of some temporal resolution.\n\nIn this case, the deviations from the 5-second schedule are relatively minor. We choose to round the timestamps to the nearest 5 seconds to enforce a uniform sampling grid, which simplifies downstream gap handling. We further add a separate date column for convenience:\n\n# Regularize timestamps by rounding to nearest 5-second interval\ndataCC &lt;- dataCC |&gt;\n  cut_Datetime(\"5 secs\", New.colname = Datetime) |&gt;  # round times to 5-second bins\n  add_Date_col(group.by = TRUE)                     # add a Date column for grouping by day\n\nAfter this operation, all Datetime entries in dataCC align perfectly on 5-second boundaries (e.g. 08:00:00, 08:00:05, 08:00:10, etc.). We can verify that no irregular intervals remain by re-running has_irregulars() (it now returns FALSE). Next, we want to quantify the missing data. LightLogR distinguishes between explicit missing values (actual NAs in the data, possibly from sentinel replacements or gaps we have filled in) and implicit missing intervals (time points where the device should have a reading but none was recorded, and we have not yet filled them in). Initially, many gaps are still implicit (between the first and last timestamp of each day). We can generate a gap summary table:\n\n# Summarize observed vs missing data by day for distance\ndataCC |&gt; gap_table(Dis, Variable.label = \"Distance (cm)\") |&gt;\n  cols_hide(contains(\"_n\"))   # hide absolute counts for brevity in output\n\n\n\nTable 1: Summary of missing and observed data for the Clouclip device\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSummary of available and missing data\n\n\nVariable: Distance (cm)\n\n\n\n\nData\n\n\nMissing\n\n\n\n\n\nRegular\n\n\nIrregular\n\n\nRange\n\n\nInterval\n\n\nGaps\n\n\nImplicit\n\n\nExplicit\n\n\n\nTime\n%\nn1,2\nTime\nTime\nN\nø\nTime\n%\nTime\n%\nTime\n%\n\n\n\n\nOverall\n2d 14h 43m 10s\n29.0%3\n0\n1w 2d\n5\n2,690\n1h 35m 57s\n6d 9h 16m 50s\n71.0%3\n5d 15h 19m 55s\n62.7%3\n17h 56m 55s\n8.3%3\n\n\nClouclip - 2021-02-06\n\n\n\n43m 30s\n3.0%\n0\n1d\n5s\n26\n53m 43s\n23h 16m 30s\n97.0%\n22h 53m 20s\n95.4%\n23m 10s\n1.6%\n\n\nClouclip - 2021-02-07\n\n\n\n2h 45m\n11.5%\n0\n1d\n5s\n139\n9m 10s\n21h 15m\n88.5%\n19h 42m 35s\n82.1%\n1h 32m 25s\n6.4%\n\n\nClouclip - 2021-02-08\n\n\n\n11h 13m 55s\n46.8%\n0\n1d\n5s\n443\n1m 44s\n12h 46m 5s\n53.2%\n10h 47m 50s\n45.0%\n1h 58m 15s\n8.2%\n\n\nClouclip - 2021-02-09\n\n\n\n8h 46m 25s\n36.6%\n0\n1d\n5s\n278\n3m 17s\n15h 13m 35s\n63.4%\n13h 50m\n57.6%\n1h 23m 35s\n5.8%\n\n\nClouclip - 2021-02-10\n\n\n\n7h 1m 30s\n29.3%\n0\n1d\n5s\n367\n2m 47s\n16h 58m 30s\n70.7%\n14h 18m 40s\n59.6%\n2h 39m 50s\n11.1%\n\n\nClouclip - 2021-02-11\n\n\n\n8h 31m 55s\n35.5%\n0\n1d\n5s\n423\n2m 12s\n15h 28m 5s\n64.5%\n11h 43m 30s\n48.9%\n3h 44m 35s\n15.6%\n\n\nClouclip - 2021-02-12\n\n\n\n12h 17m 55s\n51.2%\n0\n1d\n5s\n417\n1m 41s\n11h 42m 5s\n48.8%\n9h 17m 45s\n38.7%\n2h 24m 20s\n10.0%\n\n\nClouclip - 2021-02-13\n\n\n\n10h 32m 15s\n43.9%\n0\n1d\n5s\n527\n1m 32s\n13h 27m 45s\n56.1%\n10h 42m 10s\n44.6%\n2h 45m 35s\n11.5%\n\n\nClouclip - 2021-02-14\n\n\n\n50m 45s\n3.5%\n0\n1d\n5s\n70\n19m 51s\n23h 9m 15s\n96.5%\n22h 4m 5s\n92.0%\n1h 5m 10s\n4.5%\n\n\n\n1 If n &gt; 0: it is possible that the other summary statistics are affected, as they are calculated based on the most prominent interval.\n\n\n2 Number of (missing or actual) observations\n\n\n3 Based on times, not necessarily number of observations\n\n\n\n\n\n\n\n\n\n\n\nThis summary (Table 1) breaks down, for each day, how much data is present vs. missing. It reports the total duration of recorded data and the duration of gaps. After rounding the times, there are no irregular timestamp issues, but we see substantial implicit gaps — periods where the device was not recording (e.g., overnight when the device was likely not worn or was in sleep mode). Notably, the first and last days of the week have very little data (less than 1 hour each), since they probably represent partial recording days (the device was put on and removed on those days).\nTo prepare the dataset for analysis, we will convert all those implicit gaps into explicit missing entries, and remove days that are mostly incomplete. Converting implicit gaps means inserting rows with NA for each missing 5-second slot, so that the time series becomes continuous and explicit about missingness. We use gap_handler() for this, and then drop the nearly-empty days:\n\n# Convert implicit gaps to explicit NA gaps, and drop days with &lt;1 hour of data\ndataCC &lt;- dataCC |&gt; \n  # First ensure that status columns have an \"operational\" tag for non-missing periods:\n  mutate(across(c(Lux_status, Dis_status), ~ replace_na(.x, \"operational\"))) |&gt; \n  # Fill in all implicit gaps with explicit NA rows (for full days range):\n  gap_handler(full.days = TRUE) |&gt;  \n  # Remove any day that has less than 1 hour of recorded data\n  remove_partial_data(Dis, threshold.missing = \"23 hours\")\n\nAfter these steps, dataCC contains continuous 5-second timestamps for each day that remains. We chose a threshold of “23 hours” missing to remove days with &lt;1 hour of data, which in this dataset removes the first and last (partial) days. The cleaned Clouclip data now covers six full days with bouts of continuous wear.\nIt is often helpful to double-check how the sentinel values and missing data are distributed over time. We can visualize the distance time-series with status annotations and day/night periods:\n\n#setting coordinates for Houston, Texas\ncoordinates &lt;- c(29.75, -95.36)\n# visualize observations\ndataCC |&gt; \n  fill(c(Lux_status, Dis_status), .direction = \"downup\") |&gt; \n  gg_day(y.axis = Dis, geom = \"line\", y.axis.label = y.label) |&gt; #create a basic plot\n  gg_state(Dis_status, aes_fill = Dis_status) |&gt; #add the status times\n  gg_photoperiod(coordinates, alpha = 0.1, col = \"red\") + #add the photoperiod (day/night)\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\nFigure 3: Distance measurements across days. Blue, grey and yellow-colored areas show sentinel states of the device. Blue indicates an operational status, grey sleep mode (not recording), and yellow an out of range measurement. Red boxed areas show nighttime from civil dusk until dawn, which are calculated based on the recording date and geographic coordinates\n\n\n\n\n\nIn this plot, blue segments indicate times when the Clouclip was operational (actively measuring), grey segments indicate the device in sleep mode (no recording, typically at night), and yellow segments indicate out-of-range distance readings. The red outlined regions show nighttime (from civil dusk to dawn) based on the given latitude/longitude and dates. As expected, most of the grey “sleep” periods align with night hours, and we see a few yellow spans when the user’s viewing distance exceeded the device’s range (e.g. presumably when no object was within 100 cm, such as when the user looked into the distance). At this stage, the Clouclip dataset dataCC is fully preprocessed: all timestamps are regular 5-second intervals, missing data are explicitly marked, extraneous partial days are removed, and sentinel codes are handled via the status columns. The data are ready for calculating daily distance and light exposure metrics (as done in the main tutorial’s Results)."
  },
  {
    "objectID": "supplement.html#veet-data-ambient-light-illuminance-processing",
    "href": "supplement.html#veet-data-ambient-light-illuminance-processing",
    "title": "Supplement 1",
    "section": "3 VEET Data: Ambient Light (Illuminance) Processing",
    "text": "3 VEET Data: Ambient Light (Illuminance) Processing\nThe VEET device Sullivan et al. (2024) is a more complex logger that records multiple data modalities in one combined file. Its raw data file contains interleaved records for different sensor types, distinguished by a “modality” field. We focus first on the ambient light sensor modality (abbreviated ALS), which provides broad-spectrum illuminance readings (lux) and related information like sensor gains and flicker, recorded every 2 seconds. Later we will import the spectral sensor modality (PHO) for spectral irradiance data, and the time-of-flight modality (TOF) for distance data.\nIn the VEET’s export file, each line includes a timestamp and a modality code, followed by fields specific to that modality. Importantly, this means that the VEET export is not rectangular, i.e., tabular. This makes it challenging for many import functions that expect the equal number of columns in every row, which is not the case in this instance. For the ALS modality, the relevant columns include a high-resolution timestamp (in Unix epoch format), integration time, UV/VIS/IR sensor gain settings, raw UV/VIS/IR sensor counts, a flicker measurement, and the computed illuminance in lux. For example, the ALS data columns are named: time_stamp, integration_time, uvGain, visGain, irGain, uvValue, visValue, irValue, Flicker, and Lux.\nFor the PHO (spectral) modality, the columns include a timestamp, integration time, a general Gain factor, and nine sensor channel readings covering different wavelengths (with names like s415, s445, ..., s680, s940) as well as a Dark channel and two broadband channels ClearL and ClearR. In essence, the VEET’s spectral sensor captures light in several wavelength bands (from ~415 nm up to 940 nm, plus an infrared and two “clear” channels) rather than outputting a single lux value like the ambient light sensor does (PHO).\nTo import the VEET ambient light data, we again use the LightLogR import function, specifying the ALS modality. The raw VEET data in our example is provided as a zip file (01_VEET_L.csv.zip) containing the logged data for one week. We do the following:\n\n# Import VEET Ambient Light Sensor (ALS) data\npath &lt;- \"data/01_VEET_L.csv.zip\"\ntz   &lt;- \"US/Central\"    # assuming device clock was set to US Central, for consistency\ndataVEET &lt;- import$VEET(path, tz = tz, modality = \"ALS\", manual.id = \"VEET\")\n\n\nSuccessfully read in 304'193 observations across 1 Ids from 1 VEET-file(s).\nTimezone set is US/Central.\nThe system timezone is Europe/Berlin. Please correct if necessary!\n1 observations were dropped due to a missing or non-parseable Datetime value (e.g., non-valid timestamps during DST jumps). \n\nFirst Observation: 2024-06-04 15:00:37\nLast Observation: 2024-06-12 08:29:43\nTimespan: 7.7 days\n\nObservation intervals: \n  Id    interval.time              n pct      \n1 VEET  0s                         1 0.00033% \n2 VEET  1s                      1957 0.64334% \n3 VEET  2s                    300147 98.67025%\n4 VEET  3s                      2074 0.68181% \n5 VEET  4s                         3 0.00099% \n6 VEET  9s                         5 0.00164% \n7 VEET  10s                        3 0.00099% \n8 VEET  109s (~1.82 minutes)       1 0.00033% \n9 VEET  59077s (~16.41 hours)      1 0.00033% \n\n\n\n\n\n\n\n\nFigure 4: Overview plot of imported VEET data\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe get one warning as a single time stamp could not be parsed into a datetime - with ~300k observations, this is not an issue.\n\n\nThis call reads in only the lines corresponding to the ALS modality from the VEET file. The result dataVEET is a tibble3 with columns such as Datetime (parsed from the time_stamp epoch to POSIXct in US/Central time), Lux (illuminance in lux), Flicker, and the various sensor gains/values. Unneeded columns like the modality code or file name are also included but can be ignored or removed. After import, LightLogR again provides an overview of the data. We learn that the VEET light data, like the Clouclip, also exhibits irregularities and gaps. (The device nominally records every 2 seconds, but timing may drift or pause when not worn.)\nTo make the VEET light data comparable to the Clouclip’s and to simplify analysis, we choose to aggregate the VEET illuminance data to 5-second intervals. This slight downsampling will both reduce data volume and help align with the Clouclip’s timeline for any combined analysis. Before aggregation, we will also explicitly mark gaps in the VEET data so that missing intervals are not overlooked.\n\n# Aggregate VEET light data to 5-second intervals and mark gaps\ndataVEET &lt;- dataVEET |&gt;\n  aggregate_Datetime(unit = \"5 seconds\") |&gt;  # resample to 5-sec bins (e.g. average Lux over 2-sec readings)\n  gap_handler(full.days = TRUE) |&gt;          # fill in implicit gaps with NA rows\n  add_Date_col(group.by = TRUE) |&gt;          # add Date column for daily grouping\n  remove_partial_data(Lux, threshold.missing = \"1 hour\")\n\nFirst, aggregate_Datetime(unit = \"5 seconds\") combines the high-frequency 2-second observations into 5-second slots. By default, this function will average numeric columns like Lux over each 5-second period (and handle counts or categorical appropriately). All of these data type handlers can be changed with the function call. The result is that dataVEET now has a reading every 5 seconds (or an NA if none were present in that window). Next, gap_handler(full.days = TRUE) inserts explicit NA entries for any 5-second timestamp that had no data within the continuous span of the recording. Then we add a Date column for grouping, and finally we remove days with more than 1 hour of missing data (using a more strict criterion as we did for Clouclip). According to the gap summary (Table 2), this leaves six full days of VEET light data with good coverage, after dropping the very incomplete start/end days.\nWe can inspect the missing-data summary for the VEET illuminance data:\n\ndataVEET |&gt; gap_table(Lux, \"Illuminance (lx)\") |&gt;   \n  cols_hide(contains(\"_n\")) #remove the absolute number of data points\n\n\n\nTable 2: Summary of missing and observed data for the VEET device\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSummary of available and missing data\n\n\nVariable: Illuminance (lx)\n\n\n\n\nData\n\n\nMissing\n\n\n\n\n\nRegular\n\n\nIrregular\n\n\nRange\n\n\nInterval\n\n\nGaps\n\n\nImplicit\n\n\nExplicit\n\n\n\nTime\n%\nn1,2\nTime\nTime\nN\nø\nTime\n%\nTime\n%\nTime\n%\n\n\n\n\nOverall\n5d 23h 57m 40s\n100.0%3\n0\n6d\n5\n8\n58s\n2m 20s\n0.0%3\n0s\n0.0%3\n2m 20s\n0.0%3\n\n\nVEET - 2024-06-06\n\n\n\n23h 58m 5s\n99.9%\n0\n1d\n5s\n3\n38s\n1m 55s\n0.1%\n0s\n0.0%\n1m 55s\n0.1%\n\n\nVEET - 2024-06-07\n\n\n\n1d\n100.0%\n0\n1d\n5s\n0\n0s\n0s\n0.0%\n0s\n0.0%\n0s\n0.0%\n\n\nVEET - 2024-06-08\n\n\n\n23h 59m 55s\n100.0%\n0\n1d\n5s\n1\n5s\n5s\n0.0%\n0s\n0.0%\n5s\n0.0%\n\n\nVEET - 2024-06-09\n\n\n\n23h 59m 50s\n100.0%\n0\n1d\n5s\n2\n5s\n10s\n0.0%\n0s\n0.0%\n10s\n0.0%\n\n\nVEET - 2024-06-10\n\n\n\n23h 59m 55s\n100.0%\n0\n1d\n5s\n1\n5s\n5s\n0.0%\n0s\n0.0%\n5s\n0.0%\n\n\nVEET - 2024-06-11\n\n\n\n23h 59m 55s\n100.0%\n0\n1d\n5s\n1\n5s\n5s\n0.0%\n0s\n0.0%\n5s\n0.0%\n\n\n\n1 If n &gt; 0: it is possible that the other summary statistics are affected, as they are calculated based on the most prominent interval.\n\n\n2 Number of (missing or actual) observations\n\n\n3 Based on times, not necessarily number of observations\n\n\n\n\n\n\n\n\n\n\n\nTable 2 shows, for each retained day, the total recorded duration and the duration of gaps. The VEET device, like the Clouclip, was not worn continuously 24 hours per day, so there are nightly gaps of wear time (when the device was likely off the participant), but not of recordings. After our preprocessing, any implicit gaps are represented as explicit missing intervals. The VEET’s time sampling was originally more frequent, but by aggregating to 5 s we have ensured a uniform timeline akin to the Clouclip’s.\nAt this point, the dataVEET object (for illuminance) is cleaned and ready for computing light exposure metrics. For example, one could calculate daily mean illuminance or the duration spent above certain light thresholds (e.g. “outdoor light exposure” defined as &gt;1000 lx) using this dataset. Indeed, basic summary tables in the main tutorial illustrate the highly skewed nature of light exposure data and the calculation of outdoor light metrics. We will not repeat those metric calculations here in the supplement, as our focus is on data preprocessing; however, having a cleaned, gap-marked time series is crucial for those metrics to be accurate."
  },
  {
    "objectID": "supplement.html#veet-data-spectral-data-processing",
    "href": "supplement.html#veet-data-spectral-data-processing",
    "title": "Supplement 1",
    "section": "4 VEET Data: Spectral Data Processing",
    "text": "4 VEET Data: Spectral Data Processing\n\n4.1 Import\nIn addition to broad-band illuminance and distance, the VEET provides spectral sensor data through its PHO modality. Unlike illuminance, the spectral data are not directly given as directly interpretable radiometric metrics but rather as raw sensor counts across multiple wavelength channels, which require conversion to reconstruct a spectral power distribution. In our analysis, spectral data allow us to compute metrics like the relative contribution of short-wavelength (blue) light versus long-wavelength light in the participant’s environment. Processing this spectral data involves several necessary steps.\nFirst, we import the spectral modality from a second VEET file. This device used the latest software version to allow for the best spectral reconstruction. This time we need to extract the lines marked as PHO. We will store the spectral dataset in a separate object dataVEET2 so as not to overwrite the dataVEET illuminance data in our R session:\n\n# Import VEET Spectral Sensor (PHO) data\npath &lt;- \"data/02_VEET_L.csv.zip\"\n#if a version of LightLogR ≤ 0.9.2 is used, this script needs to be imported, as the device data was collected with a newer firmware version that changes the output format.\nsource(\"scripts/VEET_import.R\")\ndataVEET2 &lt;- import$VEET(path, tz = tz, modality = \"PHO\", manual.id = \"VEET\")\n\n\nSuccessfully read in 173'013 observations across 1 Ids from 1 VEET-file(s).\nTimezone set is US/Central.\nThe system timezone is Europe/Berlin. Please correct if necessary!\n\nFirst Observation: 2025-06-17 12:25:13\nLast Observation: 2025-06-21 22:47:01\nTimespan: 4.4 days\n\nObservation intervals: \n   Id    interval.time      n pct      \n 1 VEET  1s               417 0.24102% \n 2 VEET  2s            171837 99.32086%\n 3 VEET  3s               738 0.42656% \n 4 VEET  4s                 7 0.00405% \n 5 VEET  9s                 1 0.00058% \n 6 VEET  11s                1 0.00058% \n 7 VEET  12s                2 0.00116% \n 8 VEET  13s                4 0.00231% \n 9 VEET  15s                1 0.00058% \n10 VEET  16s                1 0.00058% \n# ℹ 3 more rows\n\n\n\n\n\n\n\n\nFigure 5: Overview plot of imported VEET data\n\n\n\n\n\nAfter import, dataVEET2 contains columns for the timestamp (Datetime), Gain (the sensor gain setting), and the nine spectral sensor channels plus a clear channel. These appear as numeric columns named s415, s445, ..., s940, Dark, Clear. The spectral sensor was logging at a 2-second rate. Because this dataset is even denser and more high-dimensional, we will aggregate it to a 5-minute interval for computational efficiency. The assumption is that spectral composition does not need to be examined at every 2-second instant for our purposes, and 5-minute averages can capture the general trends while drastically reducing data size and downstream computational costs.\n\n# Aggregate spectral data to 5-minute intervals and mark gaps\ndataVEET2 &lt;- dataVEET2 |&gt;\n  aggregate_Datetime(unit = \"5 mins\") |&gt;     # aggregate to 5-minute bins\n  gap_handler(full.days = TRUE) |&gt;           # explicit NA for any gaps in between\n  add_Date_col(group.by = TRUE) |&gt; \n  remove_partial_data(Clear, threshold.missing = \"1 hour\")\n\nWe aggregate over 5-minute windows; within each 5-minute bin, multiple spectral readings (if present) are combined (averaged). We use one of the channels (here Clear) as the reference variable for remove_partial_data to drop incomplete days (the choice of channel is arbitrary as all channels share the same level of completeness).\nIt is informative to look at a snippet of the imported spectral data before further processing. Table 3 shows the first three rows of dataVEET2 after import (before calibration), with some technical columns omitted for brevity:\n\ndataVEET2 |&gt; head(3) |&gt; select(-c(modality, file.name, is.implicit, time_stamp)) |&gt; \n  gt() |&gt; fmt_number(s415:Clear) \n\n\n\nTable 3: Overview of the spectral sensor import from the VEET device (first 3 observations). Each row corresponds to a 5-minute timestamp (Datetime) and shows the raw sensor readings for the spectral channels (s415–s940, Dark, Clear). All values are in arbitrary sensor units (counts). Gain values and integration_time are also relevant for each interval, depending on the downstream computation.\n\n\n\n\n\n\n\n\n\nDatetime\nintegration_time\nGain\ns415\ns445\ns480\ns515\ns555\ns590\ns630\ns680\ns910\nDark\nClear\n\n\n\n\nVEET - 2025-06-18\n\n\n2025-06-18\n100\n512\n20.24\n26.95\n30.02\n40.85\n46.83\n63.02\n89.98\n138.35\n736.04\n0.00\n525.21\n\n\n2025-06-18 00:05:00\n100\n512\n20.93\n27.63\n30.95\n41.99\n47.81\n64.58\n91.27\n140.51\n774.85\n0.00\n537.75\n\n\n2025-06-18 00:10:00\n100\n512\n20.86\n27.47\n30.60\n41.31\n46.90\n63.20\n89.92\n139.66\n757.36\n0.00\n534.43\n\n\n\n\n\n\n\n\n\n\n\n\n4.2 Spectral calibration\nNow we proceed with spectral calibration. The VEET’s spectral sensor counts need to be converted to physical units (spectral irradiance) via a calibration matrix provided by the manufacturer. For this example, we assume we have a calibration matrix that maps all the channel readings to an estimated spectral power distribution (SPD). The LightLogR package provides a function spectral_reconstruction() to perform this conversion. However, before applying it, we must ensure the sensor counts are in a normalized form. This procedure is laid out by the manufacturer. In our version, we refer to the VEET SPD Reconstruction Guide.pdf, version 06/05/2025. Note that each manufacturer has to specify the method of count normalization (if any) and spectral reconstruction. In our raw data, each observation comes with a Gain setting that indicates how the sensor’s sensitivity was adjusted; we need to divide the raw counts by the gain to get normalized counts. LightLogR offers normalize_counts() for this purpose. We further need to scale by integration time (in milliseconds) and adjust depending on counts in the Dark sensor channel.\n\ncount.columns &lt;- c(\"s415\", \"s445\", \"s480\", \"s515\", \"s555\", \"s590\", \"s630\", \n                      \"s680\", \"s910\", \"Dark\", \"Clear\") #column names\n\ngain.ratios &lt;- #gain ratios as specified by the manufacturers reconstruction guide\n  tibble(\n    gain = c(0.5, 1, 2, 4, 8, 16, 32, 64, 128, 256, 512),\n    gain.ratio = c(0.008, 0.016, 0.032, 0.065, 0.125, 0.25, 0.5, 1, 2, 3.95, 7.75)\n  ) \n\n#normalize data\ndataVEET2 &lt;-\n  dataVEET2 |&gt; \n  mutate(across(c(s415:Clear), \\(x) (x - Dark)/integration_time)) |&gt;  #remove dark counts & scale by integration time\n  normalize_counts( #function to normalize counts\n    gain.columns = rep(\"Gain\", 11), #all sensor channels share the gain value\n    count.columns = count.columns, #sensor channels to normalize\n    gain.ratios #gain ratios\n  ) |&gt; \n  select(-c(s415:Clear)) |&gt; # drop original raw count columns\n  rename_with(~ str_remove(.x, \".normalized\"))\n\nIn this call, we specified gain.columns = rep(\"Gain\", 11) because we have 11 sensor columns that all use the same gain factor column (Gain). This step will add new columns (with a suffix, e.g. .normalized) for each spectral channel representing the count normalized by the gain. We then dropped the raw count columns and renamed the normalized ones by dropping .normalized from the names. After this, dataVEET2 contains the normalized sensor readings for s415, s445, ..., s940, Dark, Clear for each 5-minute time point. The dataset is now ready for spectral reconstruction.\n\n\n4.3 Spectral reconstruction\nFor spectral reconstruction, we require a calibration matrix that corresponds to the VEET’s sensor channels. This matrix would typically be obtained from the device manufacturer or a calibration procedure. It defines how each channel’s count relates to intensity at various wavelengths. For demonstration, the calibration matrix was provided by the manufacturer and is specific to the make and model. It should not be used for research purposes without confirming its accuracy with the manufacturer.\n\n#import calibration matrix\ncalib_mtx &lt;- \n  read_csv(\"data/VEET_calibration_matrix.csv\", show_col_types = FALSE) |&gt; \n  column_to_rownames(\"wavelength\")\n\n# Reconstruct spectral power distribution (SPD) for each observation\ndataVEET2 &lt;- dataVEET2 |&gt; mutate(\n  Spectrum = spectral_reconstruction(\n    pick(s415:s910),   # pick the normalized sensor columns\n    calibration_matrix = calib_mtx, \n    format = \"long\" # return a long-form list column (wavelength, intensity)\n  )\n)\n\nHere, we use format = \"long\" so that the result for each observation is a list-column Spectrum, where each entry is a tibble4 containing two columns: wavelength and irradiance (one row per wavelength in the calibration matrix). In other words, each row of dataVEET2 now holds a full reconstructed spectrum in the Spectrum column. The long format is convenient for further calculations and plotting. (An alternative format = \"wide\" would add each wavelength as a separate column, but that is less practical when there are many wavelengths.)\nTo visualize the data we will calculate the photopic illuminance based on the spectra and plot each spectrum color-scaled by their illuminance. For clarity, we reduce the data to observations within the first day.\n\ndataVEET2 |&gt; \n  filter_Date(length = \"1 day\") |&gt; #keep only observations for one day (from start)\n  mutate( \n    Illuminance = Spectrum |&gt; #Use the spectrum,...\n      map_dbl(spectral_integration, #... call the function spectral_integration for each,...\n              action.spectrum = \"photopic\", #... use the brightness sensitivity function,...\n              general.weight = \"auto\") #... and apply the appropriate efficacy weight.\n  ) |&gt; \n  unnest(Spectrum) |&gt; #create a long format of the data where the spectrum is unnested\n  ggplot(aes(x = wavelength, y = irradiance*1000, group = Datetime)) +\n  geom_line(aes(col = Illuminance)) +\n  labs(y = \"Irradiance (mW/m²/nm)\", x = \"Wavelength (nm)\", col = \"Photopic illuminance (lx)\")+\n  scale_color_viridis_b() +\n  coord_cartesian(ylim = c(0,5.3)) +\n  theme_minimal()\n\n\n\n\n\n\n\nFigure 6: Overview of the reconstructed spectra, color-scaled by photopic illuminance (lx)\n\n\n\n\n\nAt this stage, the dataVEET2 dataset has been processed to yield time-series of spectral power distributions. We can use these to compute biologically relevant light metrics. For instance, one possible metric is the proportion of power in short wavelengths versus long wavelengths. In the main analysis, we defined short-wavelength (blue light) content as the integrated intensity in the 400–500 nm range, and long-wavelength content as the integrated intensity in a longer range (e.g. 600–700 nm), then computed the short-to-long ratio (“sl ratio”). Calculating these metrics is the first step of spectrum analysis in the main tutorial.\ndataVEET2 |&gt; \n  select(Id, Date, Datetime, Spectrum) |&gt;    # focus on ID, date, time, and spectrum\n  mutate(\n    short = Spectrum |&gt; map_dbl(spectral_integration, wavelength.range = c(400, 500)),\n    long  = Spectrum |&gt; map_dbl(spectral_integration, wavelength.range = c(600, 700)),\n    `sl ratio` = short / long   # compute short-to-long ratio\n  )\n(The cutoff of 500 nm here is hypothetical for demonstration; actual definitions might vary.) We would then have columns short, long, and sl_ratio for each observation, which could be averaged per day or analyzed further. The cleaned spectral data in dataVEET2 makes it straightforward to calculate such metrics or apply spectral weighting functions (for melatonin suppression, circadian stimulus, etc., if one has the spectral sensitivity curves).\nWith the VEET spectral preprocessing complete, we emphasize that these steps – normaliziing by gain, applying calibration, and perhaps simplifying channels – are device-specific requirements. They ensure that the raw sensor counts are translated into meaningful physical measures (like spectral irradiance). Researchers using other spectral devices would follow a similar procedure, adjusting for their device’s particulars (some may output spectra directly, whereas others, like VEET, require reconstruction.\n\n\n\n\n\n\nNote\n\n\n\nSome devices may output normalized counts instead of raw counts. For example, the ActLumus device outputs normalized counts, while the VEET device records raw counts and the gain. Manufacturers will be able to speficy exact outputs for a given model and software version."
  },
  {
    "objectID": "supplement.html#veet-data-time-of-flight-distance",
    "href": "supplement.html#veet-data-time-of-flight-distance",
    "title": "Supplement 1",
    "section": "5 VEET Data: Time of flight (distance)",
    "text": "5 VEET Data: Time of flight (distance)\nIn this last section, the distance data of the VEET device will be imported, analogous to the other modalities. The TOF modality contains information for up to two objects in a 8x8 grid of measurements, spanning a total of about 52° vertically and 41° horizontally. Because the VEET device can detect up to two objects in a given grid point, and there is a confidence value assigned to every measurement, each observation contains \\(2*2*8*8 = 256\\) measurements.\n\n# Import VEET Spectral Sensor (TOF) data\npath &lt;- \"data/01_VEET_L.csv.zip\"\ndataVEET3 &lt;- LightLogR::import$VEET(path, tz = tz, modality = \"TOF\", manual.id = \"VEET\")\n\n\nSuccessfully read in 304'195 observations across 1 Ids from 1 VEET-file(s).\nTimezone set is US/Central.\nThe system timezone is Europe/Berlin. Please correct if necessary!\n\nFirst Observation: 2024-06-04 15:00:36\nLast Observation: 2024-06-12 08:29:43\nTimespan: 7.7 days\n\nObservation intervals: \n  Id    interval.time              n pct      \n1 VEET  0s                         3 0.00099% \n2 VEET  1s                      2089 0.68673% \n3 VEET  2s                    299876 98.58051%\n4 VEET  3s                      2213 0.72750% \n5 VEET  4s                         3 0.00099% \n6 VEET  6s                         1 0.00033% \n7 VEET  9s                         7 0.00230% \n8 VEET  109s (~1.82 minutes)       1 0.00033% \n9 VEET  59077s (~16.41 hours)      1 0.00033% \n\n\n\n\n\n\n\n\nFigure 7: Overview plot of imported VEET data\n\n\n\n\n\nIn a first step, we condition the data similarly to the other VEET modalities.\n\n# Aggregate spectral data to 5-minute intervals and mark gaps\ndataVEET3 &lt;- dataVEET3 |&gt;\n  aggregate_Datetime(unit = \"5 secs\") |&gt;     # aggregate to 5-second bins\n  gap_handler(full.days = TRUE) |&gt;           # explicit NA for any gaps in between\n  add_Date_col(group.by = TRUE) |&gt; \n  remove_partial_data(dist1_0, threshold.missing = \"1 hour\")\n\nIn the next step, we need to transform the wide format of the imported dataset into a long format, where each row contains exactly one observation for one grid-point.\n\ndataVEET3 &lt;- \n  dataVEET3 |&gt; \n  pivot_longer(\n    cols = -c(Datetime, file.name, Id, is.implicit, time_stamp, modality, Date),\n    names_to = c(\".value\", \"position\"),\n    names_pattern = \"(conf1|conf2|dist1|dist2)_(\\\\d+)\"\n  )\n\nIn a final step before we can use the data in the analysis, we need to assign x and y coordinates based on the position column that was created when pivoting longer. Positions are counted from 0 to 63 starting at the top left and increasing towards the right, before continuing on the left in the next row below. y positions thus depend on the row count, i.e., how often a row of 8 values fits into the position column. x positions consequently depend on the position within each 8-value row. We also add an observation variable that increases by +1 every time, the position column hits 0. We then center both x and y coordinates to receive meaningful values, i.e., 0° indicates the center of the overall measurement cone. Lastly, we convert both confidence columns, which are scaled from 0-255 into percentages by dividing them by 255. Empirical data from the manufacturer points to a threshold of about 10%, under which the respective distance data is not reliable.\n\ndataVEET3 &lt;- \n  dataVEET3 |&gt; \n  # ungroup() |&gt; \n  mutate(position = as.numeric(position),\n         y.pos = (position %/% 8)+1,\n         y.pos = scale(y.pos, scale = FALSE)*52/8,\n         x.pos = (position %% 8)+1,\n         x.pos = scale(x.pos, scale = FALSE)*41/8,\n         observation = cumsum(position == 0),\n         across(starts_with(\"conf\"), \\(x) x/255)\n         )\n\nNow this dataset is ready for further analysis. We finish by visualizing the same observation time on different days. Note that we replace zero distance values with 5 meters, which is the maximum distance the VEET can measure.\n\n#set visualization parameters\nextras &lt;- list(\n  geom_tile(),\n  scale_fill_viridis_c(direction = -1, limits = c(0, 200),\n                       oob = scales::oob_squish_any),\n  scale_color_manual(values = c(\"black\", \"white\")),\n  theme_minimal(),\n  guides(colour = \"none\"),\n  geom_text(aes(label = (dist1/10) |&gt; round(0), colour = dist1&gt;1000), size = 2.5),\n  coord_fixed(),\n  labs(x = \"X position (°)\", y = \"Y position (°)\", \n       fill = \"Distance (cm)\", alpha = \"Confidence (0-255)\"))\n\nslicer &lt;- function(x){seq(min((x-1)*64+1), max(x*64, by = 1))} #allows to choose an observation\n\ndataVEET3 |&gt; \n  slice(slicer(9530)) |&gt;  #choose a particular observation\n  mutate(dist1 = ifelse(dist1 == 0, Inf, dist1)) |&gt; #replace 0 distances with 5m\n  filter(conf1 &gt;= 0.1 | dist1 == Inf) |&gt; #remove data that has less than 10% confidence\n  ggplot(aes(x=x.pos, y=y.pos, fill = dist1/10))+ extras + #plot the data\n  facet_grid(~Datetime) #show one plot per day\n\n\n\n\n\n\n\nFigure 8: Example observations of the measurement grid\n\n\n\n\n\nAs we can see from the figure, different days have a vastly different distribution of distance data, and measurement confidence (values with confidence &lt; 10% are removed)"
  },
  {
    "objectID": "supplement.html#saving-the-cleaned-data",
    "href": "supplement.html#saving-the-cleaned-data",
    "title": "Supplement 1",
    "section": "6 Saving the Cleaned Data",
    "text": "6 Saving the Cleaned Data\nAfter executing all the above steps, we have three cleaned data frames in our R session:\n\ndataCC – the processed Clouclip dataset (5-second intervals, with distance and lux, including NA for gaps and sentinel statuses).\ndataVEET – the processed VEET ambient light dataset (5-second intervals, illuminance in lux, with gaps filled).\ndataVEET2 – the processed VEET spectral dataset (5-minute intervals, each entry containing a spectrum or derived spectral metrics).\ndataVEET3 – the processed VEET distance dataset (5-second intervals, each entry containing the distance of up to two objects in the 8x8 grid).\n\nFor convenience and future reproducibility, we will save these combined results to a single R data file. Storing all cleaned data together ensures that any analysis can reload the exact same data state without re-running the import and cleaning (which can be time-consuming for large raw files).\n\n# Create directory for cleaned data if it doesn't exist\nif (!dir.exists(\"data/cleaned\")) dir.create(\"data/cleaned\", recursive = TRUE)\n\n# Save all cleaned datasets into one .RData file\nsave(dataCC, dataVEET, dataVEET2, dataVEET3,\n        file = \"data/cleaned/data.RData\")\n\nThe above code creates (if necessary) a folder data/cleaned/ and saves a single RData file (data.RData) containing the three objects. To retrieve them later, one can use &lt;- load(\"data/cleaned/data.RData\"), which will return the objects into the environment. This single-file approach simplifies sharing and keeps the cleaned data together.\nIn summary, this supplement has walked through the full preprocessing pipeline for two example devices. We began by describing the raw data format for each device and then demonstrated how to import the data with correct time zone settings. We handled device-specific quirks like sentinel codes (for Clouclip) and multiple modalities with gain normalization (for VEET). We showed how to detect and address irregular sampling, how to explicitly mark missing data gaps to avoid analytic pitfalls, and how to reduce data granularity via rounding or aggregation when appropriate. Throughout, we used functions from LightLogR in a tidyverse workflow, aiming to make the steps clear and modular. By saving the final cleaned datasets, we set the stage for the computation of visual experience metrics such as working distance, time in bright light, spectral composition ratios, as presented in the main tutorial. We hope this detailed tutorial empowers researchers to adopt similar pipelines for their own data, facilitating reproducible and accurate analyses of visual experience."
  },
  {
    "objectID": "supplement.html#footnotes",
    "href": "supplement.html#footnotes",
    "title": "Supplement 1",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nA sentinel value is a special placeholder value used in data recording to signal a particular condition. It does not represent a valid measured quantity but rather acts as a marker (for example, “device off” or “value out of range”).↩︎\ntibble are data.tables with tweaked behavior, ideal for a tidy analysis workflow. For more information, visit the documentation page for tibbles↩︎\ntibble are data.tables with tweaked behavior, ideal for a tidy analysis workflow. For more information, visit the documentation page for tibbles↩︎\ntibble are data.tables with tweaked behavior, ideal for a tidy analysis workflow. For more information, visit the documentation page for tibbles↩︎"
  }
]