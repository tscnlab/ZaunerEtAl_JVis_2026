[
  {
    "objectID": "supplement.html",
    "href": "supplement.html",
    "title": "Supplement 1",
    "section": "",
    "text": "This supplementary document provides a detailed, step-by-step tutorial on importing and preprocessing raw data from two wearable devices: Clouclip and VEET. We describe the structure of the raw datasets recorded by each device and explain how to parse these data, specify time zones, handle special sentinel values, clean missing observations, regularize timestamps to fixed intervals, and aggregate data as needed. All original R code from the main tutorial is shown here for transparency, with additional guidance intended for a broad research audience. We demonstrate how to detect gaps and irregular sampling, convert implicit missing periods into explicit missing values, and address device-specific quirks such as the Clouclip’s use of sentinel codes for “sleep mode” and “out of range” readings. Special procedures for processing the VEET’s rich spectral data (e.g. normalizing sensor counts and reconstructing full spectra from multiple sensor channels) are also outlined. Finally, we show how to save the cleaned datasets from both devices into a single R data file for downstream analysis. This comprehensive walkthrough is designed to ensure reproducibility and to assist researchers in understanding and adapting the data pipeline for their own visual experience datasets."
  },
  {
    "objectID": "supplement.html#abstract",
    "href": "supplement.html#abstract",
    "title": "Supplement 1",
    "section": "",
    "text": "This supplementary document provides a detailed, step-by-step tutorial on importing and preprocessing raw data from two wearable devices: Clouclip and VEET. We describe the structure of the raw datasets recorded by each device and explain how to parse these data, specify time zones, handle special sentinel values, clean missing observations, regularize timestamps to fixed intervals, and aggregate data as needed. All original R code from the main tutorial is shown here for transparency, with additional guidance intended for a broad research audience. We demonstrate how to detect gaps and irregular sampling, convert implicit missing periods into explicit missing values, and address device-specific quirks such as the Clouclip’s use of sentinel codes for “sleep mode” and “out of range” readings. Special procedures for processing the VEET’s rich spectral data (e.g. normalizing sensor counts and reconstructing full spectra from multiple sensor channels) are also outlined. Finally, we show how to save the cleaned datasets from both devices into a single R data file for downstream analysis. This comprehensive walkthrough is designed to ensure reproducibility and to assist researchers in understanding and adapting the data pipeline for their own visual experience datasets."
  },
  {
    "objectID": "supplement.html#introduction",
    "href": "supplement.html#introduction",
    "title": "Supplement 1",
    "section": "1 Introduction",
    "text": "1 Introduction\nWearable sensors like the Clouclip and the Visual Environment Evaluation Tool (VEET) produce high-dimensional time-series data on viewing distance and light exposure. Proper handling of these raw data is essential before any analysis of visual experience metrics. In the main tutorial, we introduce an analysis pipeline using the open-source R package LightLogR (Zauner, Hartmeyer, and Spitschan 2025) to calculate various distance and light exposure metrics. Here, we present a full account of the data import and preparation steps as a supplement to the methods, with an emphasis on clarity for researchers who may be less familiar with data processing in R.\nWe use example datasets from a Clouclip device (Wen et al. 2021, 2020) and from a VEET device (Sah, Narra, and Ostrin 2025) (both provided in the accompanying repository). The Clouclip is a glasses-mounted sensor that records working distance (distance from eyes to object, in cm) and ambient illuminance (in lux) at 5-second intervals. The VEET is a head-mounted multi-modal sensor that logs ambient light and spectral information (along with other data like motion and distance via a depth sensor) - in this exemplary case at 2-second intervals. A single week of continuous data illustrates the contrast in complexity: approximately 1.6 MB for the Clouclip’s simple two-column output versus up to 270 MB for the VEET’s multi-channel output (due to its higher sampling rate and richer sensor modalities).\nIn the following sections, we detail how these raw data are structured and how to import and preprocess them using LightLogR. We cover device-specific considerations such as file format quirks and sensor range limitations, as well as general best practices like handling missing timestamps and normalizing sensor readings. All code blocks can be executed in R (with the required packages loaded) to reproduce the cleaning steps. The end result will be clean, regularized datasets (dataCC for Clouclip, dataVEET for VEET light data, dataVEET2 for VEET spectral data, and dataVEET3 for VEET distance) ready for calculating visual experience metrics. We conclude by saving these cleaned datasets into a single file for convenient reuse."
  },
  {
    "objectID": "supplement.html#clouclip-data-raw-structure-and-import",
    "href": "supplement.html#clouclip-data-raw-structure-and-import",
    "title": "Supplement 1",
    "section": "2 Clouclip Data: Raw Structure and Import",
    "text": "2 Clouclip Data: Raw Structure and Import\nThe Clouclip device exports its data as a text file (not a true Excel file despite sometimes using an .xls extension), which is actually tab-separated values. See Figure 1 for the raw file.\n\n\n\n\n\n\nFigure 1: Screenshot of the first rows of the Clouclip export file format as seen in a text editor\n\n\n\nEach record corresponds to one timestamped observation (nominally every 5 seconds) and includes two measured variables: distance and illuminance. In the sample dataset (Sample_Clouclip.csv provided), the columns are:\n\nDate – the date and time of the observation (in the device’s local time, here one week in 2021).\nDis – the viewing distance in centimeters.\nLux – the ambient illuminance in lux.\n\nFor example, a raw data line might look like:\n2021-07-01 08:00:00 45  320\nindicating that at 2021-07-01 08:00:00 local time, the device recorded a working distance of 45 cm and illuminance of 320 lx. The Clouclip uses special sentinel values1 in these measurement columns to denote certain device states. Specifically, a distance (Dis) value of 204 is a code meaning the object is out of the sensor’s range, and a value of -1 in either Dis or Lux indicates the device was in sleep mode (not actively recording). During normal operation, distance measurements are limited by the device’s range, and illuminance readings are positive lux values. Any sentinel codes in the raw file need to be handled appropriately, as described below.\nWe will use LightLogR’s built-in import function for Clouclip, which automatically reads the file, parses the timestamps, and converts sentinel codes into a separate status annotation. To begin, we load the necessary libraries and import the raw Clouclip dataset:\n\n\n\nLoad required packages\n\n1library(tidyverse)\n2library(LightLogR)\n3library(gt)\n4library(ggridges)\n5library(downlit)\nlibrary(magick)\n\n\n\n1\n\nFor tidy data science\n\n2\n\nWearable analysis package\n\n3\n\nFor great tables\n\n4\n\nFor ridgeline plots\n\n5\n\nThese packages are not used, but are needed for dependencies\n\n\n\n\n\n\n\nImport of Clouclip data\n\n1path &lt;- \"data/Sample_Clouclip.csv\"\n2tz   &lt;- \"US/Central\"\n3dataCC &lt;- import$Clouclip(path, tz = tz, manual.id = \"Clouclip\")\n\n\n\n1\n\nDefine file path\n\n2\n\nTime zone in which device was recording (e.g., US Central Time)\n\n3\n\nImport Clouclip data\n\n\n\n\n\nSuccessfully read in 58'081 observations across 1 Ids from 1 Clouclip-file(s).\nTimezone set is US/Central.\nThe system timezone is Europe/Berlin. Please correct if necessary!\n\nFirst Observation: 2021-02-06 17:12:47\nLast Observation: 2021-02-14 17:12:36\nTimespan: 8 days\n\nObservation intervals: \n  Id       interval.time            n pct     \n1 Clouclip 5s                   54572 93.9601%\n2 Clouclip 17s                     12 0.0207% \n3 Clouclip 18s                     14 0.0241% \n4 Clouclip 120s (~2 minutes)     3479 5.9900% \n5 Clouclip 128s (~2.13 minutes)     1 0.0017% \n6 Clouclip 132s (~2.2 minutes)      1 0.0017% \n7 Clouclip 133s (~2.22 minutes)     1 0.0017% \n\n\n\n\n\n\n\n\nFigure 2: Overview plot of imported Clouclip data\n\n\n\n\n\nIn this code, import$Clouclip() reads the tab-delimited file and returns a tibble2 (saved in the variable dataCC) containing the data. We specify tz = \"US/Central\" because the device’s clock was set to U.S. Central time; this ensures that the Datetimevalues are properly interpreted with the correct time zone. The argument manual.id = \"Clouclip\" simply tags the dataset with an identifier (useful if combining data from multiple devices).\nDuring import, LightLogR automatically handles the Clouclip’s sentinel codes. The Date column from the raw file is parsed into a POSIXct date-time (Datetime) with the specified time zone. The Lux and Dis columns are read as numeric, but any occurrences of -1 or 204 are treated specially: these are replaced with NA (missing values) in the numeric columns, and corresponding status columns Lux_status and Dis_status are created to indicate the reason for those NA values. For example, if a Dis value of 204 was encountered, that row’s Dis will be set to NA and Dis_status will contain \"out_of_range\"; if Lux or Dis was -1, the status is \"sleep_mode\". We will set all other readings to  \"operational\" (meaning the device was functioning normally at that time) for visualisation purposes.\n\n\n\nPrint the first 6 rows of the Clouclip dataset\n\ndataCC |&gt; head()\n\n\n# A tibble: 6 × 7\n# Groups:   Id [1]\n  Id       file.name       Datetime              Dis   Lux Lux_status Dis_status\n  &lt;fct&gt;    &lt;chr&gt;           &lt;dttm&gt;              &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;     \n1 Clouclip Sample_Clouclip 2021-02-06 17:12:47    92    92 &lt;NA&gt;       &lt;NA&gt;      \n2 Clouclip Sample_Clouclip 2021-02-06 17:12:52    92    92 &lt;NA&gt;       &lt;NA&gt;      \n3 Clouclip Sample_Clouclip 2021-02-06 17:12:57    92    92 &lt;NA&gt;       &lt;NA&gt;      \n4 Clouclip Sample_Clouclip 2021-02-06 17:13:02    92    92 &lt;NA&gt;       &lt;NA&gt;      \n5 Clouclip Sample_Clouclip 2021-02-06 17:13:07    92    92 &lt;NA&gt;       &lt;NA&gt;      \n6 Clouclip Sample_Clouclip 2021-02-06 17:13:12    92    92 &lt;NA&gt;       &lt;NA&gt;      \n\n\nAfter import, it is good practice to get an overview of the data. The import function by default prints a brief summary (and generates an overview plot of the timeline) showing the number of observations, the time span, and any irregularities or large gaps. In our case, the Clouclip summary indicates the data spans one week and reveals that there are irregular intervals in the timestamps. This means some observations do not occur exactly every 5 seconds as expected. We can programmatically check for irregular timing:\n\n\n\nCheck if data are on a perfectly regular 5-second schedule\n\ndataCC |&gt; has_irregulars()\n\n\n[1] TRUE\n\n\nIf the result is TRUE, it confirms that the time sequence has deviations from the regular interval. Indeed, our example dataset has many small timing irregularities and gaps (periods with no data). Understanding the pattern of these missing or irregular readings is important. We can visualize them using a gap plot:\n\n\n\nPlot gaps and irregular timestamps for Clouclip data\n\ny.label &lt;- \"Distance (cm)\"\n1dataCC |&gt; gg_gaps(Dis,\n2                  include.implicit.gaps = FALSE,\n3                  show.irregulars = TRUE,\n                  y.axis.label = y.label,\n                  group.by.days = TRUE, col.irregular = alpha(\"red\", 0.03)\n                  ) + labs(title = NULL)\n\n\n\n1\n\nBasing the gap-figure on the Dis distance variable\n\n2\n\nOnly show missing observations (NA values)\n\n3\n\nHighlight irregular timing\n\n\n\n\n\n\n\n\n\n\nFigure 3: Visualization of gaps and irregular data. Black traces show available data. Red shaded areas show times of missing data. Red dots show instances where observations occur off the regular interval from start to finish, i.e., irregular data.\n\n\n\n\n\nIn Figure 3, time periods where data are missing appear as red-shaded areas, and any off-schedule observation times are marked with red dots. The Clouclip example shows extensive gaps (red blocks) on certain days and irregular timing on all days except the first and last. These irregular timestamps likely arise from the device’s logging process (e.g. slight clock drift or buffering when the device was turned on/off). Such issues must be addressed before further analysis.\nWhen faced with irregular or gapped data, we recommend a few strategies:\n\nRemove leading/trailing segments that cause irregularity. For example, if only the first day is regular and subsequent days drift, one might exclude the problematic portion using date filters (see filter_Date() / filter_Datetime() in LightLogR).\nRound timestamps to the nearest regular interval. This relabels slightly off-schedule times back to the 5-second grid (using cut_Datetime() with a 5-second interval), provided the deviations are small and this rounding won’t create duplicate timestamps.\nAggregate to a coarser time interval. For instance, grouping and averaging data into 1-minute bins with aggregate_Datetime() can mask irregularities at finer scales, at the cost of some temporal resolution.\n\nIn this case, the deviations from the 5-second schedule are relatively minor. We choose to round the timestamps to the nearest 5 seconds to enforce a uniform sampling grid, which simplifies downstream gap handling. We further add a separate date column for convenience:\n\n\n\nRegularize timestamps by rounding to nearest 5-second interval\n\ndataCC &lt;- dataCC |&gt;\n1  cut_Datetime(\"5 secs\", New.colname = Datetime) |&gt;\n2  add_Date_col(group.by = TRUE)\n\n\n\n1\n\nRound times to 5-second bins\n\n2\n\nAdd a Date column for grouping by day\n\n\n\n\nAfter this operation, all Datetime entries in dataCC align perfectly on 5-second boundaries (e.g. 08:00:00, 08:00:05, 08:00:10, etc.). We can verify that no irregular intervals remain by re-running has_irregulars():\n\n\n\nRe-check if data are on a perfectly regular 5-second schedule\n\ndataCC |&gt; has_irregulars()\n\n\n[1] FALSE\n\n\nNext, we want to quantify the missing data. LightLogR distinguishes between explicit missing values (actual NAs in the data, possibly from sentinel replacements or gaps we have filled in) and implicit missing intervals (time points where the device should have a reading but none was recorded, and we have not yet filled them in). See Figure 4 for a visual aid to these terms. Initially, many gaps are still implicit (between the first and last timestamp of each day).\n\n\n\n\n\n\n\n\nTerminology of gaps and irregular data in LightLogR\n\n\n\n\n\n\n\nHandling of gaps with LightLogR’s gap_handler() function\n\n\n\n\n\n\nFigure 4: Gaps and irregular data\n\n\n\nWe can generate a gap summary table:\n\n\n\nSummarize observed vs missing data by day for distance\n\ndataCC |&gt; gap_table(Dis, Variable.label = \"Distance (cm)\") |&gt;\n1  cols_hide(contains(\"_n\"))\n\n\n\n1\n\nHide absolute counts for brevity in output\n\n\n\n\n\n\nTable 1: Summary of missing and observed data for the Clouclip device\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSummary of available and missing data\n\n\nVariable: Distance (cm)\n\n\n\n\nData\n\n\nMissing\n\n\n\n\n\nRegular\n\n\nIrregular\n\n\nRange\n\n\nInterval\n\n\nGaps\n\n\nImplicit\n\n\nExplicit\n\n\n\nTime\n%\nn1,2\nTime\nTime\nN\nø\nTime\n%\nTime\n%\nTime\n%\n\n\n\n\nOverall\n2d 14h 43m 10s\n29.0%3\n0\n1w 2d\n5\n2,690\n1h 35m 57s\n6d 9h 16m 50s\n71.0%3\n5d 15h 19m 55s\n62.7%3\n17h 56m 55s\n8.3%3\n\n\nClouclip - 2021-02-06\n\n\n\n43m 30s\n3.0%\n0\n1d\n5s\n26\n53m 43s\n23h 16m 30s\n97.0%\n22h 53m 20s\n95.4%\n23m 10s\n1.6%\n\n\nClouclip - 2021-02-07\n\n\n\n2h 45m\n11.5%\n0\n1d\n5s\n139\n9m 10s\n21h 15m\n88.5%\n19h 42m 35s\n82.1%\n1h 32m 25s\n6.4%\n\n\nClouclip - 2021-02-08\n\n\n\n11h 13m 55s\n46.8%\n0\n1d\n5s\n443\n1m 44s\n12h 46m 5s\n53.2%\n10h 47m 50s\n45.0%\n1h 58m 15s\n8.2%\n\n\nClouclip - 2021-02-09\n\n\n\n8h 46m 25s\n36.6%\n0\n1d\n5s\n278\n3m 17s\n15h 13m 35s\n63.4%\n13h 50m\n57.6%\n1h 23m 35s\n5.8%\n\n\nClouclip - 2021-02-10\n\n\n\n7h 1m 30s\n29.3%\n0\n1d\n5s\n367\n2m 47s\n16h 58m 30s\n70.7%\n14h 18m 40s\n59.6%\n2h 39m 50s\n11.1%\n\n\nClouclip - 2021-02-11\n\n\n\n8h 31m 55s\n35.5%\n0\n1d\n5s\n423\n2m 12s\n15h 28m 5s\n64.5%\n11h 43m 30s\n48.9%\n3h 44m 35s\n15.6%\n\n\nClouclip - 2021-02-12\n\n\n\n12h 17m 55s\n51.2%\n0\n1d\n5s\n417\n1m 41s\n11h 42m 5s\n48.8%\n9h 17m 45s\n38.7%\n2h 24m 20s\n10.0%\n\n\nClouclip - 2021-02-13\n\n\n\n10h 32m 15s\n43.9%\n0\n1d\n5s\n527\n1m 32s\n13h 27m 45s\n56.1%\n10h 42m 10s\n44.6%\n2h 45m 35s\n11.5%\n\n\nClouclip - 2021-02-14\n\n\n\n50m 45s\n3.5%\n0\n1d\n5s\n70\n19m 51s\n23h 9m 15s\n96.5%\n22h 4m 5s\n92.0%\n1h 5m 10s\n4.5%\n\n\n\n1 If n &gt; 0: it is possible that the other summary statistics are affected, as they are calculated based on the most prominent interval.\n\n\n2 Number of (missing or actual) observations\n\n\n3 Based on times, not necessarily number of observations\n\n\n\n\n\n\n\n\n\n\n\nThis summary (Table 1) breaks down, for each day, how much data is present vs. missing. It reports the total duration of recorded data and the duration of gaps. After rounding the times, there are no irregular timestamp issues, but we see substantial implicit gaps — periods where the device was not recording (e.g., overnight when the device was likely not worn or was in sleep mode). Notably, the first and last days of the week have very little data (less than 1 hour each), since they probably represent partial recording days (the trial started and ended on those days).\nTo prepare the dataset for analysis, we will convert all those implicit gaps into explicit missing entries, and remove days that are mostly incomplete. Converting implicit gaps means inserting rows with NA for each missing 5-second slot, so that the time series becomes continuous and explicit about missingness (see Figure 4). We use gap_handler() for this, and then drop the nearly-empty days:\n\n\n\nConvert implicit gaps to explicit NA gaps, and drop days with &lt;1 hour of data\n\ndataCC &lt;- dataCC |&gt; \n1  mutate(across(c(Lux_status, Dis_status), ~ replace_na(.x, \"operational\"))) |&gt;\n2  gap_handler(full.days = TRUE) |&gt;\n3  remove_partial_data(Dis, threshold.missing = \"-1 hour\")\n\n\n\n1\n\nFirst ensure that status columns have an “operational” tag for non-missing periods\n\n2\n\nFill in all implicit gaps with explicit NA rows (for full days range)\n\n3\n\nRemove any day that has less than 1 hour of recorded data\n\n\n\n\nAfter these steps, dataCC contains continuous 5-second timestamps for each day that remains. We chose a threshold of “-1 hours” to remove days with less than one hour of data, which in this dataset removes the first and last (partial) days. The cleaned Clouclip data now covers six full days with bouts of continuous wear.\nIt is often helpful to double-check how the sentinel values and missing data are distributed over time. We can visualize the distance time-series with status annotations and day/night periods:\n\n\n\nVisualize observations and sentinel states\n\n1coordinates &lt;- c(29.75, -95.36)\ndataCC |&gt; \n2  fill(c(Lux_status, Dis_status), .direction = \"downup\") |&gt;\n3  gg_day(y.axis = Dis, geom = \"line\", y.axis.label = y.label) |&gt;\n4  gg_state(Dis_status, aes_fill = Dis_status, ymin = 0, ymax = 0.5, alpha = 1) |&gt;\n5  gg_photoperiod(coordinates, alpha = 0.1) +\n  theme(legend.position = \"bottom\")\n\n\n\n1\n\nSetting coordinates for Houston, Texas (recording location)\n\n2\n\nRetain status markers until a new marker arrives\n\n3\n\nCreate the basic plot\n\n4\n\nAdd the status times\n\n5\n\nAdd the photoperiod (day/night)\n\n\n\n\n\n\n\n\n\n\nFigure 5: Distance measurements across days. Blue, grey and yellow-colored bars at the bottom of each day show sentinel states of the device. Blue indicates an operational status, grey sleep mode (not recording), and yellow an out of range measurement. Shaded areas in the main plot show nighttime from civil dusk until dawn, which are calculated based on the recording date and geographic coordinates\n\n\n\n\n\nIn this plot, blue segments indicate times when the Clouclip was operational (actively measuring), grey segments indicate the device in sleep mode (no recording, typically at night), and yellow segments indicate out-of-range distance readings. The red outlined regions show nighttime (from civil dusk to dawn) based on the given latitude/longitude and dates. As expected, most of the grey “sleep” periods align with night hours, and we see a few yellow spans when the user’s viewing distance exceeded the device’s range (e.g. presumably when no object was within 100 cm, such as when the user looked into the distance). At this stage, the Clouclip dataset dataCC is fully preprocessed: all timestamps are regular 5-second intervals, missing data are explicitly marked, extraneous partial days are removed, and sentinel codes are handled via the status columns. The data are ready for calculating daily distance and light exposure metrics (as done in the main tutorial’s Results)."
  },
  {
    "objectID": "supplement.html#veet-data-ambient-light-illuminance-processing",
    "href": "supplement.html#veet-data-ambient-light-illuminance-processing",
    "title": "Supplement 1",
    "section": "3 VEET Data: Ambient Light (Illuminance) Processing",
    "text": "3 VEET Data: Ambient Light (Illuminance) Processing\nThe VEET device Sullivan et al. (2024) is a more complex logger that records multiple data modalities in one combined file. Its raw data file contains interleaved records for different sensor types, distinguished by a “modality” field. We focus first on the ambient light sensor modality (abbreviated ALS), which provides broad-spectrum illuminance readings (lux) and related information like sensor gains and flicker, recorded every 2 seconds. Later we will import the spectral sensor modality (PHO) for spectral irradiance data, and the time-of-flight modality (TOF) for distance data.\nIn the VEET’s export file, each line includes a timestamp and a modality code, followed by fields specific to that modality. Importantly, this means that the VEET export is not rectangular, i.e., tabular (see Figure 6). This makes it challenging for many import functions that expect the equal number of columns in every row, which is not the case in this instance. For the ALS modality, the relevant columns include a high-resolution timestamp (in Unix epoch format), integration time, UV/VIS/IR sensor gain settings, raw UV/VIS/IR sensor counts, a flicker measurement, and the computed illuminance in lux. For example, the ALS data columns are named: time_stamp, integration_time, uvGain, visGain, irGain, uvValue, visValue, irValue, Flicker, and Lux.\n\n\n\n\n\n\nFigure 6: Screenshot of the first rows of the VEET export file format as seen in a text editor\n\n\n\nFor the PHO (spectral) modality, the columns include a timestamp, integration time, a general Gain factor, and nine sensor channel readings covering different wavelengths (with names like s415, s445, ..., s680, s940) as well as a Dark channel and a broadband channel Clear. In essence, the VEET’s spectral sensor captures light in several wavelength bands (from ~415 nm up to 940 nm, plus an infrared and “clear” channel) rather than outputting a single lux value like the ambient light sensor does (PHO).\nTo import the VEET ambient light data, we again use the LightLogR import function, specifying the ALS modality. The raw VEET data in our example is provided as a zip file (01_VEET_L.csv.zip) containing the logged data for one week. We do the following:\n\n\n\nImport VEET Ambient Light Sensor (ALS) data\n\npath &lt;- \"data/01_VEET_L.csv.zip\"\ntz   &lt;- \"US/Central\"\n1dataVEET &lt;- import$VEET(path, tz = tz, modality = \"ALS\", manual.id = \"VEET\")\n\n\n\n1\n\nIn difference to the Clouclip file, we simply respecify the device type with import$VEET(...), but must also provide a modality argument.\n\n\n\n\n\nSuccessfully read in 304'193 observations across 1 Ids from 1 VEET-file(s).\nTimezone set is US/Central.\nThe system timezone is Europe/Berlin. Please correct if necessary!\n1 observations were dropped due to a missing or non-parseable Datetime value (e.g., non-valid timestamps during DST jumps). \n\nFirst Observation: 2024-06-04 15:00:37\nLast Observation: 2024-06-12 08:29:43\nTimespan: 7.7 days\n\nObservation intervals: \n  Id    interval.time              n pct      \n1 VEET  0s                         1 0.00033% \n2 VEET  1s                      1957 0.64334% \n3 VEET  2s                    300147 98.67025%\n4 VEET  3s                      2074 0.68181% \n5 VEET  4s                         3 0.00099% \n6 VEET  9s                         5 0.00164% \n7 VEET  10s                        3 0.00099% \n8 VEET  109s (~1.82 minutes)       1 0.00033% \n9 VEET  59077s (~16.41 hours)      1 0.00033% \n\n\n\n\n\n\n\n\nFigure 7: Overview plot of imported VEET data\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe get one warning as a single time stamp could not be parsed into a datetime - with ~300k observations, this is not an issue.\n\n\nThis call reads in only the lines corresponding to the ALS modality from the VEET file. The result dataVEET is a tibble3 with columns such as Datetime (parsed from the time_stamp  to POSIXct in US/Central time), Lux (illuminance in lux), Flicker, and the various sensor gains/values. Columns we don’t need for our analysis, like the modality code or file name, are also included but can be ignored or removed. From the import summary, we learn that the VEET light data, like the Clouclip, also exhibits irregularities and gaps. (The device nominally records every 2 seconds, but timing may drift or pause when not worn.)\n\n\n\nPrint the first 6 rows of the VEETs light dataset\n\ndataVEET |&gt; head()\n\n\n# A tibble: 6 × 14\n# Groups:   Id [1]\n  Id    Datetime            file.name     time_stamp modality integration_time\n  &lt;fct&gt; &lt;dttm&gt;              &lt;chr&gt;              &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt;\n1 VEET  2024-06-04 15:00:37 01_VEET_L.csv 1717531237 ALS                   100\n2 VEET  2024-06-04 15:00:39 01_VEET_L.csv 1717531239 ALS                   100\n3 VEET  2024-06-04 15:00:41 01_VEET_L.csv 1717531241 ALS                   100\n4 VEET  2024-06-04 15:00:43 01_VEET_L.csv 1717531243 ALS                   100\n5 VEET  2024-06-04 15:00:45 01_VEET_L.csv 1717531245 ALS                   100\n6 VEET  2024-06-04 15:00:47 01_VEET_L.csv 1717531247 ALS                   100\n# ℹ 8 more variables: uvGain &lt;dbl&gt;, visGain &lt;dbl&gt;, irGain &lt;dbl&gt;, uvValue &lt;dbl&gt;,\n#   visValue &lt;dbl&gt;, irValue &lt;dbl&gt;, Flicker &lt;dbl&gt;, Lux &lt;dbl&gt;\n\n\nTo make the VEET light data comparable to the Clouclip’s and to simplify analysis, we choose to aggregate the VEET illuminance data to 5-second intervals. This slight downsampling will both reduce data volume and remove irregularities.\n\n\n\nAggregate VEET light data to 5-second intervals and mark gaps\n\ndataVEET &lt;- dataVEET |&gt;\n1  aggregate_Datetime(unit = \"5 seconds\") |&gt;\n2  gap_handler(full.days = TRUE) |&gt;\n3  add_Date_col(group.by = TRUE) |&gt;\n4  remove_partial_data(Lux, threshold.missing = \"1 hour\")\n\n\n\n1\n\nResample to 5-sec bins (e.g. average Lux over 2-sec readings)\n\n2\n\nFill in implicit gaps with NA rows\n\n3\n\nAdd Date column for daily grouping\n\n4\n\nRemove participant days with more than one hour of missing data\n\n\n\n\nFirst, aggregate_Datetime(unit = \"5 seconds\") combines the high-frequency 2-second observations into 5-second slots. By default, this function will average numeric columns like Lux over each 5-second period (and have sensible defaults for strings or categorical data). All of these data type handlers can be changed with the function call. The result is that dataVEET now has a reading every 5 seconds (or an NA if none were present in that window). Next, gap_handler(full.days = TRUE) inserts explicit NA entries for any 5-second timestamp that had no data within the continuous span of the recording. Then we add a Date column for grouping, and finally we remove days with more than 1 hour of missing data (using a more strict criterion as we did for Clouclip). According to the gap summary (Table 2), this leaves six full days of VEET light data with good coverage, after dropping the very incomplete start/end days.\nWe can inspect the missing-data summary for the VEET illuminance data:\n\ndataVEET |&gt; gap_table(Lux, \"Illuminance (lx)\") |&gt; cols_hide(contains(\"_n\"))\n\n\n\nTable 2: Summary of missing and observed data for the VEET device, light modality\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSummary of available and missing data\n\n\nVariable: Illuminance (lx)\n\n\n\n\nData\n\n\nMissing\n\n\n\n\n\nRegular\n\n\nIrregular\n\n\nRange\n\n\nInterval\n\n\nGaps\n\n\nImplicit\n\n\nExplicit\n\n\n\nTime\n%\nn1,2\nTime\nTime\nN\nø\nTime\n%\nTime\n%\nTime\n%\n\n\n\n\nOverall\n5d 23h 57m 40s\n100.0%3\n0\n6d\n5\n8\n58s\n2m 20s\n0.0%3\n0s\n0.0%3\n2m 20s\n0.0%3\n\n\nVEET - 2024-06-06\n\n\n\n23h 58m 5s\n99.9%\n0\n1d\n5s\n3\n38s\n1m 55s\n0.1%\n0s\n0.0%\n1m 55s\n0.1%\n\n\nVEET - 2024-06-07\n\n\n\n1d\n100.0%\n0\n1d\n5s\n0\n0s\n0s\n0.0%\n0s\n0.0%\n0s\n0.0%\n\n\nVEET - 2024-06-08\n\n\n\n23h 59m 55s\n100.0%\n0\n1d\n5s\n1\n5s\n5s\n0.0%\n0s\n0.0%\n5s\n0.0%\n\n\nVEET - 2024-06-09\n\n\n\n23h 59m 50s\n100.0%\n0\n1d\n5s\n2\n5s\n10s\n0.0%\n0s\n0.0%\n10s\n0.0%\n\n\nVEET - 2024-06-10\n\n\n\n23h 59m 55s\n100.0%\n0\n1d\n5s\n1\n5s\n5s\n0.0%\n0s\n0.0%\n5s\n0.0%\n\n\nVEET - 2024-06-11\n\n\n\n23h 59m 55s\n100.0%\n0\n1d\n5s\n1\n5s\n5s\n0.0%\n0s\n0.0%\n5s\n0.0%\n\n\n\n1 If n &gt; 0: it is possible that the other summary statistics are affected, as they are calculated based on the most prominent interval.\n\n\n2 Number of (missing or actual) observations\n\n\n3 Based on times, not necessarily number of observations\n\n\n\n\n\n\n\n\n\n\n\nTable 2 shows, for each retained day, the total recorded duration and the duration of gaps. The VEET device, like the Clouclip, was not worn continuously 24 hours per day, so there are nightly gaps of wear time (when the device was likely off the participant), but not of recordings. After our preprocessing, any implicit gaps are represented as explicit missing intervals. The VEET’s time sampling was originally more frequent, but by aggregating to 5 s we have ensured a uniform timeline akin to the Clouclip’s.\nAt this point, the dataVEET object (for illuminance) is cleaned and ready for computing light exposure metrics. For example, one could calculate daily mean illuminance or the duration spent above certain light thresholds (e.g. “outdoor light exposure” defined as &gt;1000 lx) using this dataset. Indeed, basic summary tables in the main tutorial illustrate the highly skewed nature of light exposure data and the calculation of outdoor light metrics. We will not repeat those metric calculations here in the supplement, as our focus is on data preprocessing; however, having a cleaned, gap-marked time series is crucial for those metrics to be accurate.\n\n3.1 Identifying non-wear times\nNot all recorded time points of the VEET can be considered as wear time. Non-wear times should generally be removed from time series, if possible. There are several ways how Non-wear can be classified (Zauner et al. 2025):\n\nA device detects non-wear and does not record any measurements during non-wear times, or has a variable in the exported data to denote non-wear times. The Clouclip is an example here with the sleep mode sentinel state\nRecord non-wear separately, e.g. with a wear-log or diary. This is easy to implement, but puts a higher burden on participants and research staff, and can be error prone: forgotten, or incorrect data entries can mis-classify wear and non-wear times. For an implementation on how to remove non-wear times based on such a log, see, e.g., this tutorial.\nInstruct participants with a certain behavior when removing the device to ease automated detection of non-wear times in the data. These include putting a device in a black opaque bag, so that sensor readings for light are zero, or pressing an event button (if one exists). Up- and downsides are similar to the previous option, but the measures are usually harder to decipher in the data: when a buttonpress was forgotten, does that mess up the automated detection moving forward, which expects two presses per non-wear period (at beginning and at start). When there is zero lux during the day - was it in a black bag, or was this person just in a dark environment?\nAutomated detection by an algorithm. There are several possibilities to try to classify non-wear times based on the available data from a wearable. E.g., if there is an activity tracker, that can be used to determine periods of inactivity, which could indicate non-wear. If only light data is available, the standard deviation (or coefficient of variance) of light in a moving window of a few minutes can be used to determine low variance, which also indicates inactivity. Usually a histogram of values shows a spike in those periods of inactivity.\n\nIf datasets are large enough, i.e., collect data from a long enought period, non-wear has a diminishing effect, at least as daily metrics of light are concerned. E.g., in a monthlong study of 39 participants from Switzerland and Malaysia, (Biller et al. 2025) found that based on a sensitivity anaylsis up to 6 hours of data could be missing every day, and still the daily metrics across that month would not significantly change. This assumption only holds when non-wear times are not systematic, i.e., at the same time each day.\nWe will perform a simple variant of the third option, and look at the VEET’s IMU modality\n\n\n\nImport VEET activity (IMU) data\n\npath &lt;- \"data/01_VEET_L.csv.zip\"\ntz   &lt;- \"US/Central\"\ndataIMU &lt;- \n  import$VEET(path, tz = tz, modality = \"IMU\", manual.id = \"VEET\",\n1              remove_duplicates = TRUE,\n2              silent = TRUE)\n\n\n\n1\n\nSome rows in the data are duplicated. These will be removed during import\n\n2\n\nIn this instance, we skip the import summary\n\n\n\n\n15 duplicate rows were removed during import.\n\n\nTo get a quick feeling for the data, we visualize the activity variable for the x axis in Figure 8\n\n\n\nPlotting the IMU timeline\n\ndataIMU |&gt; \n  gg_days(ax, \n          aes_col = abs(ax) &lt; 1, \n          group = consecutive_id(abs(ax) &lt; 1),\n          y.axis.label = \"ax\"\n          )\n\n\n\n\n\n\n\n\nFigure 8: Timeline of the activity sensor (x direction)\n\n\n\n\n\nax seems to vary between ±10. In general, the periods of inactivity seem to lie within a band of ±1. However, simply choosing this band does not eliminate false detections during times of high movement. Some data transformations can make these more clear:\n\n\n\nPlotting a transformed IMU timeline\n\ndataIMU |&gt; \n  aggregate_Datetime(\n    \"5 mins\",\n    numeric.handler = sd\n  ) |&gt; \n  pivot_longer(cols = c(ax, ay, az)) |&gt; \n  group_by(name) |&gt; \n  gg_days(value, \n          aes_col = value &lt; 0.05,\n          group = consecutive_id(value &lt; 0.05),\n          y.axis.label = \"activity axes\"\n          )\n\n\n\n\n\n\n\n\nFigure 9: Timeline of the activity sensor (x direction) - transformed to distinguish times of low activity\n\n\n\n\n\nWhat Figure 9 shows is that the 5-minute standard deviation of the activity channels (x, y, and z direction) allows a pretty stable distinction between periods of high and low activity, with a threshold of 0.05. We can us this to create a wear column. As the choice of channel does not seem to matter much, we will use ax.\n\n\n\nCalculating times of wear and non-wear\n\nwear_data &lt;- \ndataIMU |&gt; \n1  aggregate_Datetime(\"5 mins\",numeric.handler = sd) |&gt;\n  mutate(wear = ax &gt; 0.05) |&gt;\n  select(Id, Datetime, wear) |&gt;\n2  extract_states(wear)\n3wear_data |&gt;\n  ungroup(Id) |&gt;\n  summarize_numeric(remove = c(\"start\", \"end\", \"epoch\")) |&gt;\n  gt()\nwear_data &lt;- wear_data |&gt; select(Id, wear, start, end)\n\n\n\n1\n\nCalculation of the wear-variable\n\n2\n\nExtracting the start and end times of wear and non-wear\n\n3\n\nSummarizing wear and non-wear times in a table\n\n\n\n\n\n\n\n\n\n\nwear\nmean_duration\ntotal_duration\nepisodes\n\n\n\n\nFALSE\n11447s (~3.18 hours)\n366300s (~4.24 days)\n32\n\n\nTRUE\n9431s (~2.62 hours)\n301800s (~3.49 days)\n32\n\n\n\n\n\n\n\nWe see that most of the recorded timespan is actually non-wear (including sleep), with an average wear time of 2.6 hours.\nLet’s add this data to the ALS dataset and visualize it in Figure 10\n\n\n\nPlotting non-wear for light\n\ndataVEET &lt;- \ndataVEET |&gt; \n  group_by(Id) |&gt; \n  add_states(wear_data)\n\ndataVEET |&gt; \n  gg_days(Lux) |&gt; \n  gg_states(wear, ymax = 0, alpha = 1, fill = \"red\")\n\n\n\n\n\n\n\n\nFigure 10: Wear times for light data, shown as red bars\n\n\n\n\n\nThis looks sensible, e.g., when we look at noon of 7 June 2024. We can remove these observations based on the wear column to make our summaries more valid.\n\n\n\nRemoving non-wear observations from light modality\n\ndataVEET &lt;- dataVEET |&gt; mutate(Lux = ifelse(wear, Lux, NA)) |&gt; group_by(Id, Date)"
  },
  {
    "objectID": "supplement.html#veet-data-spectral-data-processing",
    "href": "supplement.html#veet-data-spectral-data-processing",
    "title": "Supplement 1",
    "section": "4 VEET Data: Spectral Data Processing",
    "text": "4 VEET Data: Spectral Data Processing\n\n4.1 Import\nIn addition to broad-band illuminance and distance, the VEET provides spectral sensor data through its PHO modality. Unlike illuminance, the spectral data are not given as directly interpretable radiometric metrics but rather as raw sensor counts across multiple wavelength channels, which require conversion to reconstruct a spectral power distribution. In our analysis, spectral data allow us to compute metrics like the relative contribution of short-wavelength (blue) light versus long-wavelength light in the participant’s environment. Processing this spectral data involves several necessary steps.\nFirst, we import the spectral modality from a second VEET file. This time we need to extract the lines marked as PHO. We will store the spectral dataset in a separate object dataVEET2 so as not to overwrite the dataVEET illuminance data in our R session:\n\n\n\nImport VEET Spectral Sensor (PHO) data\n\npath &lt;- \"data/02_VEET_L.csv.zip\"\ndataVEET2 &lt;- import$VEET(path, tz = tz, modality = \"PHO\", manual.id = \"VEET\")\n\n\n\nSuccessfully read in 173'013 observations across 1 Ids from 1 VEET-file(s).\nTimezone set is US/Central.\nThe system timezone is Europe/Berlin. Please correct if necessary!\n\nFirst Observation: 2025-06-17 12:25:13\nLast Observation: 2025-06-21 22:47:01\nTimespan: 4.4 days\n\nObservation intervals: \n   Id    interval.time      n pct      \n 1 VEET  1s               417 0.24102% \n 2 VEET  2s            171837 99.32086%\n 3 VEET  3s               738 0.42656% \n 4 VEET  4s                 7 0.00405% \n 5 VEET  9s                 1 0.00058% \n 6 VEET  11s                1 0.00058% \n 7 VEET  12s                2 0.00116% \n 8 VEET  13s                4 0.00231% \n 9 VEET  15s                1 0.00058% \n10 VEET  16s                1 0.00058% \n# ℹ 3 more rows\n\n\n\n\n\n\n\n\nFigure 11: Overview plot of imported VEET data\n\n\n\n\n\n\n\n\nPrint the first 6 rows of the VEETs spectral dataset\n\ndataVEET2 |&gt; head()\n\n\n# A tibble: 6 × 18\n# Groups:   Id [1]\n  Id    Datetime            file.name time_stamp modality integration_time  Gain\n  &lt;fct&gt; &lt;dttm&gt;              &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt; &lt;dbl&gt;\n1 VEET  2025-06-17 12:25:13 02_VEET_… 1750181113 PHO                   100   512\n2 VEET  2025-06-17 12:25:17 02_VEET_… 1750181117 PHO                   100   512\n3 VEET  2025-06-17 12:25:19 02_VEET_… 1750181119 PHO                   100   512\n4 VEET  2025-06-17 12:25:21 02_VEET_… 1750181121 PHO                   100   512\n5 VEET  2025-06-17 12:25:23 02_VEET_… 1750181123 PHO                   100   512\n6 VEET  2025-06-17 12:25:25 02_VEET_… 1750181125 PHO                   100   512\n# ℹ 11 more variables: s415 &lt;dbl&gt;, s445 &lt;dbl&gt;, s480 &lt;dbl&gt;, s515 &lt;dbl&gt;,\n#   s555 &lt;dbl&gt;, s590 &lt;dbl&gt;, s630 &lt;dbl&gt;, s680 &lt;dbl&gt;, s910 &lt;dbl&gt;, Dark &lt;dbl&gt;,\n#   Clear &lt;dbl&gt;\n\n\nAfter import, data contains columns for the timestamp (Datetime), Gain (the sensor gain setting), and the nine spectral sensor channels plus a clear channel. These appear as numeric columns named s415, s445, ..., s940, Dark, Clear. Other columns are also present but not needed for now. The spectral sensor was logging at a 2-second rate. It is informative to look at a snippet of the imported spectral data before further processing. Table 3 shows three rows of data after import (before calibration), with some technical columns omitted for brevity:\n\n\n\nTable overview of spectral sensor data\n\ndataVEET2 |&gt; \n  slice(6000:6003) |&gt; \n  select(-c(modality, file.name, time_stamp)) |&gt; \n  gt() |&gt; \n  fmt_number(s415:Clear) \n\n\n\n\nTable 3: Overview of the spectral sensor import from the VEET device (3 observations). Each row corresponds to a 2-second timestamp (Datetime) and shows the raw sensor readings for the spectral channels (s415–s940, Dark, Clear). All values are in arbitrary sensor units (counts). Gain values and integration_time are also relevant for each interval, depending on the downstream computation.\n\n\n\n\n\n\n\n\n\nDatetime\nintegration_time\nGain\ns415\ns445\ns480\ns515\ns555\ns590\ns630\ns680\ns910\nDark\nClear\n\n\n\n\nVEET\n\n\n2025-06-18 00:11:22\n100\n512\n20.00\n27.00\n31.00\n42.00\n47.00\n63.00\n90.00\n139.00\n756.00\n0.00\n534.00\n\n\n2025-06-18 00:11:24\n100\n512\n21.00\n28.00\n31.00\n41.00\n47.00\n63.00\n90.00\n140.00\n756.00\n0.00\n534.00\n\n\n2025-06-18 00:11:26\n100\n512\n21.00\n27.00\n31.00\n41.00\n47.00\n63.00\n90.00\n139.00\n756.00\n0.00\n534.00\n\n\n2025-06-18 00:11:28\n100\n512\n21.00\n27.00\n31.00\n42.00\n47.00\n63.00\n90.00\n140.00\n755.00\n0.00\n534.00\n\n\n\n\n\n\n\n\n\n\n\n\n4.2 Spectral calibration\nNow we proceed with spectral calibration. The VEET’s spectral sensor counts need to be converted to physical units (spectral irradiance) via a calibration matrix provided by the manufacturer. For this example, we assume we have a calibration matrix that maps all the channel readings to an estimated spectral power distribution (SPD). The LightLogR package provides a function spectral_reconstruction() to perform this conversion. However, before applying it, we must ensure the sensor counts are in a normalized form. This procedure is laid out by the manufacturer. In our version, we refer to the VEET SPD Reconstruction Guide.pdf, version 06/05/2025. Note that each manufacturer has to specify the method of count normalization (if any) and spectral reconstruction. In our raw data, each observation comes with a Gain setting that indicates how the sensor’s sensitivity was adjusted; we need to divide the raw counts by the gain to get normalized counts. LightLogR offers normalize_counts() for this purpose. We further need to scale by integration time (in milliseconds) and adjust depending on counts in the Dark sensor channel.\n\n\n\nNormalize spectral sensor counts\n\n1count.columns &lt;- c(\"s415\", \"s445\", \"s480\", \"s515\", \"s555\", \"s590\", \"s630\",\n                      \"s680\", \"s910\", \"Dark\", \"Clear\")\n\n2gain.ratios &lt;-\n  tibble(\n    gain = c(0.5, 1, 2, 4, 8, 16, 32, 64, 128, 256, 512),\n    gain.ratio =\n      c(0.008, 0.016, 0.032, 0.065, 0.125, 0.25, 0.5, 1, 2, 3.95, 7.75)\n  )\n\n#normalize data:\ndataVEET2 &lt;-\n  dataVEET2 |&gt; \n3  mutate(across(c(s415:Clear), \\(x) (x - Dark)/integration_time)) |&gt;\n4  normalize_counts(\n5    gain.columns = rep(\"Gain\", 11),\n6    count.columns = count.columns,\n7    gain.ratios\n  ) |&gt; \n8  select(-c(s415:Clear)) |&gt;\n  rename_with(~ str_remove(.x, \".normalized\"))\n\n\n\n1\n\nColumn names of variables that need to be normalized\n\n2\n\nGain ratios as specified by the manufacturer’s reconstruction guide\n\n3\n\nRemove dark counts & scale by integration time\n\n4\n\nFunction to normalize counts\n\n5\n\nAll sensor channels share the gain value\n\n6\n\nSensor channels to normalize (see 1.)\n\n7\n\nGain ratios (see 2.)\n\n8\n\nDrop original raw count columns\n\n\n\n\nIn this call, we specified gain.columns = rep(\"Gain\", 11) because we have 11 sensor columns that all use the same gain factor column (Gain). This step will add new columns (with a suffix, e.g. .normalized) for each spectral channel representing the count normalized by the gain. We then dropped the raw count columns and renamed the normalized ones by dropping .normalized from the names. After this, dataVEET2 contains the normalized sensor readings for s415, s445, ..., s940, Dark, Clear for each time point time point.\nBecause we do not need this high a resolution, we will aggregate it to a 5-minute interval for computational efficiency. The assumption is that spectral composition does not need to be examined at every 2-second instant for our purposes, and 5-minute averages can capture the general trends while drastically reducing data size and downstream computational costs.\n\n\n\nAggregate spectral data to 5-minute intervals and mark gaps\n\ndataVEET2 &lt;- dataVEET2 |&gt;\n1  aggregate_Datetime(unit = \"5 mins\") |&gt;\n2  gap_handler(full.days = TRUE) |&gt;\n3  add_Date_col(group.by = TRUE) |&gt;\n4  remove_partial_data(Clear, threshold.missing = \"1 hour\")\n\n\n\n1\n\nAggregate to 5-minute bins\n\n2\n\nExplicit NA for any gaps in between\n\n3\n\nAdd a date identifier for grouping\n\n4\n\nremove days with more than one hour of data missing\n\n\n\n\nWe aggregate over 5-minute windows; within each 5-minute bin, multiple spectral readings (if present) are combined (averaged). We use one of the channels (here Clear) as the reference variable for remove_partial_data to drop incomplete days (the choice of channel is arbitrary as all channels share the same level of completeness).\n\n\n\n\n\n\nWarning\n\n\n\nPlease note that normalize_counts() requires the Gain values according to the gain table. If we had aggregated the data before normalizing it, Gain values would have been averaged within each bin (5 minutes in this case). If the Gain did not change in that time, it is not an issue. Any mix of Gain values will lead to a Gain value that is not represented in the gain table. While outputs for normalize_counts() are not wrong in these cases, they will output NA if a Gain value is not found in the table. Thus we recommend to always normalize counts based on the raw dataset.\n\n\n\n\n4.3 Spectral reconstruction\nFor spectral reconstruction, we require a calibration matrix that corresponds to the VEET’s sensor channels. This matrix would typically be obtained from the device manufacturer or a calibration procedure. It defines how each channel’s normalized count relates to intensity at various wavelengths. For demonstration, the calibration matrix was provided by the manufacturer and is specific to the make and model (see Figure 12). It should not be used for research purposes without confirming its accuracy with the manufacturer.\n\n\n\n\n\n\nFigure 12: Calibration matrix\n\n\n\n\n\n\nCalibration matrica and reconstruction of spectral power distribution\n\n1calib_mtx &lt;-\n  read_csv(\"data/VEET_calibration_matrix.csv\",\n           show_col_types = FALSE) |&gt;\n  column_to_rownames(\"wavelength\")\n\ndataVEET2 &lt;-\n  dataVEET2 |&gt; \n  mutate(\n  Spectrum = \n2    spectral_reconstruction(\n3      pick(s415:s910),\n4      calibration_matrix = calib_mtx,\n5      format = \"long\"\n  )\n)\n\n\n\n1\n\nImport the calibration matrix and make certain wavelength is set a rownames\n\n2\n\nThe function spectral_reconstruction() does not work on the level of the dataset, but has to be called within mutate()(or provided the data directly)\n\n3\n\nPick the normalized sensor columns\n\n4\n\nProvide the calibration matrix\n\n5\n\nReturn a long-form list column (wavelength, intensity)\n\n\n\n\nHere, we use format = \"long\" so that the result for each observation is a list-column Spectrum, where each entry is a tibble4 containing two columns: wavelength and irradiance (one row per wavelength in the calibration matrix). In other words, each row of dataVEET2 now holds a full reconstructed spectrum in the Spectrum column. The long format is convenient for further calculations and plotting. (An alternative format = \"wide\" would add each wavelength as a separate column, but that is less practical when there are many wavelengths.)\nTo visualize the data we will calculate the photopic illuminance based on the spectra and plot each spectrum color-scaled by their illuminance. For clarity, we reduce the data to observations within the day that has the most observations (non-NA).\n\n\n\nCalculate photopic illuminance\n\ndata_spectra &lt;- \ndataVEET2 |&gt; \n1  sample_groups(order.by = sum(!is.implicit)) |&gt;\n  mutate( \n2    Illuminance = Spectrum |&gt;\n3      map_dbl(spectral_integration,\n4              action.spectrum = \"photopic\",\n5              general.weight = \"auto\")\n  ) |&gt; \n6  unnest(Spectrum)\ndata_spectra |&gt; select(Id, Date, Datetime, Illuminance) |&gt; distinct()\n\n\n\n1\n\nKeep only observations for one day (with the lowest missing intervals)\n\n2\n\nUse the spectrum,…\n\n3\n\n… call the function spectral_integration() for each,…\n\n4\n\n… use the brightness sensitivity function,…\n\n5\n\n… and apply the appropriate efficacy weight.\n\n6\n\nCreate a long format of the data where the spectrum is unnested\n\n\n\n\n# A tibble: 288 × 4\n# Groups:   Id, Date [1]\n   Id    Date       Datetime            Illuminance\n   &lt;fct&gt; &lt;date&gt;     &lt;dttm&gt;                    &lt;dbl&gt;\n 1 VEET  2025-06-18 2025-06-18 00:00:00        3.70\n 2 VEET  2025-06-18 2025-06-18 00:05:00        3.79\n 3 VEET  2025-06-18 2025-06-18 00:10:00        3.72\n 4 VEET  2025-06-18 2025-06-18 00:15:00        6.90\n 5 VEET  2025-06-18 2025-06-18 00:20:00        3.53\n 6 VEET  2025-06-18 2025-06-18 00:25:00        3.26\n 7 VEET  2025-06-18 2025-06-18 00:30:00        3.59\n 8 VEET  2025-06-18 2025-06-18 00:35:00        3.49\n 9 VEET  2025-06-18 2025-06-18 00:40:00        3.54\n10 VEET  2025-06-18 2025-06-18 00:45:00        3.62\n# ℹ 278 more rows\n\n\nThe following plot visualizes the spectra:\n\n\n\nPlot spectra\n\ndata_spectra |&gt; \n  ggplot(aes(x = wavelength,group = Datetime)) +\n  geom_line(aes(y = irradiance*1000, col = Illuminance)) +\n  labs(y = \"Irradiance (mW/m²/nm)\", \n       x = \"Wavelength (nm)\", \n       col = \"Photopic illuminance (lx)\") +\n  scale_color_viridis_b(breaks = c(0, 10^(0:3))) +\n  scale_y_continuous(trans = \"symlog\", breaks = c(0, 1, 10, 50)) +\n  coord_cartesian(ylim = c(0,NA), expand = FALSE) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nFigure 13: Overview of the reconstructed spectra, color-scaled by photopic illuminance (lx)\n\n\n\n\n\nThe following ridgeline plot can be used to assess when in the day certain spectral wavelenghts are dominant:\n\n\n\nPlot spectra across the time of day\n\ndata_spectra |&gt; \n  ggplot(aes(x = wavelength, group = Datetime)) +\n  geom_ridgeline(aes(height = irradiance*1000, \n                     y = Datetime, \n                     fill = Illuminance), \n                 scale = 400, lwd = 0.1, alpha = 0.7) +\n  labs(y = \"Local time & Irradiance (mW/m²/nm)\", \n       x = \"Wavelength (nm)\", \n       fill = \"Photopic illuminance (lx)\")+\n  scale_fill_viridis_b(breaks = c(0, 10^(0:3))) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nFigure 14: Overview of the reconstructed spectra by time of day, color-scaled by photopic illuminance (lx)\n\n\n\n\n\nAt this stage, the dataVEET2 dataset has been processed to yield time-series of spectral power distributions. We can use these to compute biologically relevant light metrics. For instance, one possible metric is the proportion of power in short wavelengths versus long wavelengths.\nIn the main analysis, we defined short-wavelength (blue light) content as the integrated intensity in the 400–500 nm range, and long-wavelength content as the integrated intensity in a longer range (e.g. 600–700 nm), then computed the short-to-long ratio (“sl ratio”). Calculating these metrics is the first step of spectrum analysis in the main tutorial.\ndataVEET2 |&gt; \n  select(Id, Date, Datetime, Spectrum) |&gt;    # focus on ID, date, time, and spectrum\n  mutate(\n    short = Spectrum |&gt; map_dbl(spectral_integration, wavelength.range = c(400, 500)),\n    long  = Spectrum |&gt; map_dbl(spectral_integration, wavelength.range = c(600, 700)),\n    `sl ratio` = short / long   # compute short-to-long ratio\n  )\n(The cutoff of 500 nm here is hypothetical for demonstration; actual definitions might vary.) We would then have columns short, long, and sl_ratio for each observation, which could be averaged per day or analyzed further. The cleaned spectral data in dataVEET2 makes it straightforward to calculate such metrics or apply spectral weighting functions (for melatonin suppression, circadian stimulus, etc., if one has the spectral sensitivity curves).\nWith the VEET spectral preprocessing complete, we emphasize that these steps – normalizing by gain, applying calibration, and perhaps simplifying channels – are device-specific requirements. They ensure that the raw sensor counts are translated into meaningful physical measures (like spectral irradiance). Researchers using other spectral devices would follow a similar procedure, adjusting for their device’s particulars (some may output spectra directly, whereas others, like VEET, require reconstruction.\n\n\n\n\n\n\nNote\n\n\n\nSome devices may output normalized counts instead of raw counts. For example, the ActLumus device outputs normalized counts, while the VEET device records raw counts and the gain. Manufacturers will be able to speficy exact outputs for a given model and software version."
  },
  {
    "objectID": "supplement.html#veet-data-time-of-flight-distance",
    "href": "supplement.html#veet-data-time-of-flight-distance",
    "title": "Supplement 1",
    "section": "5 VEET Data: Time of flight (distance)",
    "text": "5 VEET Data: Time of flight (distance)\nIn this last section, the distance data of the VEET device will be imported, analogous to the other modalities. The TOF modality contains information for up to two objects in a 8x8 grid of measurements, spanning a total of about 52° vertically and 41° horizontally. Because the VEET device can detect up to two objects in a given grid point, and there is a confidence value assigned to every measurement, each observation contains \\(2*2*8*8 = 256\\) measurements.\n\n\n\nImport VEET Spectral Sensor (TOF) data\n\npath &lt;- \"data/01_VEET_L.csv.zip\"\ndataVEET3 &lt;- import$VEET(path, \n                        tz = tz, \n1                        modality = \"TOF\",\n2                        manual.id = \"VEET\"\n                        ) \n\n\n\n1\n\nmodality is a parameter only the VEET device requires. If uncertain, which devices require special parameters, have a look a the import help page (?import) under the VEET device. Setting it to TOF gives us the distance modality.\n\n2\n\nAs we are only dealing with one individual here, we set a manual Id\n\n\n\n\n\nSuccessfully read in 304'195 observations across 1 Ids from 1 VEET-file(s).\nTimezone set is US/Central.\nThe system timezone is Europe/Berlin. Please correct if necessary!\n\nFirst Observation: 2024-06-04 15:00:36\nLast Observation: 2024-06-12 08:29:43\nTimespan: 7.7 days\n\nObservation intervals: \n  Id    interval.time              n pct      \n1 VEET  0s                         3 0.00099% \n2 VEET  1s                      2089 0.68673% \n3 VEET  2s                    299876 98.58051%\n4 VEET  3s                      2213 0.72750% \n5 VEET  4s                         3 0.00099% \n6 VEET  6s                         1 0.00033% \n7 VEET  9s                         7 0.00230% \n8 VEET  109s (~1.82 minutes)       1 0.00033% \n9 VEET  59077s (~16.41 hours)      1 0.00033% \n\n\n\n\n\n\n\n\nFigure 15: Overview plot of imported VEET data\n\n\n\n\n\n\n\n\nPrint the first 6 rows of the VEETs distance dataset\n\ndataVEET3 |&gt; head()\n\n\n# A tibble: 6 × 261\n# Groups:   Id [1]\n  Id    Datetime            file.name     time_stamp modality conf1_0 conf1_1\n  &lt;fct&gt; &lt;dttm&gt;              &lt;chr&gt;              &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;   &lt;dbl&gt;\n1 VEET  2024-06-04 15:00:36 01_VEET_L.csv 1717531236 TOF           46      36\n2 VEET  2024-06-04 15:00:38 01_VEET_L.csv 1717531238 TOF           29      22\n3 VEET  2024-06-04 15:00:40 01_VEET_L.csv 1717531240 TOF            0       0\n4 VEET  2024-06-04 15:00:42 01_VEET_L.csv 1717531242 TOF            0       0\n5 VEET  2024-06-04 15:00:44 01_VEET_L.csv 1717531244 TOF            0       0\n6 VEET  2024-06-04 15:00:46 01_VEET_L.csv 1717531246 TOF           59      40\n# ℹ 254 more variables: conf1_2 &lt;dbl&gt;, conf1_3 &lt;dbl&gt;, conf1_4 &lt;dbl&gt;,\n#   conf1_5 &lt;dbl&gt;, conf1_6 &lt;dbl&gt;, conf1_7 &lt;dbl&gt;, conf1_8 &lt;dbl&gt;, conf1_9 &lt;dbl&gt;,\n#   conf1_10 &lt;dbl&gt;, conf1_11 &lt;dbl&gt;, conf1_12 &lt;dbl&gt;, conf1_13 &lt;dbl&gt;,\n#   conf1_14 &lt;dbl&gt;, conf1_15 &lt;dbl&gt;, conf1_16 &lt;dbl&gt;, conf1_17 &lt;dbl&gt;,\n#   conf1_18 &lt;dbl&gt;, conf1_19 &lt;dbl&gt;, conf1_20 &lt;dbl&gt;, conf1_21 &lt;dbl&gt;,\n#   conf1_22 &lt;dbl&gt;, conf1_23 &lt;dbl&gt;, conf1_24 &lt;dbl&gt;, conf1_25 &lt;dbl&gt;,\n#   conf1_26 &lt;dbl&gt;, conf1_27 &lt;dbl&gt;, conf1_28 &lt;dbl&gt;, conf1_29 &lt;dbl&gt;, …\n\n\nIn a first step, we condition the data similarly to the other VEET modalities. For computational reasons of the use cases, we remove the second object and set the interval to 10 seconds. Note that the next step still takes considerable computation time.\n\n\n\nAggregate distance data to 5-second intervals and mark gaps\n\ndataVEET3 &lt;- \n  dataVEET3 |&gt;\n1  select(-contains(c(\"conf2_\", \"dist2_\"))) |&gt;\n2  aggregate_Datetime(unit = \"5 secs\") |&gt;\n3  gap_handler(full.days = TRUE) |&gt;\n  add_Date_col(group.by = TRUE) |&gt; \n  remove_partial_data(dist1_0, threshold.missing = \"1 hour\")\ndataVEET3 |&gt; summary_overview(dist1_0)\n\n\n\n1\n\nRemove the second object (for computational reasons)\n\n2\n\nAggregate to 10-second bins\n\n3\n\nExplicit NA for any gaps\n\n\n\n\n# A tibble: 4 × 4\n  name                mean   min   max\n  &lt;chr&gt;              &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Participants           1    NA    NA\n2 Participant-days       6     6     6\n3 Days ≥80% complete     6     6     6\n4 Missing/Irregular      0     0     0\n\n\nIn the next step, we need to transform the wide format of the imported dataset into a long format, where each row contains exactly one observation for one grid-point.\n\n\n\nPivot distance grid from wide to long\n\ndataVEET3 &lt;- \n  dataVEET3 |&gt; \n  pivot_longer(\n    cols = -c(Datetime, file.name, Id, is.implicit, time_stamp, modality, Date),\n    names_to = c(\".value\", \"position\"),\n    names_pattern = \"(conf1|conf2|dist1|dist2)_(\\\\d+)\"\n  )\n\n\nIn a final step before we can use the data in the analysis, we need to assign x and y coordinates based on the position column that was created when pivoting longer. Positions are counted from 0 to 63 starting at the top right and increasing towards the left, before continuing on the right in the next row below. y positions thus depend on the row count, i.e., how often a row of 8 values fits into the position column. x positions consequently depend on the position within each 8-value row. We also add an observation variable that increases by +1 every time, the position column hits 0. We then center both x and y coordinates to receive meaningful values, i.e., 0° indicates the center of the overall measurement cone. Lastly, we convert both confidence columns, which are scaled from 0-255 into percentages by dividing them by 255. Empirical data from the manufacturer points to a threshold of about 10%, under which the respective distance data is not reliable.\n\n\n\nCalculate grid positions of spatial distance measurements\n\ndataVEET3 &lt;- \n  dataVEET3 |&gt; \n  mutate(position = as.numeric(position),\n1         y.pos = (position %/% 8)+1,\n2         y.pos = scale(y.pos, scale = FALSE)*52/8,\n3         x.pos = 8 - (position %% 8),\n4         x.pos = scale(x.pos, scale = FALSE)*41/8,\n5         observation = cumsum(position == 0),\n6         across(starts_with(\"conf\"), \\(x) x/255)\n         )\n\n\n\n1\n\nIncrement the y position for every 8 steps in position\n\n2\n\nCenter y.pos and rescale it to cover 52° across 8 steps\n\n3\n\nIncrement the x position for every step in position, resetting every 8 steps\n\n4\n\nCenter x.pos and rescale it to cover 41° across 8 steps\n\n5\n\nIncrease an observation counter every time we restart with position at 0\n\n6\n\nScale the confidence columns so that 255 = 100%\n\n\n\n\nNow this dataset is ready for further analysis. We finish by visualizing the same observation time on different days. Note that we replace zero distance values with Infinity, as these indicate measurements outside the 5m measurement radius of the device.\n\n\n\nPlot spatial distance grid for the same time point on each day\n\n1extras &lt;- list(\n  geom_tile(),\n  scale_fill_viridis_c(direction = -1, limits = c(0, 200),\n                       oob = scales::oob_squish_any),\n  scale_color_manual(values = c(\"black\", \"white\")),\n  theme_minimal(),\n  guides(colour = \"none\"),\n  geom_text(aes(label = (dist1/10) |&gt; round(0), colour = dist1&gt;1000),\n            size = 2.5),\n  coord_fixed(),\n  labs(x = \"X position (°)\", y = \"Y position (°)\",\n       fill = \"Distance (cm)\"))\n\n2slicer &lt;- function(x){seq(min((x-1)*64+1), max(x*64, by = 1))}\n\ndataVEET3 |&gt; \n3  slice(slicer(9530)) |&gt;\n4  mutate(dist1 = ifelse(dist1 == 0, Inf, dist1)) |&gt;\n5  filter(conf1 &gt;= 0.1 | dist1 == Inf) |&gt;\n6  ggplot(aes(x=x.pos, y=y.pos, fill = dist1/10))+ extras +\n7  facet_grid(~Datetime)\n\n\n\n1\n\nSet visualization parameters\n\n2\n\nAllows to choose an observation\n\n3\n\nChoose a particular observation\n\n4\n\nReplace 0 distances with Infinity\n\n5\n\nRemove data that has less than 10% confidence\n\n6\n\nPlot the data\n\n7\n\nShow one plot per day\n\n\n\n\n\n\n\n\n\n\nFigure 16: Example observations of the measurement grid at 1:14 p.m. for each measurement day. Text values show distance in cm. Empty grid points show values with low confidence. Zero-distance values were replaced with infinite distance and plotted despite low confidence.\n\n\n\n\n\nAs we can see from the figure, different days have - at a given time - a vastly different distribution of distance data, and measurement confidence (values with confidence &lt; 10% are removed)\n\n5.1 Removing non-wear times\nSame as for the ALS modality, we can remove times of non-wear - we can even use the same wear_data set for it:\n\n\n\nRemoving non-wear observations from distance modality\n\ndataVEET3 &lt;- \n  dataVEET3 |&gt; \n  group_by(Id) |&gt; \n  add_states(wear_data)\n\ndataVEET3 &lt;- \n  dataVEET3 |&gt; \n  mutate(dist1 = ifelse(wear, dist1, NA)) |&gt; \n  group_by(Id, Date)"
  },
  {
    "objectID": "supplement.html#saving-the-cleaned-data",
    "href": "supplement.html#saving-the-cleaned-data",
    "title": "Supplement 1",
    "section": "6 Saving the Cleaned Data",
    "text": "6 Saving the Cleaned Data\nAfter executing all the above steps, we have three cleaned data frames in our R session:\n\ndataCC – the processed Clouclip dataset (5-second intervals, with distance and lux, including NA for gaps and sentinel statuses).\ndataVEET – the processed VEET ambient light dataset (5-second intervals, illuminance in lux, with gaps filled).\ndataVEET2 – the processed VEET spectral dataset (5-minute intervals, each entry containing a spectrum or derived spectral metrics).\ndataVEET3 – the processed VEET distance dataset (5-second intervals, each entry containing the distance of up to two objects in the 8x8 grid).\n\nFor convenience and future reproducibility, we will save these combined results to a single R data file. Storing all cleaned data together ensures that any analysis can reload the exact same data state without re-running the import and cleaning (which can be time-consuming for large raw files).\n\n\n\nSave preprocessed files\n\n1if (!dir.exists(\"data/cleaned\")) dir.create(\"data/cleaned\", recursive = TRUE)\n2save(dataCC, dataVEET, dataVEET2, dataVEET3, file = \"data/cleaned/data.RData\")\n\n\n\n1\n\nCreate directory for cleaned data if it doesn’t exist\n\n2\n\nSave all cleaned datasets into one .RData file\n\n\n\n\nThe above code creates (if necessary) a folder data/cleaned/ and saves a single RData file (data.RData) containing the three objects. To retrieve them later, one can use &lt;- load(\"data/cleaned/data.RData\"), which will return the objects into the environment. This single-file approach simplifies sharing and keeps the cleaned data together.\nIn summary, this supplement has walked through the full preprocessing pipeline for two example devices. We began by describing the raw data format for each device and then demonstrated how to import the data with correct time zone settings. We handled device-specific quirks like sentinel codes (for Clouclip) and multiple modalities with gain normalization (for VEET). We showed how to detect and address irregular sampling, how to explicitly mark missing data gaps to avoid analytic pitfalls, and how to reduce data granularity via rounding or aggregation when appropriate. Throughout, we used functions from LightLogR in a tidyverse workflow, aiming to make the steps clear and modular. By saving the final cleaned datasets, we set the stage for the computation of visual experience metrics such as working distance, time in bright light, spectral composition ratios, as presented in the main tutorial. We hope this detailed tutorial empowers researchers to adopt similar pipelines for their own data, facilitating reproducible and accurate analyses of visual experience."
  },
  {
    "objectID": "supplement.html#footnotes",
    "href": "supplement.html#footnotes",
    "title": "Supplement 1",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nA sentinel value is a special placeholder value used in data recording to signal a particular condition. It does not represent a valid measured quantity but rather acts as a marker (for example, “device off” or “value out of range”).↩︎\ntibble are data.tables with tweaked behavior, ideal for a tidy analysis workflow. For more information, visit the documentation page for tibbles↩︎\ntibble are data.tables with tweaked behavior, ideal for a tidy analysis workflow. For more information, visit the documentation page for tibbles↩︎\ntibble are data.tables with tweaked behavior, ideal for a tidy analysis workflow. For more information, visit the documentation page for tibbles↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Analysis of human visual experience data",
    "section": "",
    "text": "Exposure to the optical environment — often referred to as visual experience — profoundly influences human physiology and behavior across multiple time scales. Two notable examples, from distinct research domains, can be understood through a common retinally-referenced framework.\nThe first example relates to the non-visual effects of light on human circadian and neuroendocrine physiology. The light–dark cycle entrains the circadian clock, and light exposure at night suppresses melatonin production (Brown et al. 2022; Blume, Garbazza, and Spitschan 2019). The second example concerns the influence of visual experience on ocular development, particularly myopia. Time spent outdoors — which features distinct optical environments — has been consistently associated with protective effects on ocular growth and health outcomes (Dahlmann-Noor et al. 2025).\nIn controlled laboratory settings, light exposure can be held constant or manipulated parametrically. In contrast, real-world conditions are inherently complex and dynamic, and cannot be captured by single spot measurements. As people move in and between spaces (indoors and outdoors) and move their body, head, and eyes, exposure to the optical environment varies significantly (Webler et al. 2019) and is modulated by behavior (Biller, Balakrishnan, and Spitschan 2024). Wearable devices for measuring light exposure have thus emerged as vital tools to capture the ecological visual experience. These tools generate high-dimensional datasets that demand rigorous and flexible analysis strategies.\nStarting in the 1980s (Okudaira, Kripke, and Webster 1983), technology to measure optical exposure has matured, with miniaturized illuminance sensors now (in 2025) very common in consumer wearables (van Duijnhoven et al. 2025). In research, several devices are available that differ in functionality, ranging from small pins measuring ambient illuminance (Mohamed et al. 2021) to head-mounted multi-modal devices capturing nearly all relevant aspects of visual experience (Gibaldi et al. 2024). Increased capabilities in wearables bring complex, dense datasets. These go hand-in-hand with a proliferation of metrics, as highlighted by recent review papers in both circadian and myopia research (Hönekopp and Weigelt 2023; Hartmeyer and Andersen 2023).\nAt present, the analysis processes to derive metrics are often implemented on a per-laboratory or even per-researcher basis. This fragmentation is a potential source of errors and inconsistencies between studies, consumes considerable researcher time (Hartmeyer, Webler, and Andersen 2022), and these bespoke processes and formats hinder harmonization or meta-analysis across multiple studies. It is very common that more time is spent preparing data than gaining insights through rigorous statistical analysis. These preparation tasks are best handled, or at least facilitated, by standardized, transparent, community-based analysis pipelines (J. Zauner, Udovicic, and Spitschan 2024).\nIn circadian research, the R package LightLogR was developed to address this need (J. Zauner, Hartmeyer, and Spitschan 2025). LightLogR is an open-source, MIT-licensed, community-driven package specifically designed for data from wearable light loggers and optical radiation dosimeters. It contains functions to calculate over sixty different metrics used in the field (Hartmeyer and Andersen 2023). The package functions come with light-related defaults, but they remain fundamentally agnostic to modality. As a result, parameters like viewing distance and light spectra, both highly relevant to myopia research (Hönekopp and Weigelt 2023), can easily be handled.\nIn this article, we demonstrate that LightLogR’s analysis pipelines and metric functions apply broadly across the field of visual experience research, not just to circadian rhythms and chronobiology. Our approach is modular and extensible, allowing researchers to adapt it to a variety of devices and research questions. Emphasis is placed on clarity, transparency, and reproducibility, aligning with best practices in scientific computing and open science. We use example data from two devices (worn by different individuals and at different times) to showcase the LightLogR workflow with metrics relevant to myopia research, covering working distance, (day)light exposure, and spectral analysis. Readers are encouraged to recreate the analysis using the provided code. All necessary data and code are openly available in the GitHub repository.\n\n\n\n\n\n\nTipScope\n\n\n\nThis article focuses on workflows for deriving condensed metrics from time-series data collected with wearable devices in the visual-experience domain. Specifically, we address illuminance, viewing distance, and spectral irradiance. Example datasets from two types of wearable devices are used for illustration.\nMany relevant considerations arise when collecting data with wearable devices. This article covers only a subset of these. In particular, it does not address:\n\ndevice selection (see, e.g., (van Duijnhoven et al. 2025; Johannes Zauner, Stefani, et al. 2025))\nmeasurement accuracy or device calibration\nauxiliary data such as sleep/wake information (see, e.g., (J. Zauner et al. 2025; Guidolin et al. 2024))\n\nMore information on those aspects can be found in the Technical guide for wearable optical radiation dosimetry and visual experience assessment (Johannes Zauner, Baraas, et al. 2025).\nTo demonstrate the workflows, this article uses expert-informed definitions of metrics and metric parameters (see, e.g., Table 1, Table 2, and the non-wear detection rules based on activity data described in Supplement 1). These definitions and thresholds should not be interpreted as universal standards, nor are they hard-coded into the software package. For any application, parameter choices must be tailored to the research domain, study context and design, and the specifications of the wearable device.\nFurther, the article is split up in the main analysis part, where all metrics are calculated, and the Supplement 1, where data is imported, screened, and prepared. Thus, the reader is referred to Supplement 1 for all aspects regarding data formats, preparation steps, and handling of gaps, i.e., missing data.\nLastly, the example data used in the article do not stem from a controlled experimental data collection but consist of pilot data gathered in an ecological setting without a fixed protocol. Given the substantial interindividual differences in visual experience metrics, and because the analyses focus on one participant at a time, the reported results should be interpreted as illustrative rather than representative of typical or population-level values."
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Analysis of human visual experience data",
    "section": "",
    "text": "Exposure to the optical environment — often referred to as visual experience — profoundly influences human physiology and behavior across multiple time scales. Two notable examples, from distinct research domains, can be understood through a common retinally-referenced framework.\nThe first example relates to the non-visual effects of light on human circadian and neuroendocrine physiology. The light–dark cycle entrains the circadian clock, and light exposure at night suppresses melatonin production (Brown et al. 2022; Blume, Garbazza, and Spitschan 2019). The second example concerns the influence of visual experience on ocular development, particularly myopia. Time spent outdoors — which features distinct optical environments — has been consistently associated with protective effects on ocular growth and health outcomes (Dahlmann-Noor et al. 2025).\nIn controlled laboratory settings, light exposure can be held constant or manipulated parametrically. In contrast, real-world conditions are inherently complex and dynamic, and cannot be captured by single spot measurements. As people move in and between spaces (indoors and outdoors) and move their body, head, and eyes, exposure to the optical environment varies significantly (Webler et al. 2019) and is modulated by behavior (Biller, Balakrishnan, and Spitschan 2024). Wearable devices for measuring light exposure have thus emerged as vital tools to capture the ecological visual experience. These tools generate high-dimensional datasets that demand rigorous and flexible analysis strategies.\nStarting in the 1980s (Okudaira, Kripke, and Webster 1983), technology to measure optical exposure has matured, with miniaturized illuminance sensors now (in 2025) very common in consumer wearables (van Duijnhoven et al. 2025). In research, several devices are available that differ in functionality, ranging from small pins measuring ambient illuminance (Mohamed et al. 2021) to head-mounted multi-modal devices capturing nearly all relevant aspects of visual experience (Gibaldi et al. 2024). Increased capabilities in wearables bring complex, dense datasets. These go hand-in-hand with a proliferation of metrics, as highlighted by recent review papers in both circadian and myopia research (Hönekopp and Weigelt 2023; Hartmeyer and Andersen 2023).\nAt present, the analysis processes to derive metrics are often implemented on a per-laboratory or even per-researcher basis. This fragmentation is a potential source of errors and inconsistencies between studies, consumes considerable researcher time (Hartmeyer, Webler, and Andersen 2022), and these bespoke processes and formats hinder harmonization or meta-analysis across multiple studies. It is very common that more time is spent preparing data than gaining insights through rigorous statistical analysis. These preparation tasks are best handled, or at least facilitated, by standardized, transparent, community-based analysis pipelines (J. Zauner, Udovicic, and Spitschan 2024).\nIn circadian research, the R package LightLogR was developed to address this need (J. Zauner, Hartmeyer, and Spitschan 2025). LightLogR is an open-source, MIT-licensed, community-driven package specifically designed for data from wearable light loggers and optical radiation dosimeters. It contains functions to calculate over sixty different metrics used in the field (Hartmeyer and Andersen 2023). The package functions come with light-related defaults, but they remain fundamentally agnostic to modality. As a result, parameters like viewing distance and light spectra, both highly relevant to myopia research (Hönekopp and Weigelt 2023), can easily be handled.\nIn this article, we demonstrate that LightLogR’s analysis pipelines and metric functions apply broadly across the field of visual experience research, not just to circadian rhythms and chronobiology. Our approach is modular and extensible, allowing researchers to adapt it to a variety of devices and research questions. Emphasis is placed on clarity, transparency, and reproducibility, aligning with best practices in scientific computing and open science. We use example data from two devices (worn by different individuals and at different times) to showcase the LightLogR workflow with metrics relevant to myopia research, covering working distance, (day)light exposure, and spectral analysis. Readers are encouraged to recreate the analysis using the provided code. All necessary data and code are openly available in the GitHub repository.\n\n\n\n\n\n\nTipScope\n\n\n\nThis article focuses on workflows for deriving condensed metrics from time-series data collected with wearable devices in the visual-experience domain. Specifically, we address illuminance, viewing distance, and spectral irradiance. Example datasets from two types of wearable devices are used for illustration.\nMany relevant considerations arise when collecting data with wearable devices. This article covers only a subset of these. In particular, it does not address:\n\ndevice selection (see, e.g., (van Duijnhoven et al. 2025; Johannes Zauner, Stefani, et al. 2025))\nmeasurement accuracy or device calibration\nauxiliary data such as sleep/wake information (see, e.g., (J. Zauner et al. 2025; Guidolin et al. 2024))\n\nMore information on those aspects can be found in the Technical guide for wearable optical radiation dosimetry and visual experience assessment (Johannes Zauner, Baraas, et al. 2025).\nTo demonstrate the workflows, this article uses expert-informed definitions of metrics and metric parameters (see, e.g., Table 1, Table 2, and the non-wear detection rules based on activity data described in Supplement 1). These definitions and thresholds should not be interpreted as universal standards, nor are they hard-coded into the software package. For any application, parameter choices must be tailored to the research domain, study context and design, and the specifications of the wearable device.\nFurther, the article is split up in the main analysis part, where all metrics are calculated, and the Supplement 1, where data is imported, screened, and prepared. Thus, the reader is referred to Supplement 1 for all aspects regarding data formats, preparation steps, and handling of gaps, i.e., missing data.\nLastly, the example data used in the article do not stem from a controlled experimental data collection but consist of pilot data gathered in an ecological setting without a fixed protocol. Given the substantial interindividual differences in visual experience metrics, and because the analyses focus on one participant at a time, the reported results should be interpreted as illustrative rather than representative of typical or population-level values."
  },
  {
    "objectID": "index.html#methods-and-materials",
    "href": "index.html#methods-and-materials",
    "title": "Analysis of human visual experience data",
    "section": "2 Methods and materials",
    "text": "2 Methods and materials\n\n2.1 Software\nThis tutorial was built with Quarto, an open-source scientific and technical publishing system that integrates text, code, and code output into a single document. The source code to reproduce all results is included and accessible via the Quarto document’s code tool menu. All analyses were conducted in R (version 4.5.0, “How About a Twenty-Six”) using LightLogR (version 0.10.0 “High noon”). We also used the tidyverse suite (version 2.0.0) for data manipulation (which LightLogR follows in its design), and the gt package (version 1.1.0) for generating summary tables. A comprehensive overview of the R computing environment is provided in the session info (see Session info section).\n\n\n2.2 Metric selection and definitions\nIn March 2025, two workshops with myopia researchers — initiated by the Research Data Alliance (RDA) Working Group on Optical Radiation Exposure and Visual Experience Data — focused on current needs and future opportunities in data analysis, including the development and standardization of metrics. Based on expert input from these workshops, the authors of this tutorial compiled a list of visual experience metrics, shown in Table 1. These include many currently used metrics and definitions (Wen et al. 2020, 2019; Bhandari and Ostrin 2020; Williams et al. 2019), as well as new metrics enabled by spectrally-resolved measurements. While they are not derived by a formal consensus process, they are expert-informed and used in current scientific research, and thus will serve as example-definitions for metrics and thresholds throughout this article.\n\n\n\nTable 1: Overview of metrics as they are used in this article. In all cases, the averages for weekday, weekend, and the mean daily value are calculated through mean_daily.\n\n\n\n\n\nNo.\nName\nImplementation1\n\n\n\n\n\nDistance\n\n\n\n1\nTotal wear time daily\ndurations()\n\n\n2\nDuration of\nNear work,\nIntermediate Work,\nNear + Intermediate Work, or\nper each Distance range\n(10cm steps)\nfilter for distance range +\ndurations() (for single ranges)\nor\ngrouping by distance range +\ndurations() (for all ranges)\n\n\n3\nFrequency of\nContinuous near work\nextract_clusters() +\nsummarize_numeric()\n\n\n4\nFrequency,\nduration,\nand distances of\nNear Work episodes\nextract_clusters() +\nextract_metric() +\nsummarize_numeric()\n\n\n5\nFrequency and duration of Visual breaks\nextract_clusters() +\nfilter\n\n\n\nLight\n\n\n\n6\nLight exposure (in lux)\nsummarize_numeric()\n\n\n7\nDuration per Outdoor range\ngrouping by Outdoor range +\ndurations()\n\n\n8\nThe number of times light level changes from indoor (&lt;1000 lx) to outdoor (&gt;1000 lx)\nextract_states() +\nsummarize_numeric()\n\n\n9\nLongest period above 1000 lx\nperiod_above_threshold()\n\n\n\nSpectrum\n\n\n\n10\nRatio of short vs. long wavelength light\nspectral_integration() +\nsummarize_numeric()\n\n\n11\nMelanopic daylight efficacy ratio (MDER)\nspectral_integration() +\nsummarize_numeric()\n\n\n12\nShort-wavelength light at certain times of day\nspectral_integration() +\nfilter_Time() (for defined times) or\ncut_Datetime() (for regular time intervals) or\nadd_photoperiod() (for solar times) +\ngrouping by time state +\nsummarize_numeric()\n\n\n\n\n\n\nTable 2 provides definitions for the terms used in Table 1. Note that specific definitions may vary depending on the research question or device capabilities.\n\n\n\nTable 2: Definitions of mean daily and conditions for distance and illuminance calculation as used in the article\n\n\n\n\n\n\n\n\n\nMetric\nDescription / pseudo formula\n\n\n\n\nTotal wear time\n\\(\\sum(t)*dt, \\textrm{ where } t\\textrm{: valid observations }\\)\n\n\nMean daily\n\\(\\frac{5*\\bar{\\textrm{weekday}} + 2*\\bar{weekend}}{7}\\)\n\n\nNear work\n\\(\\textrm{working distance}, [15,60)cm\\)\n\n\nIntermediate Work\n\\(\\textrm{working distance}, [60,100)cm\\)\n\n\nTotal work2\n\\(\\textrm{working distance}, [15,120)cm\\)\n\n\nDistance range\n\\(\\textrm{working distance}, {[15,20)cm \\textrm{,  Extremely near} \\\\ [20,30)cm \\textrm{,  Very near} \\\\ [30,40)cm \\textrm{,  Fairly near} \\\\ [40,50)cm \\textrm{,  Near} \\\\ [50,60)cm \\textrm{,  Moderately near} \\\\ [60,70)cm \\textrm{,  Near intermediate} \\\\ [70,80)cm \\textrm{,  Intermediate} \\\\ [80,90)cm \\textrm{,  Moderately intermediate} \\\\ [90,100)cm \\textrm{,  Far intermediate}}\\)\n\n\nContinuous near work\n\\(\\textrm{working distance}, [20,60)cm,\\)\n\\(T_\\textrm{duration} ≥ 30 minutes, \\textrm{ }T_{interruptions} ≤ 1 minute\\)\n\n\nNear work episodes\n\\(\\textrm{working distance}, [20,60)cm,\\)\n\\(T_\\textrm{interruptions} ≤ 20 seconds\\)\n\n\nRatio of daily near work\n\\(\\frac{T_\\textrm{near work}}{T_\\textrm{total wear}}\\)\n\n\nVisual break\n\\(\\textrm{working distance} ≥ 100cm, \\\\ T_\\textrm{duration} ≥ 20 seconds, \\textrm{ }T_\\textrm{previous episode} ≤ 20 minutes\\)\n\n\nOutdoor range\n\\(\\textrm{illuminance}, {[1000,2000)lx \\textrm{,  Outdoor bright} \\\\ [2000,3000)lx \\textrm{,  Outdoor very bright} \\\\ [3000, \\infty) lx \\textrm{,  Outdoor extremely bright}}\\)\n\n\nLight exposure3\n\\(\\bar{illuminance}\\)\n\n\nSpectral bands\n\\(\\textrm{spectral irradiance}, {[380,500]nm \\textrm{,  short wavelength light} \\\\ [600, 780]nm \\textrm{,  long wavelength light}}\\)\n\n\nRatio of short vs. long wavelength light\n\\(\\frac{E_{e\\textrm{,short wavelength}}}{E_{e\\textrm{,long wavelength}}}\\)\n\n\n\n\n\n\nIt should be noted that although daylight levels can far exceed the thresholds defined in Table 2 - and may reach or even exceed 10^5 lux - empirical daylight levels measured at eye level are much lower, typically around 10^3 lux, especially when considering aggregated time-series data over minutes to hours.\n\n\n2.3 Devices\nData from two wearable devices are used in this analysis:\n\nClouclip: A wearable device that measures viewing distance and ambient light simultaneously [Glasson Technology Co., Ltd, Hangzhou, China; Wen et al. (2021); Wen et al. (2020)]. The Clouclip provides a simple data output with only distance (working distance, in centimeters) and illuminance (ambient light, in lux). Data in our example were recorded at 5-second intervals. Approximately one week of data (~120,960 observations) is about 1.6 MB in size.\nVisual Environment Evaluation Tool (VEET): A head-mounted multi-modal device that logs multiple data streams [Reality Labs Research, Menlo Park, CA, USA; Sah, Narra, and Ostrin (2025); Sullivan et al. (2024)]. The VEET dataset used here contains simultaneous measurements of distance (via a time-of-flight sensor), ambient light (illuminance), activity (accelerometer & gyroscope), and spectral irradiance (multi-channel light sensor). Data were recorded at 2-second intervals, yielding a very dense dataset (~270 MB per week).\n\n\n\n2.4 Data processing summary\nThe Results section uses imported and pre-processed data from the two devices to calculate metrics. Supplement 1 contains the annotated code and description for the steps involved. The following summarizes the steps involved, please refer to the supplement for details:\nData import: We imported raw data from the Clouclip and VEET devices using LightLogR’s built-in import functions, which automatically handle device-specific formats and idiosyncrasies.\nThe Clouclip export file (provided as a tab-delimited text file) contains timestamped records of distance (cm) and illuminance (lux). LightLogR’s import$Clouclip function reads this file, after specifying the device’s recording timezone, and converts device-specific sentinel codes into proper missing values. For instance, the Clouclip uses special numeric codes to indicate when it is in “sleep mode” or when a reading is out of the sensor’s range, rather than recording a normal value. LightLogR identifies -1 (for both distance and lux) as indicating the device’s sleep mode and 204 (for distance) as indicating the object was beyond the measurable range, replacing these with NA and logging their status in separate columns. The import routine also provides an initial summary of the dataset, including start and end times and any irregular sampling intervals or gaps.\nFor the VEET device, data were provided as CSV logs (zipped on Github, due to size). We focused on the ambient light sensor modality first. Using import$VEET(..., modality = \"ALS\"), we extracted the illuminance (Lux) data stream and its timestamps. The raw VEET data similarly contains irregular intervals and can contain missing periods (e.g., if the device stopped recording or was reset); the import summary flags these issues.\nBesides the Clouclip and VEET, LightLogR 0.10.0 contains import functions for 18 more wearable devices. The package further supports versions due to evolving data formats, and includes documentation for both code-based and code-less additions of new device import-functions.\nIrregular intervals, gaps, non-wear times: Both datasets showed irregular timing and missing data, i.e., gaps. Irregular data means that some observations did not align to the nominal sampling interval (e.g., slight timing drift or pauses in recording). For the Clouclip 5-second data, we detected irregular timestamps spanning all but the first and last day of the recording. Handling such irregularities is important because many downstream analyses assume a regular time series. We evaluated strategies to address this, including:\n\nRemoving an initial portion of data if irregularities occur mainly during device start-up.\nRounding all timestamps to the nearest regular interval (5 s in this case).\nAggregating to a coarser time interval (with some loss of temporal resolution).\n\nBased on the import summary and visual inspection of the time gaps, we chose to round the observation times to the nearest 5-second mark, as this addressed the minor offsets without significant data loss. After rounding timestamps, we added an explicit date column for convenient grouping by day.\nWe then generated a summary of missing data for each day. Implicit gaps (intervals where the device should have recorded data but did not) were converted into explicit missing entries using LightLogR’s gap-handling functions. We also removed days that had very little data to focus on days with substantial wear time. In our Clouclip example, days with &lt;1 hour of recordings were dropped. This threshold should be adjusted based on how much complete days matter for a given analysis at hand. E.g., in circadian science, the metrics of interdaily stability and intradaily variation require measurements for each hour of the day.\nAfter these preprocessing steps, the Clouclip dataset had no irregular timestamps remaining and contained explicit markers for all periods of missing data (e.g., times when the device was off or not worn). The distance and illuminance values were now ready for metric calculations. Because the device was put in sleep mode when not worn, there are no measurements during non-wear times.\nThe VEET illuminance data underwent a similar cleaning procedure. To make the VEET’s 2-second illuminance data more comparable to the Clouclip’s and to reduce computational load, we aggregated the illuminance time series to 5-second intervals. Aggregation was performed with the arithmetic mean of values in a 5-second bin. We then inserted explicit missing entries for each whole day and removed days with more than one hour of missing illuminance data. After cleaning, six days of VEET illuminance data with good coverage remained for analysis (see Supplement 1 for details).\nFinally, for spectral analysis, we imported the VEET’s spectral sensor modality, and, for the distance analysis, the time-of-flight modality. This required additional processing: the raw spectral data consists of counts from 10 wavelength-specific channels (approximately 415 nm through 940 nm, unequally spaced between 30 and 50 nm, plus one broadband clear channel covering the whole range of individual channels and a dark channel) along with a sensor gain setting. We aggregated the spectral data to 5-minute intervals to focus on broader trends and reduce data volume. Each channel’s counts were normalized by the appropriate gain. Using a calibration matrix provided by the manufacturer (specific to the spectral sensor model), we reconstructed full spectral power distributions for each 5-minute interval. The end result is a list-column in the dataset where each entry is the estimated spectral irradiance across wavelengths for that time interval. Detailed spectral preprocessing steps, including the calibration and normalization, are provided in the Supplement 1. After spectral reconstruction, the dataset was ready for calculating example spectrum-based metrics.\nSimilarly, the time-of-flight modality contains 256 values per observation, encoding an 8x8 grid of distance and confidence measurements for up to two objects (8x8 grid, times two objects, times distance + confidence column for each object and grid point -&gt; 256 values). For computational reasons, only the first object was kept. These data were pivoted into a long format, where each row contains the distance and confidence data for a given position in the grid and a given datetime. After pivoting and converting grid positions into a deviation angle from central view, the dataset was ready to be used for distance analysis.\nBecause the VEET devices record even when not worn, a non-wear detection using the devices’ actigraphy modality was implemented. This process used the standard deviation of a linear motion sensor in a 5-minute bin with a visually derived threshold to separate wear from non-wear time. Measurements of illuminance and distance were consequently removed during the calculated non-wear times.\nThis tutorial will start by importing a Clouclip dataset and providing an overview of the data. The Clouclip export is considerably simpler compared to the VEET export, only containing Distance and Illuminance measurements. The VEET dataset will be imported later for the spectrum related metrics.\n\n\n\nLoad libraries and preprocessed data\n\nlibrary(LightLogR)\nlibrary(tidyverse)\nlibrary(gt)\nload(\"data/cleaned/data.RData\")\n\n\n\n\n\nStore coordinates of data collection\n\n1coordinates &lt;- c(29.75, -95.36)\n\n\n\n1\n\nCoordinates for Houston, Texas; coordinates are important to calculate and visualize photoperiods later"
  },
  {
    "objectID": "index.html#results",
    "href": "index.html#results",
    "title": "Analysis of human visual experience data",
    "section": "3 Results",
    "text": "3 Results\n\n3.1 Distance\nWe first examine metrics related to viewing distance, using the processed Clouclip dataset. Many distance-based metrics are computed for each day and then averaged over weekdays, weekends, or across all days. To facilitate this, we define a helper function that will take daily metric values and calculate the mean values for weekdays, weekends, and the overall daily average:\n\n\n\nDefine helper function to_mean_daily()\n\nto_mean_daily &lt;- function(data, prefix = \"average_\") {\n  data |&gt; \n1    ungroup(Date) |&gt;\n2    mean_daily(prefix = prefix) |&gt;\n3    rename_with(.fn = \\(x) str_replace_all(x,\"_\",\" \")) |&gt;\n4    gt()\n}\n\n\n\n1\n\nUngroup by days\n\n2\n\nCalculate the averages per grouping\n\n3\n\nRemove underscores in names\n\n4\n\nFormat as a gt table for display\n\n\n\n\n\n3.1.1 Total wear time daily\nTotal wear time daily refers to the amount of time the device was actively collecting distance data each day (i.e. the time the device was worn and operational). We compute this by summing all intervals where a valid distance measurement is present, ignoring periods where data are missing or the device was off. The results are shown in Table 3.\n\n\n\nCalculate total wear time\n\ndataCC |&gt; \n1  durations(Dis) |&gt;\n2  to_mean_daily(\"Total wear \")\n\n\n\n1\n\nCalculate total duration of data per day\n\n2\n\nUsing the helper function defined above\n\n\n\n\n\n\nTable 3: Total wear time per day (average across days)\n\n\n\n\n\n\n\n\n\nDate\nTotal wear duration\n\n\n\n\nClouclip\n\n\nMean daily\n31448s (~8.74 hours)\n\n\nWeekday\n34460s (~9.57 hours)\n\n\nWeekend\n23918s (~6.64 hours)\n\n\n\n\n\n\n\n\n\n\n\n\n3.1.2 Duration within distance ranges\nMany myopia-relevant metrics concern the time spent at certain viewing distances (e.g., “near work” vs. intermediate or far distances). We calculate the duration of time spent in specific distance ranges. Table 4 shows the average daily duration of near work, defined here as time viewing at 15–60 cm. Table 5 provides a more detailed breakdown across multiple distance bands.\n\nDuration of near workDuration within distance ranges\n\n\n\n\n\nCalculate daily duration of near work\n\ndataCC |&gt; \n1  filter(Dis &gt;= 15, Dis &lt; 60) |&gt;\n2  durations(Dis) |&gt;\n  to_mean_daily(\"Near work \")\n\n\n\n1\n\nConsider only distances in [15, 60) cm\n\n2\n\nTotal duration in that range per day\n\n\n\n\n\n\nTable 4: Daily duration of near work (15–60 cm viewing distance)\n\n\n\n\n\n\n\n\n\nDate\nNear work duration\n\n\n\n\nClouclip\n\n\nMean daily\n17309s (~4.81 hours)\n\n\nWeekday\n21173s (~5.88 hours)\n\n\nWeekend\n7648s (~2.12 hours)\n\n\n\n\n\n\n\n\n\n\n\n\nFirst, we define a set of distance breakpoints and descriptive labels for each range:\n\n\n\nDefining distance ranges (in cm)\n\ndist_breaks &lt;- c(15, 20, 30, 40, 50, 60, 70, 80, 90, 100, Inf)\ndist_labels &lt;- c(\n    \"Extremely near\",          # [15, 20)\n    \"Very near\",               # [20, 30)\n    \"Fairly near\",             # [30, 40)\n    \"Near\",                    # [40, 50)\n    \"Moderately near\",         # [50, 60)\n    \"Near intermediate\",       # [60, 70)\n    \"Intermediate\",            # [70, 80)\n    \"Moderately intermediate\", # [80, 90)\n    \"Far intermediate\",        # [90, 100)\n    \"Far\"                      # [100, Inf)\n  )\n\n\nNow we cut the distance data into these ranges and compute the daily duration spent in each range:\n\n\n\nCalculate daily duration within viewing distance range\n\ndataCC |&gt; \n1  mutate(Dis_range = cut(Dis, breaks = dist_breaks, labels = dist_labels)) |&gt;\n2  drop_na(Dis_range) |&gt;\n3  group_by(Dis_range, .add = TRUE) |&gt;\n4  durations(Dis) |&gt;\n5  pivot_wider(names_from = Dis_range, values_from = duration) |&gt;\n  ungroup() |&gt; \n  mean_daily(prefix = \"\") |&gt; \n  pivot_longer(-Date) |&gt; \n  pivot_wider(names_from = Date) |&gt; \n  mutate(name = factor(name, levels = rev(dist_labels))) |&gt; \n  arrange(name) |&gt; \n  gt() |&gt; \n6  fmt_duration(input_units = \"seconds\", output_units = \"minutes\")\n\n\n\n1\n\nCategorize distances\n\n2\n\nRemove intervals with no data\n\n3\n\nGroup by distance range (in addition to the date)\n\n4\n\nDuration per range per day\n\n5\n\nPivot data from long to wide format (ranges as columns)\n\n6\n\nConvert seconds to minutes\n\n\n\n\n\n\nTable 5: Daily duration in each viewing distance range\n\n\n\n\n\n\n\n\n\nname\nMean daily\nWeekday\nWeekend\n\n\n\n\nFar\n16m\n20m\n5m\n\n\nFar intermediate\n11m\n14m\n2m\n\n\nModerately intermediate\n5m\n6m\n3m\n\n\nIntermediate\n4m\n6m\n1m\n\n\nNear intermediate\n7m\n7m\n8m\n\n\nModerately near\n13m\n16m\n5m\n\n\nNear\n27m\n36m\n5m\n\n\nFairly near\n46m\n60m\n12m\n\n\nVery near\n102m\n128m\n38m\n\n\nExtremely near\n74m\n88m\n40m\n\n\n\n\n\n\n\n\n\n\nTo visualize this, Figure 1 illustrates the relative proportion of time spent in each distance range:\n\n\n\nPlot time spent within each viewing distance range\n\ndataCC |&gt; \n1  mutate(Dis_range = cut(Dis, breaks = dist_breaks, labels = dist_labels)) |&gt;\n  drop_na(Dis_range) |&gt;\n  group_by(Dis_range, .add = TRUE) |&gt;\n  durations(Dis) |&gt;\n  group_by(Dis_range) |&gt;\n  mean_daily(prefix = \"\") |&gt;\n  ungroup() |&gt;\n  mutate(Dis_range = forcats::fct_relabel(Dis_range, \\(x) str_replace(x, \" \", \"\\n\"))) |&gt; \n2  mutate(duration = duration/sum(duration), .by = Date) |&gt;\n  ggplot(aes(x = Dis_range, y = duration, fill = Date)) +\n  geom_col(position = \"dodge\") +\n  scale_y_continuous(labels = scales::label_percent()) +\n  ggsci::scale_fill_jco() +\n  theme_minimal() +\n  labs(y = \"Relative duration (%)\", x = NULL, fill = NULL) +\n  coord_flip()\nggsave(\"manuscript/figures/Figure1.png\",\n                width = 7,\n                height = 5)\n\n\n\n1\n\nBroadly, this portion repeats the prior code cell\n\n2\n\nConvert to percentage of daily total\n\n\n\n\n\n\n\n\n\n\nFigure 1: Percentage of total time spent in each viewing distance range for an average day (mean daily), average weekday, or weekend\n\n\n\n\n\n\n\n\n\n\n3.1.3 Frequency of continuous near work\nContinuous near-work can be understood as sustained viewing within a near distance for some minimum duration, allowing only brief interruptions. We use LightLogR’s cluster function to identify episodes of continuous near work. Here, we define a near-work episode as viewing distance between 20 cm and 60 cm that lasts at least 30 minutes, with interruptions of up to 1 minute allowed (meaning short breaks ≤1 min do not end the episode). Using extract_clusters() with those parameters, we count how many such episodes occur per day.\nTable 6 summarizes the average frequency of continuous near-work episodes per day, and Figure 2 provides an example visualization of these episodes on the distance time series.\n\n\n\nCalculate the frequency of continuous near-work episodes per day\n\ndataCC |&gt; \n  extract_clusters(\n1    Dis &gt;= 20 & Dis &lt; 60,\n2    cluster.duration = \"30 mins\",\n3    interruption.duration = \"1 min\",\n4    drop.empty.groups = FALSE\n  ) |&gt; \n  summarize_numeric(remove = c(\"start\", \"end\", \"epoch\", \"duration\"),\n5                    add.total.duration = FALSE) |&gt;\n6  mean_daily(prefix = \"Frequency of \") |&gt;\n  gt() |&gt; fmt_number() \n\n\n\n1\n\nCondition: near-work distance\n\n2\n\nMinimum duration of a continuous episode\n\n3\n\nMaximum gap allowed within an episode\n\n4\n\nKeep days with zero episodes in output\n\n5\n\nCount number of episodes per day\n\n6\n\nCompute daily mean frequency\n\n\n\n\n\n\nTable 6: Frequency of continuous near-work episodes per day\n\n\n\n\n\n\n\n\n\nDate\nFrequency of episodes\n\n\n\n\nClouclip\n\n\nMean daily\n0.86\n\n\nWeekday\n1.20\n\n\nWeekend\n0.00\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlot continuous near-work episodes\n\n1dataCC |&gt;\n  add_clusters(\n    Dis &gt;= 20 & Dis &lt; 60,\n    cluster.duration = \"30 mins\",\n    interruption.duration = \"1 min\"\n  ) |&gt;\n  gg_day(y.axis = Dis, y.axis.label = \"Distance (cm)\", geom = \"line\",\n         y.scale = \"identity\", y.axis.breaks = seq(0,100, by = 20)) |&gt; \n2  gg_photoperiod(coordinates) |&gt;\n3  gg_state(state, fill = \"red\") +\n  geom_hline(yintercept = c(20, 60), col = \"red\", linetype = \"dashed\") +\n  coord_cartesian(ylim = c(0,100))\n\n\n\n1\n\nAs in code cell above\n\n2\n\nAdd photoperiod information\n\n3\n\nAdd state bands\n\n\n\n\n\n\n\n\n\n\nFigure 2: Example of continuous near-work episodes. Red shaded areas indicate periods of continuous near work (20–60 cm for ≥30 min, allowing ≤1 min interruptions). Black trace is viewing distance over time; red dashed lines mark the 20 cm and 60 cm boundaries. Grey shaded areas indicate nighttime.\n\n\n\n\n\n\n\n3.1.4 Near-work episodes\nBeyond frequency, we can characterize near-work episodes by their duration and typical viewing distance. This section extracts all near-work episodes (using a 5-second minimum duration to capture more routine near-work bouts) and summarizes three aspects:\n\nfrequency (count of episodes per day),\naverage duration of episodes, and\naverage distance during those episodes.\n\nThese results are combined in Table 7.\n\n\n\nCalculate near-work episodes\n\ndataCC |&gt; \n  extract_clusters(\n    Dis &gt;= 20 & Dis &lt; 60,\n1    cluster.duration = \"5 secs\",\n    interruption.duration = \"20 secs\",\n    drop.empty.groups = FALSE\n  ) |&gt; \n2  extract_metric(dataCC, distance = mean(Dis, na.rm = TRUE)) |&gt;\n3  summarize_numeric(remove = c(\"start\", \"end\", \"epoch\"),\n                    prefix = \"\",\n                    add.total.duration = FALSE) |&gt;\n4  mean_daily(prefix = \"\") |&gt;\n5  gt() |&gt;\n  fmt_number(c(distance, episodes), decimals = 0) |&gt;\n  cols_units(distance = \"cm\")\n\n\n\n1\n\nMinimal duration to count as an episode (set to interval level of dataCC)\n\n2\n\nCalculate mean distance during each episode\n\n3\n\nCalculate averages for all numeric columns per group\n\n4\n\nDaily averages for each metric\n\n5\n\nTable generation\n\n\n\n\n\n\nTable 7: Near-work episodes: frequency, mean duration, and mean viewing distance\n\n\n\n\n\n\n\n\n\nDate\nduration\ndistance, cm\nepisodes\n\n\n\n\nClouclip\n\n\nMean daily\n233s (~3.88 minutes)\n32\n57\n\n\nWeekday\n284s (~4.73 minutes)\n32\n64\n\n\nWeekend\n104s (~1.73 minutes)\n32\n40\n\n\n\n\n\n\n\n\n\n\n\nIn the code cell above, extract_metric(..., distance = mean(Dis, ...)) computes the mean viewing distance during each episode, and the subsequent summarize_numeric and mean_daily steps derive daily averages of episode count, duration, and distance.\n\n\n\n3.1.5 Visual breaks\nVisual breaks as defined in this article, require a minimum break-length, and the previous episode is important. This leads to a two step process, where we first extract instances of Distance above 100 cm for at least 20 seconds, before we filter for a previous duration of at maximum 20 minutes. Table 8 provides the daily frequency of visual breaks.\n\n\n\nCalculate visual breaks\n\ndataCC |&gt; \n1  extract_clusters(Dis &gt;= 100,\n2                   cluster.duration = \"20 secs\",\n3                   return.only.clusters = FALSE,\n4                   drop.empty.groups = FALSE\n                   ) |&gt; \n5  filter((start - lag(end) &lt;= duration(\"20 mins\")), is.cluster) |&gt;\n6  summarize_numeric(remove = c(\"start\", \"end\", \"epoch\", \"is.cluster\", \"duration\"),\n                    prefix = \"\",\n                    add.total.duration = FALSE) |&gt;\n7  mean_daily(prefix = \"Daily \") |&gt;\n8  gt() |&gt;\n  fmt_number(decimals = 1)\n\n\n\n1\n\nDefine the condition, greater 100 cm away\n\n2\n\nDefine the minimum duration\n\n3\n\nReturn non-clusters as well\n\n4\n\nKeep all days, even without clusters\n\n5\n\nReturn only clusters with previous episode lengths of maximum 20 minutes\n\n6\n\nCount the number of episodes\n\n7\n\nCalculate daily means\n\n8\n\nTable generation\n\n\n\n\n\n\nTable 8: Frequency of visual breaks\n\n\n\n\n\n\n\n\n\nDate\nDaily episodes\n\n\n\n\nClouclip\n\n\nMean daily\n5.9\n\n\nWeekday\n6.2\n\n\nWeekend\n5.0\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlot visual breaks\n\n1dataCC |&gt;\n    extract_clusters(Dis &gt;= 100,\n                   cluster.duration = \"20 secs\",\n                   return.only.clusters = FALSE,\n                   drop.empty.groups = FALSE\n                   ) |&gt;\n  filter((start - lag(end) &lt;= duration(\"20 mins\")), is.cluster) %&gt;%\n2  add_states(dataCC, ., ) |&gt;\n  gg_day(y.axis = Dis, y.axis.label = \"Distance (cm)\", geom = \"line\") |&gt; \n3  gg_photoperiod(coordinates) +\n  geom_point(data = \\(x) filter(x, is.cluster), col = \"red\")\n\n\n\n1\n\nAs in the code cell above\n\n2\n\nAdd the resulting states\n\n3\n\nAdd photoperiod information to the plot\n\n\n\n\n\n\n\n\n\n\nFigure 3: Plot of visual breaks (red dots). Black traces show distance measurement data. Grey shaded areas show nighttime between civil dusk and civil dawn\n\n\n\n\n\n\n\n3.1.6 Distance with spatial distribution\nThe Clouclip device outputs a singular measure for distance, while the visual environment in natural conditions contains many distances, depending on the solid angle and direction of the measurement. A device like the VEET increases the spatial resolution of these measurements, allowing for more in-depth analyses of the size and position of an object within the field of view. In the case of the VEET, data are collected from an 8x8 measurement grid, spanning 52° vertically and 41° horizontally. Here are sample observations from six different days at the same time.\n\n\n\nPlot spatial distance grids for different days\n\ndataVEET3 |&gt; \n1  filter_Time(start = \"13:14:02\", length = \"00:00:05\") |&gt;\n2  mutate(dist1 = ifelse(dist1 == 0, Inf, dist1)) |&gt;\n3  filter(conf1 &gt;= 0.1 | dist1 == Inf) |&gt;\n4  ggplot(aes(x=x.pos, y=y.pos, fill = dist1/10))+\n  extras +\n5  facet_wrap(~Datetime)\n\n\n\n1\n\nChoose a particular observation\n\n2\n\nReplace 0 distances with infinity\n\n3\n\nRemove data that has less than 10% confidence\n\n4\n\nPlot the data and add the plot partials from the code cell above\n\n5\n\nShow one plot per day\n\n\n\n\n\n\n\n\n\n\nFigure 4: Example observations of the measurement grid at 1:14 p.m. for each measurement day. Text values show distance in cm. Empty grid points show values with low confidence. Zero-distance values were replaced with infinite distance and plotted despite low confidence.\n\n\n\n\n\nTo use these distance data in the framework shown above for the Clouclip device, a sensible method to condense the data has to be applied. There are many ways how a spatially resolved distance measure could be utilized for analysis:\n\nWhere in the field of view are objects in close range?\nHow large are near objects in the field of view?\nHow varied are distances within the field of view?\nHow close are objects / is viewing distance in a region of interest within the field of view?\n\nPossible methods include:\n\naverage across all (high confidence) distance values within the grid\nclosest (high confidence) distance within the grid\n(high confidence) values at or around a given grid position, e.g., ±10 degrees around the central view (0°)\n\nMany more options are available based on the spatial dataset, e.g., condensation rules based on the number of points in the grid with a given condition, or the variation within the grid.\nWe will demonstrate these three methods for a single day (2024-06-10), all leading to a data structure akin to the Clouclip, i.e., to be used for further calculation of visual experience metrics.\n\n\n\nCalculating and plotting method results\n\n1dataVEET3_part &lt;-\ndataVEET3 |&gt;\n  filter_Date(start = \"2024-06-10\", length = \"1 day\")\n\ndataVEET3_condensed &lt;- \ndataVEET3_part |&gt; \n2  group_by(Datetime, .add = TRUE) |&gt;\n3  filter(conf1 &gt;= 0.1) |&gt;\n  summarize(\n4    distance_mean = mean(dist1),\n5    distance_min = min(dist1),\n6    distance_central = mean(dist1[between(x.pos, -10,10) & between(y.pos, -10,10)]),\n7    n = n(),\n    .groups = \"drop_last\"\n  )\n\ndataVEET3_condensed |&gt; \n8  aggregate_Datetime(\"15 mins\", numeric.handler = \\(x) mean(x, na.rm = TRUE)) |&gt;\n9  remove_partial_data(by.date = TRUE) |&gt;\n10  pivot_longer(contains(\"distance\"),\n               names_to = c(\".value\", \"method\"),\n    names_pattern = \"(distance)_(mean|min|max|central)\"\n    ) |&gt;\n11  gg_day(y.axis = distance/10,\n         geom = \"line\",\n         aes_col = method,\n         group = method,\n         linewidth = 1,\n         alpha = 0.75,\n         y.scale = \"identity\",\n         y.axis.breaks = seq(0,150, by = 20),\n         y.axis.label = \"Distance (cm)\"\n         ) |&gt;\n  gg_photoperiod(coordinates)\n\n\n\n1\n\nFilter one day\n\n2\n\nGroup additionally by every observation\n\n3\n\nRemove data with low confidence\n\n4\n\nAverage across all distance values\n\n5\n\nClosest across all distance values\n\n6\n\nCentral distance\n\n7\n\nNumber of (valid) grid points\n\n8\n\nAggregate to 15 minute data\n\n9\n\nRemove data points that fall exactly on midnight of the following day\n\n10\n\nPivoting the method results from wide to long for plotting\n\n11\n\nSetting up the plot for distance.\n\n\n\n\n\n\n\n\n\n\nFigure 5: Comparison of condensation methods for spatial grid of distance measurements. The lines represent an average across all data points (yellow), the minimum distance (grey), or the central 10° (blue). Data points with confidence less than 10% were removed prior to calculation.\n\n\n\n\n\nAs can be seen in Figure 5, while the overall pattern is similar regardless of the used method, there are notable differences between the methods, which will consequently affect downstream analyses. Most importantly, the process of condensation has to be well documented and reproducible, as shown above. Any of these data could now be used to calculate the frequency of continuous near work, visual breaks, or near-work episodes as described above.\n\n\n\n3.2 Light\nThe Clouclip illuminance data in our example cover indoor environments and are thus comparatively low, which would make certain daylight exposure summaries trivial or not meaningful. To better illustrate light exposure metrics, we turn to a different dataset, this one taken from the VEET device’s illuminance data, which capture a broader range of lighting conditions (though both device types are able to capture broadly the same range of illuminance). We import the VEET ambient light data (already preprocessed to have regular 5-second intervals as described above) and briefly examine its distribution.\nIlluminance distribution: The illuminance values from the Clouclip were comparatively low, while the VEET data include outdoor exposures up to several thousand lux. The contrast is evident from comparing histograms of the two datasets’ lux values (Clouclip vs. VEET), where the main peak is similarly positioned between 10 and 100 lx, but the tails differ. The VEET illuminance histogram (see Figure 7) shows a heavily skewed distribution with a considerable number of zero lx values (indicating intervals of complete darkness or the sensor being covered) and a long tail extending to very high lux values. Such zero-inflated and skewed data are common in wearable light measurements (J. Zauner, Guidolin, and Spitschan).\n\n\n\n\n\n\n\n\n\nFigure 6: Histogram of illuminance values from the Clouclip dataset (5-second data). The values are typical of indoor conditions.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 7: Histogram of illuminance values from the VEET dataset (aggregated to 5 s). Note the logarithmic x-axis: the distribution is highly skewed with many low values (including zeros) and a long tail of high lux readings. Outdoor light exposures in bright conditions are distinguishable around 10^3 to 10^4 lx.\n\n\n\n\nAfter confirming that the VEET data cover a broad dynamic range of lighting, we proceed with calculating light exposure metrics. (The VEET data had been cleaned for gaps and irregularities as described earlier, and non-wear times were removed; see Supplement 1 for the details.)\n\n3.2.1 Average light exposure\nA basic metric is the average illuminance over the day. Table 9 shows the mean illuminance (in lux) for weekdays, weekends, and the overall daily mean, calculated directly from the raw lux values.\n\n\n\nCalculating mean light exposure per day\n\ndataVEET |&gt; \n  select(Id, Date, Datetime, Lux) |&gt; \n  summarize_numeric(prefix = \"mean \", remove = c(\"Datetime\")) |&gt; \n  to_mean_daily() |&gt;\n  fmt_number(decimals = 1) |&gt; \n  cols_hide(`average episodes`) |&gt;\n  cols_label(`average mean Lux` = \"Mean photopic illuminance (lx)\")\n\n\n\n\nTable 9: Mean light exposure (illuminance) per day\n\n\n\n\n\n\n\n\n\nDate\nMean photopic illuminance (lx)\n\n\n\n\nVEET\n\n\nMean daily\n481.8\n\n\nWeekday\n538.1\n\n\nWeekend\n341.1\n\n\n\n\n\n\n\n\n\n\nHowever, because illuminance data tend to be extremely skewed and contain many zero values (periods of darkness), the arithmetic mean can be misleading. A common approach is to apply a logarithmic transform to illuminance before averaging, which down-weights extreme values and accounts for the multiplicative nature of light intensity effects. LightLogR provides helper functions log_zero_inflated() and its inverse exp_zero_inflated() to handle log-transformation when zeros are present (by adding a small offset before log, and back-transforming after averaging). Using this approach, we recompute the daily mean illuminance. The results in Table 10 show that the log-transformed mean (back-transformed to lux) is much lower, reflecting the fact that for much of the time illuminance was near zero. This transformed mean is often more representative of typical exposure for skewed data.\n\n\n\nCalculating mean light exposure per day with log transformation\n\ndataVEET |&gt; \n  select(Id, Date, Datetime, Lux) |&gt; \n1  mutate(Lux = Lux |&gt; log_zero_inflated()) |&gt;\n  summarize_numeric(prefix = \"mean \", remove = c(\"Datetime\")) |&gt; \n2  mean_daily(prefix = \"\") |&gt;\n3  mutate(`mean Lux` = `mean Lux` |&gt; exp_zero_inflated()) |&gt;\n  gt() |&gt; fmt_number(decimals = 1) |&gt; cols_hide(episodes) |&gt; \n  cols_label(`mean Lux` = \"Mean photopic illuminance (lx)\")\n\n\n\n1\n\nLog transform with zero handling (base 10)\n\n2\n\nCalculate daily mean of log-lux\n\n3\n\nBack-transform to lux\n\n\n\n\n\n\nTable 10: Mean light exposure per day (after logarithmic transformation to account for zero inflation and skewness)\n\n\n\n\n\n\n\n\n\nDate\nMean photopic illuminance (lx)\n\n\n\n\nVEET\n\n\nMean daily\n57.0\n\n\nWeekday\n70.1\n\n\nWeekend\n33.9\n\n\n\n\n\n\n\n\n\n\n\n\n3.2.2 Duration in high-light (outdoor) conditions\nAnother important metric is the amount of time spent under bright light, often used as a proxy for outdoor exposure. We define thresholds corresponding to outdoor light levels (e.g. 1000 lx and above). Here, we categorize each 5-second interval of illuminance into bands: Outdoor bright (≥1000 lx), Outdoor very bright (≥2000 lx), and Outdoor extremely bright (≥3000 lx). We then sum the duration in each category per day.\nWhile daylight levels can far exceed the recorded light levels, those are usually recorded with direct sunlight and without obstruction. Under normal viewing conditions, at eye level, and avoiding glare, daylight levels of a few thousand lux are at the higher end of the distribution (Murukesu, Zauner, and Spitschan 2025). Figure 7 shows a bimodal distribution, with the right mode representing outdoor lighting conditions. In a 2023 review of light dosimeters to investigate the light-myopia relationship (Hönekopp and Weigelt 2023), 1000 lx was the predominant cutoff value to distinguish indoor vs. outdoor environments. It is not, however, without critique, and both other thresholds (Patterson Gentile et al. 2025) and classification methods are proposed (Tabandeh and Spitschan 2025).\n\n\n\nDefine outdoor illuminance thresholds (in lux)\n\nout_breaks &lt;- c(0, 1e3, 2e3, 3e3, Inf)\nout_labels &lt;- c(\n    \"Indoor\",                  # [0, 1000) lx\n    \"Outdoor bright\",          # [1000, 2000) lx\n    \"Outdoor very bright\",     # [2000, 3000) lx\n    \"Outdoor extremely bright\" # [3000, ∞) lx\n  )\n\ndataVEET &lt;- dataVEET |&gt; \n  mutate(Lux_range = cut(Lux, breaks = out_breaks, labels = out_labels))\n\n\nNow we compute the mean daily duration spent in each of these outdoor light ranges (Table 11):\n\n\n\nCalculate the mean daily duration spent in each light range\n\ndataVEET |&gt; \n  drop_na(Lux_range) |&gt; \n  group_by(Lux_range, .add = TRUE) |&gt; \n  durations(Lux) |&gt;                         \n  pivot_wider(names_from = Lux_range, values_from = duration) |&gt; \n  to_mean_daily(\"\") |&gt; \n  fmt_duration(input_units = \"seconds\", output_units = \"minutes\")\n\n\n\n\nTable 11: Average daily duration in outdoor-equivalent light conditions\n\n\n\n\n\n\n\n\n\nDate\nIndoor\nOutdoor bright\nOutdoor very bright\nOutdoor extremely bright\n\n\n\n\nVEET\n\n\nMean daily\n663m\n24m\n28m\n42m\n\n\nWeekday\n688m\n29m\n35m\n48m\n\n\nWeekend\n602m\n10m\n10m\n28m\n\n\n\n\n\n\n\n\n\n\nIt is also informative to visualize when these high-light conditions occurred. Figure 8 shows a timeline plot with periods of outdoor-level illuminance highlighted in color. In this example, violet denotes ≥1000 lx, green ≥2000 lx, and yellow ≥3000 lx. Grey shading indicates nighttime (from civil dusk to dawn) for context.\n\n\n\nVisualize time spent outdoors\n\ndataVEET |&gt; \n1  aggregate_Datetime(\"2 mins\", type = \"floor\") |&gt;\n2  mutate(Lux_range = fct_recode(Lux_range, NULL = \"Indoor\")) |&gt;\n3  gg_day(y.axis = Lux,\n         y.axis.label = \"Photopic illuminance (lx)\",\n         geom = \"line\",\n         jco_color = FALSE) |&gt;\n4  gg_state(Lux_range, aes_fill = fct_rev(Lux_range),\n           alpha = 0.75, ymin = 10^3, ymax = 10^4) +\n  scale_fill_viridis_d() +\n  labs(fill = \"Illuminance range\") +\n  theme(legend.position = \"bottom\") +\n5  coord_cartesian(xlim = c(8, 19.5)*3600)\n\n\n\n1\n\nAggregating data to 5-minute bins\n\n2\n\nRemoving the indoor condition\n\n3\n\nSetting up the basic plot\n\n4\n\nAdding state information on the illuminance ranges\n\n5\n\nSetting the x-axis limits to cover daytime hours\n\n\n\n\n\n\n\n\n\n\nFigure 8: Outdoor light exposure over time with 2-minute interval. Colored bands indicate periods when illuminance exceeded outdoor thresholds for at least half of each interval: violet for ≥1000 lx, green for ≥2000 lx, and yellow for ≥3000 lx. Grey shaded regions denote night (from civil dusk to dawn).\n\n\n\n\n\n\n\n3.2.3 Frequency of transitions from indoor to outdoor light\nWe next consider how often the subject moved from an indoor light environment to an outdoor-equivalent environment. We operationally define an “outdoor transition” as a change from &lt;1000 lx to ≥1000 lx. Using the cleaned VEET data, we extract all instances where illuminance crosses that threshold from below to above.\nTable 12 shows the average number of such transitions per day. Note that if data are recorded at a fine temporal resolution (5 s here), very brief excursions above 1000 lx could count as transitions and inflate this number. Indeed, the initial count is fairly high, reflecting fleeting spikes above 1000 lx that might not represent meaningful outdoor exposures.\n\n\n\nCalculate the number of transitions from indoor to outdoor\n\ndataVEET |&gt; \n1  extract_states(Outdoor, Lux &gt;= 1000, group.by.state = FALSE) |&gt;\n2  filter(!lead(Outdoor) & Outdoor) |&gt;\n  summarize_numeric(prefix = \"mean \",\n    remove = c(\"Datetime\", \"Outdoor\", \"start\", \"end\", \"duration\"),\n    add.total.duration = FALSE) |&gt; \n  mean_daily(prefix = \"\") |&gt; \n  gt() |&gt; \n  fmt_number(episodes, decimals = 0) |&gt; \n  fmt_duration(`mean epoch`, input_units = \"seconds\", output_units = \"seconds\")\n\n\n\n1\n\nLabel each interval as Outdoor (Lux≥1000) or not\n\n2\n\nFind instances where the previous interval was “indoor” and current is “outdoor”\n\n\n\n\n\n\nTable 12: Average daily count of transitions from indoor (&lt;1000 lx) to outdoor (≥1000 lx) lighting when looking at 5-second epochs\n\n\n\n\n\n\n\n\n\nDate\nmean epoch\nepisodes\n\n\n\n\nVEET\n\n\nMean daily\n5s\n64\n\n\nWeekday\n5s\n72\n\n\nWeekend\n5s\n46\n\n\n\n\n\n\n\n\n\n\nTo obtain a more meaningful measure, we can require that the outdoor state persists for some minimum duration to count as a true transition (filtering out momentary fluctuations around the 1000 lx mark). For example, we can require that once ≥1000 lx is reached, it continues for at least 5 minutes (allowing short interruptions up to 20 s). Table 13 applies this criterion, resulting in a lower, more plausible transition count.\n\n\n\nCalculate the number of transitions from indoor to outdoor with clusters\n\ndataVEET |&gt; \n  extract_clusters(Lux &gt;= 1000,\n                   cluster.duration = \"5 min\", \n                   interruption.duration = \"20 secs\",\n                   return.only.clusters = FALSE,\n                   drop.empty.groups = FALSE) |&gt; \n  filter(!lead(is.cluster) & is.cluster) |&gt; \n  summarize_numeric(prefix = \"mean \",\n    remove = c(\"Datetime\", \"start\", \"end\", \"duration\"),\n    add.total.duration = FALSE) |&gt; \n  mean_daily(prefix = \"\") |&gt; \n  gt() |&gt; fmt_number(episodes, decimals = 0)\n\n\n\n\nTable 13: Daily indoor-to-outdoor transition count (requiring ≥5 min duration of ≥1000 lx to count)\n\n\n\n\n\n\n\n\n\nDate\nmean epoch\nepisodes\n\n\n\n\nVEET\n\n\nMean daily\n5s\n5\n\n\nWeekday\n5s\n6\n\n\nWeekend\n5s\n4\n\n\n\n\n\n\n\n\n\n\n\n\n3.2.4 Longest sustained bright-light period\nThe final light exposure metric we illustrate is the longest continuous period above a certain illuminance threshold (often termed longest period above threshold, e.g. PAT1000 for 1000 lx). This gives us a sense of the longest outdoor exposure in a day. Along with it, one might report the total duration above that threshold in the day (TAT1000). While we could derive these from the earlier analyses, LightLogR provides dedicated metric functions for such calculations, which can compute multiple related metrics at once.\nUsing the function period_above_threshold() for PAT and duration_above_threshold() for TAT, we calculate both metrics for the 1000 lx threshold. Table 14 shows the mean of these metrics across days (i.e., average longest bright period and average total bright time per day).\n\n\n\nCalculate PAT1000 and TAT1000\n\ndataVEET |&gt; \n  summarize(\n    period_above_threshold(\n      Lux, Datetime, threshold = 1000, na.rm = TRUE, as.df = TRUE),\n    duration_above_threshold(\n      Lux, Datetime, threshold = 1000, na.rm = TRUE, as.df = TRUE),\n    .groups = \"keep\"\n  ) |&gt; \n  to_mean_daily(\"\")\n\n\n\n\nTable 14: Longest period and total duration illuminance above 1000 lx (PAT1000 and TAT1000)\n\n\n\n\n\n\n\n\n\nDate\nperiod above 1000\nduration above 1000\n\n\n\n\nVEET\n\n\nMean daily\n1208s (~20.13 minutes)\n5703s (~1.58 hours)\n\n\nWeekday\n1469s (~24.48 minutes)\n6815s (~1.89 hours)\n\n\nWeekend\n555s (~9.25 minutes)\n2922s (~48.7 minutes)\n\n\n\n\n\n\n\n\n\n\n\n\n3.2.5 Merging data streams\nNote that while imports from different devices can be merged, devices differ in their sensors, electronics, housing or diffuser form factors, and on-device data-processing pipelines. All of these factors affect the comparability of measurements, even when devices output the same variable (e.g., illuminance or distance). If data from different devices with the same measurement variable are to be merged, the corresponding variable names should be standardized beforehand - for example, renaming Lux and LIGHT to illuminance. If we wanted to analyse the VEET data together with the Clouclip data, for example, we would not have to rename anything, as both carry their illuminance measurements in the variable Lux. The following example shows how the combination of datasets would lead to a combined dataset, and how that would affect analysis outcomes. It is the responsibility of the researcher to perform device calibration and/or checks for a similar measurement fidelity.\n\n\n\nMerge Clouclip and VEET data\n\ndata &lt;- join_datasets(dataCC, dataVEET)\ndata |&gt; summary_overview(Lux, threshold.missing = 0.5) |&gt; gt()\n\n\n\n\nTable 15: Overview of the merged dataset\n\n\n\n\n\n\n\n\n\nname\nmean\nmin\nmax\n\n\n\n\nParticipants\n2.00\nNA\nNA\n\n\nParticipant-days\n13.00\n6.00\n7.00\n\n\nDays ≥50% complete\n6.00\n3.00\n3.00\n\n\nMissing/Irregular\n0.52\n0.38\n0.86\n\n\n\n\n\n\n\n\n\n\nWe will reuse the example from Section 3.2.1, but instead of one participant, we now have data from two devices and participants\n\n\n\nRe-calculate mean photopic illuminance with the merged dataset\n\n1data |&gt;\n2  select(Id, Date, Datetime, Lux) |&gt;\n  mutate(Lux = Lux |&gt; log_zero_inflated()) |&gt;\n  summarize_numeric(prefix = \"mean \", remove = c(\"Datetime\")) |&gt;\n  mean_daily(prefix = \"\") |&gt;\n  mutate(`mean Lux` = `mean Lux` |&gt; exp_zero_inflated()) |&gt;\n  gt() |&gt; fmt_number(decimals = 1) |&gt; cols_hide(episodes) |&gt;\n  cols_label(`mean Lux` = \"Mean photopic illuminance (lx)\")\n\n\n\n1\n\nInstead of dataVEET we now supply the merged data object\n\n2\n\nVerbatim from Section 3.2.1\n\n\n\n\n\n\nTable 16: Recalculation of the mean light exposure per day (after logarithmic transformation to account for zero inflation and skewness) with the merged dataset\n\n\n\n\n\n\n\n\n\nDate\nMean photopic illuminance (lx)\n\n\n\n\nClouclip\n\n\nMean daily\n17.6\n\n\nWeekday\n18.6\n\n\nWeekend\n15.2\n\n\nVEET\n\n\nMean daily\n57.0\n\n\nWeekday\n70.1\n\n\nWeekend\n33.9\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.3 Spectrum\nThe VEET device’s spectral sensor provides multimodal data beyond simple lux values, but it requires reconstruction of the actual light spectrum from raw sensor counts. We processed the spectral sensor data in order to compute two example spectrum-based metrics. Detailed data import, normalization, and spectral reconstruction steps are given in Supplement 1; here we present the resulting metrics. Briefly, the VEET’s spectral sensor recorded counts in ten wavelength bands (roughly 415 nm to 910 nm), plus a Dark and a Clear channel4. After normalizing by sensor gain and applying the calibration matrix, we obtained an estimated spectral irradiance distribution for each 5-minute interval in the recording. With these reconstructed spectra, we can derive novel metrics that consider spectral content of the light.\n\n\n\n\n\n\nNote\n\n\n\nSpectrum-based metrics in wearable data are relatively new and less established compared to distance or broadband light metrics. The following examples illustrate potential uses of spectral data in a theoretical sense, which can be adapted as needed for specific research questions.\n\n\n\n3.3.1 Ratio of short- vs. long-wavelength light\nOur first spectral metric is the ratio of short-wavelength light to long-wavelength light, which is relevant, for example, in assessing the blue-light content of exposure. We define “short” wavelengths as 400–500 nm and “long” as 600–700 nm (which are not standardized threshold and can be freely adjusted). Using the list-column of spectra in our dataset, we integrate each spectrum over these ranges (using spectral_integration()), and then compute the ratio short/long for each time interval. We then summarize these ratios per day.\n\n\n\nExtract wavelength sections and integrate over them\n\ndataVEET &lt;- dataVEET2 |&gt; \n1  select(Id, Date, Datetime, Spectrum) |&gt;\n  mutate(\n    short = \n      Spectrum |&gt; map_dbl(spectral_integration, wavelength.range = c(400, 500)),\n    long  = \n      Spectrum |&gt; map_dbl(spectral_integration, wavelength.range = c(600, 700)),\n    `sl ratio` = \n2      ifelse(is.nan(short / long), NA, short / long)\n  )\n\n\n\n1\n\nFocus on ID, date, time, and spectrum\n\n2\n\nCompute short-to-long wavelength ratio\n\n\n\n\nTable 17 shows the average short/long wavelength ratio, averaged over each day (and then as weekday/weekend means if applicable). In this dataset, the values give an indication of the spectral balance of the light the individual was exposed to (higher values mean relatively more short-wavelength content).\n\n\n\nCalculate daily average values of short and long wavelength content\n\ndataVEET |&gt; \n  summarize_numeric(prefix = \"\", remove = c(\"Datetime\", \"Spectrum\")) |&gt; \n  gt() |&gt; \n  fmt_number(decimals = 1, scale_by = 1000) |&gt;\n  fmt_number(`sl ratio`, decimals = 3) |&gt;\n  cols_hide(episodes)\n\n\n\n\nTable 17: Average (mW/m²) and ratio of short-wavelength (400–500 nm) to long-wavelength (600–700 nm) light\n\n\n\n\n\n\n\n\n\nDate\nshort\nlong\nsl ratio\n\n\n\n\nVEET\n\n\n2025-06-18\n83.7\n71.7\n0.610\n\n\n2025-06-20\n114.0\n81.6\n0.372\n\n\n\n\n\n\n\n\n\n\n\n\n3.3.2 Melanopic daylight efficacy ratio (MDER)\nThe same idea is behind calculating the melanopic daylight efficacy ratio (or MDER), which is defined by the CIE (“CIE System for Metrology of Optical Radiation for ipRGC-Influenced Responses to Light” 2018) as the melanopic EDI divided by the photopic illuminance (Hartmeyer and Andersen 2023). Results are shown in Table 18. In this case, instead of a simple integration over a wavelength band, we apply an action spectrum to the spectral power distribution (SPD), integrate over the weighted SPD, and apply a correction factor. All alphaopic action spectra are implemented in the spectral_integration() function. These will result in photopic illuminance and melanopic equivalent daylight illuminance (melEDI).\n\n\n\nCalculate melEDI and illumiance\n\ndataVEET &lt;- \n  dataVEET |&gt; \n  select(Id, Date, Datetime, Spectrum, short, long, `sl ratio`) |&gt;\n  mutate(\n1    melEDI =\n      Spectrum |&gt; map_dbl(spectral_integration, action.spectrum = \"melanopic\"),\n2    illuminance  =\n      Spectrum |&gt; map_dbl(spectral_integration, action.spectrum = \"photopic\")\n  )\n\n\n\n1\n\nCalculate melanopic EDI by applying the \\(s_{mel (\\lambda)}\\) action spectrum, integrating, and weighing\n\n2\n\nCalculate photopic illuminance by applying the \\(V_{(\\lambda)}\\) action spectrum, integrating, and weighing\n\n\n\n\n\n\n\nCalculate MDER\n\ndataVEET  |&gt; \n  summarize_numeric(prefix = \"\", remove = c(\"Datetime\", \"Spectrum\")) |&gt; \n  mutate(MDER = melEDI / illuminance) |&gt;\n  gt() |&gt; \n  fmt_number(-`sl ratio`, decimals = 1, scale_by = 1000) |&gt;\n  fmt_number(c(MDER, `sl ratio`), decimals = 3) |&gt;\n  cols_hide(episodes)\n\n\n\n\nTable 18: Average melanopic daylight efficacy ratio (MDER)\n\n\n\n\n\n\n\n\n\nDate\nshort\nlong\nsl ratio\nmelEDI\nilluminance\nMDER\n\n\n\n\nVEET\n\n\n2025-06-18\n83.7\n71.7\n0.610\n80.6\n103.7\n0.777\n\n\n2025-06-20\n114.0\n81.6\n0.372\n108.0\n123.9\n0.871\n\n\n\n\n\n\n\n\n\n\n\n\n3.3.3 Short-wavelength light at specific times of day\nThe third spectral example examines short-wavelength light exposure as a function of time of day. Certain studies might be interested in, for instance, blue-light exposure during midday versus morning or night. We demonstrate three approaches: (a) filtering the data to a specific local time window, and (b) aggregating by hour of day to see a daily profile of short-wavelength exposure. Additionally, we (c) look at differences between day and night periods.\n\nLocal morning exposureHourly profile across the dayDay vs. night (photoperiod)\n\n\nTable 19 isolates the time window between 7:00 and 11:00 each day and computes the average short-wavelength irradiance in that interval. This represents a straightforward query: “How much blue light does the subject get in the morning on average?”\n\n\n\nCalculate short-wavelength light before noon\n\ndataVEET |&gt; \n1  filter_Time(start = \"7:00:00\", end = \"11:00:00\") |&gt;\n  select(c(Id, Date, short)) |&gt;\n  summarize_numeric(prefix = \"\") |&gt; \n  gt() |&gt; \n  fmt_number(short, scale_by = 1000) |&gt; \n  cols_label(short = \"Short-wavelength irradiance (mW/m²)\") |&gt; \n  cols_hide(episodes)\n\n\n\n1\n\nFilter data to local 7am–11am\n\n\n\n\n\n\nTable 19: Average short-wavelength light (400–500 nm) exposure between 7:00 and 11:00 each day\n\n\n\n\n\n\n\n\n\nDate\nShort-wavelength irradiance (mW/m²)\n\n\n\n\nVEET\n\n\n2025-06-18\n5.44\n\n\n2025-06-20\n0.95\n\n\n\n\n\n\n\n\n\n\n\n\nTo visualize short-wavelength exposure over the course of a day, we aggregate the data into hourly bins. We cut the timeline into 1-hour segments (using local time), compute the mean short-wavelength irradiance in each hour for each day. Figure 9 shows the resulting diurnal profile, with short-wavelength exposure expressed as a fraction of the daily maximum for easier comparison.\n\n\n\nPlot a diurnal profile\n\n1dataVEETtime &lt;- dataVEET |&gt;\n2  cut_Datetime(unit = \"1 hour\", type = \"floor\", group_by = TRUE) |&gt;\n  select(-c(Spectrum, long, Datetime)) |&gt;\n  summarize_numeric(prefix = \"\") |&gt; \n3  add_Time_col(Datetime.rounded)  |&gt;\n  mutate(rel_short = short / max(short))\n\n4dataVEETtime |&gt;\n  ggplot(aes(x=Time, y = rel_short)) +\n  geom_col(aes(fill = factor(Date)), position = \"dodge\") +\n  ggsci::scale_fill_jco() +\n  theme_minimal() +\n  labs(y = \"Normalized short-wavelength irradiance\", \n       x = \"Local time (HH:MM)\",\n       fill = \"Date\") + \n  scale_y_continuous(labels = scales::label_percent()) +\n  scale_x_time(labels = scales::label_time(format = \"%H:%M\"))\n\n\n\n1\n\nPrepare hourly binned data\n\n2\n\nBin timestamps by hour\n\n3\n\nAdd a Time column (hour of day)\n\n4\n\nCreating the plot\n\n\n\n\n\n\n\n\n\n\nFigure 9: Diurnal profile of short-wavelength light exposure. Each bar represents the average short-wavelength irradiance at that hour of the day (0–23 h), normalized to the daily maximum.\n\n\n\n\n\n\n\nFinally, we compare short-wavelength exposure during daytime vs. nighttime. Using civil dawn and dusk information (based on geographic coordinates, here set for Houston, TX, USA), we label each measurement as day or night and then compute the total short-wavelength exposure in each period. Table 20 summarizes the daily short-wavelength dose received during the day vs. during the night.\n\n\n\nCalculate photoperiod dependent measures\n\ndataVEET |&gt;\n  select(-c(Spectrum, long, `sl ratio`, melEDI, illuminance)) |&gt;\n  add_photoperiod(coordinates) |&gt; \n  group_by(photoperiod.state, .add = TRUE) |&gt; \n  summarize_numeric(prefix = \"\", \n                    remove = c(\"dawn\", \"dusk\", \"photoperiod\", \"Datetime\")) |&gt; \n  group_by(Id, photoperiod.state) |&gt; \n  select(-episodes) |&gt; \n  pivot_wider(names_from =photoperiod.state, values_from = short) |&gt; \n  gt() |&gt; \n  fmt_number(scale_by = 1000, decimals = 1)\n\n\n\n\nTable 20: Short wavelength light exposure (mW/m²) during the day and at night\n\n\n\n\n\n\n\n\n\nDate\nday\nnight\n\n\n\n\nVEET\n\n\n2025-06-18\n126.5\n12.3\n\n\n2025-06-20\n181.8\n1.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn the code cell above, add_photoperiod(coordinates) is used as a convenient way to add columns to the data frame, indicating for each timestamp whether it was day or night, given the latitude/longitude."
  },
  {
    "objectID": "index.html#discussion-and-conclusion",
    "href": "index.html#discussion-and-conclusion",
    "title": "Analysis of human visual experience data",
    "section": "4 Discussion and conclusion",
    "text": "4 Discussion and conclusion\nThis tutorial demonstrates a standardized, step-by-step pipeline to calculate a variety of visual experience metrics. We illustrated how a combination of LightLogR functions and tidyverse workflows can yield clear and reproducible analyses for wearable device data. While the full pipeline is detailed, each metric is computed through a dedicated sequence of well-documented steps, yet remains configurable to realize different metric definitions or thresholds.\nBy leveraging LightLogR’s framework alongside common data analysis approaches, the process remains transparent and relatively easy to follow. The overall goal is to make analysis transparent (with open-source functions), accessible (through thorough documentation, tutorials, and human-readable function naming, all under an MIT license), robust (the package includes &gt;900 unit tests and continuous integration with bug tracking on GitHub), and community-driven (open feature requests and contributions via GitHub).\nEven with standardized pipelines, researchers must still make and document many decisions during data cleaning, time-series handling, and metric calculations — especially for complex metrics that involve grouping data in multiple ways (for example, grouping by distance range as well as by duration for cluster metrics). We have highlighted these decision points in the tutorial (such as how to handle irregular intervals, choosing thresholds for “near” distances or “outdoor” light, and deciding on minimum durations for sustained events). Explicitly considering and reporting these choices is important for reproducibility and for comparing results across studies.\nThe broad set of features in LightLogR — ranging from data import and cleaning tools (for handling time gaps and irregularities) to visualization functions and metric calculators — make it a powerful toolkit for visual experience research. Our examples spanned circadian-light metrics and myopia-related metrics, demonstrating the versatility of a unified analysis approach. By using community-supported tools and workflows, researchers in vision science, chronobiology, myopia, and related fields can reduce time spent on low-level data wrangling and focus more on interpreting results and advancing scientific understanding."
  },
  {
    "objectID": "index.html#sessioninfo",
    "href": "index.html#sessioninfo",
    "title": "Analysis of human visual experience data",
    "section": "5 Session info",
    "text": "5 Session info\n\nsessionInfo()\n\nR version 4.5.2 (2025-10-31)\nPlatform: x86_64-pc-linux-gnu\nRunning under: Ubuntu 24.04.3 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 \nLAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.26.so;  LAPACK version 3.12.0\n\nlocale:\n [1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8       \n [4] LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8   \n [7] LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C          \n[10] LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C   \n\ntime zone: UTC\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nother attached packages:\n [1] gt_1.1.0         lubridate_1.9.4  forcats_1.0.1    stringr_1.6.0   \n [5] dplyr_1.1.4      purrr_1.2.0      readr_2.1.6      tidyr_1.3.1     \n [9] tibble_3.3.0     ggplot2_4.0.1    tidyverse_2.0.0  LightLogR_0.10.0\n\nloaded via a namespace (and not attached):\n [1] sass_0.4.10        generics_0.1.4     renv_1.1.5         class_7.3-23      \n [5] xml2_1.5.1         KernSmooth_2.23-26 stringi_1.8.7      hms_1.1.4         \n [9] digest_0.6.39      magrittr_2.0.4     evaluate_1.0.5     grid_4.5.2        \n[13] timechange_0.3.0   RColorBrewer_1.1-3 fastmap_1.2.0      jsonlite_2.0.0    \n[17] e1071_1.7-16       DBI_1.2.3          viridisLite_0.4.2  scales_1.4.0      \n[21] textshaping_1.0.4  cli_3.6.5          rlang_1.1.6        units_1.0-0       \n[25] cowplot_1.2.0      withr_3.0.2        yaml_2.3.12        tools_4.5.2       \n[29] tzdb_0.5.0         vctrs_0.6.5        R6_2.6.1           proxy_0.4-27      \n[33] classInt_0.4-11    lifecycle_1.0.4    fs_1.6.6           htmlwidgets_1.6.4 \n[37] ragg_1.5.0         pkgconfig_2.0.3    pillar_1.11.1      gtable_0.3.6      \n[41] Rcpp_1.1.0         glue_1.8.0         sf_1.0-23          systemfonts_1.3.1 \n[45] xfun_0.54          tidyselect_1.2.1   knitr_1.50         farver_2.1.2      \n[49] htmltools_0.5.9    rmarkdown_2.30     ggsci_4.1.0        labeling_0.4.3    \n[53] suntools_1.1.0     compiler_4.5.2     S7_0.2.1"
  },
  {
    "objectID": "index.html#statements",
    "href": "index.html#statements",
    "title": "Analysis of human visual experience data",
    "section": "6 Statements",
    "text": "6 Statements\n\n6.1 Acknowledgement\nWe thank George Hatoun and David Sullivan (Reality Labs Research) for reviewing a draft of the tutorial manuscript and providing sample data for the VEET for spectral analyses.\n\n\n6.2 Data availability statement\nAll data and code in this tutorial and Supplement 1 are available from the GitHub repository: https://github.com/tscnlab/ZaunerEtAl_JVis_2026/, archived on Zenodo: https://doi.org/10.5281/zenodo.16566014 under a MIT license (data under CC-BY license).\n\n\n6.3 Funding statement\nJZ’s position is funded by the MeLiDos project. The project has received funding from the European Partnership on Metrology (22NRM05 MeLiDos), co-financed from the European Union’s Horizon Europe Research and Innovation Programme and by the Participating States. Views and opinions expressed are however those of the author(s) only and do not necessarily reflect those of the European Union or EURAMET. Neither the European Union nor the granting authority can be held responsible for them. JZ, LAO, and MS received research funding from Reality Labs Research. The funders had no role in study design, data collection and analysis, decision to publish or preparation of the manuscript.\n\n\n6.4 Conflict of interest statement\nJZ declares the following potential conflict of interest in the past five years (2021-2025). Funding: Received research funding from Reality Labs Research.\nAN declares the following potential conflicts of interest in the past five years (2021-2025). none\nLAO declares the following potential conflict of interest in the past five years (2021-2025). Consultancy: Zeiss, Alcon, EssilorLuxottica; Research support: Topcon, Meta, LLC; Patents: US 11375890 B2\nMS declares the following potential conflicts of interest in the past five years (2021–2025). Academic roles: Member of the Board of Directors, Society of Light, Rhythms, and Circadian Health (SLRCH); Chair of Joint Technical Committee 20 (JTC20) of the International Commission on Illumination (CIE); Member of the Daylight Academy; Chair of Research Data Alliance Working Group Optical Radiation and Visual Experience Data. Remunerated roles: Speaker of the Steering Committee of the Daylight Academy; Ad-hoc reviewer for the Health and Digital Executive Agency of the European Commission; Ad-hoc reviewer for the Swedish Research Council; Associate Editor for LEUKOS, journal of the Illuminating Engineering Society; Examiner, University of Manchester; Examiner, Flinders University; Examiner, University of Southern Norway. Funding: Received research funding and support from the Max Planck Society, Max Planck Foundation, Max Planck Innovation, Technical University of Munich, Wellcome Trust, National Research Foundation Singapore, European Partnership on Metrology, VELUX Foundation, Bayerisch-Tschechische Hochschulagentur (BTHA), BayFrance (Bayerisch-Französisches Hochschulzentrum), BayFOR (Bayerische Forschungsallianz), and Reality Labs Research. Honoraria for talks: Received honoraria from the ISGlobal, Research Foundation of the City University of New York and the Stadt Ebersberg, Museum Wald und Umwelt. Travel reimbursements: Daimler und Benz Stiftung. Patents: Named on European Patent Application EP23159999.4A (“System and method for corneal-plane physiologically-relevant light logging with an application to personalized light interventions related to health and well-being”). With the exception of the funding source supporting this work, M.S. declares no influence of the disclosed roles or relationships on the work presented herein.\n\n\n6.5 Statement of generative AI and AI-assisted technologies in the writing process\nThe authors used ChatGPT during the preparation of this work. After using this tool, the authors reviewed and edited the content as needed and take full responsibility for the content of the publication.\nUse of AI in contributor roles 5: Conceptualization: no Data curation: no Formal analysis: bug fixing Methodology: no Software: bug fixing Validation: no Visualization: tweaking of options Writing – original draft: abstract refinement Writing – review & editing: improve readability and language"
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Analysis of human visual experience data",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFunctions from LightLogR are presented as links to the function documentation. General analysis functions (from package dplyr) are presented as normal text.↩︎\nThe upper threshold refers to the Clouclips` maximum distance measurement and is not theoretically based↩︎\nThis deviates from the common definition of luminous exposure, which is the sum of illuminance measurements scaled to hourly observation intervals↩︎\nNote that older firmware versions of the VEET prior to 2.1.7 contained two Clear channels and the highest spectral channel was indicated as 940 nm. Data collected with this early firmware version are not suitable for spectral reconstruction in the context of research projects.↩︎\nBased on the CRediT taxonomy. Funding acquisition, investigation, project administration, resources, and supervision were deemed irrelevant in this context and thus removed.↩︎"
  }
]